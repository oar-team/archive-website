<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>OAR-DOCUMENTATION-ADMIN</title>

<link rel="icon" href="../../../../../favicon.ico" type="image/x-icon" />

<link rel="stylesheet" href="../../../../../style.css" type="text/css" />

<link rel="stylesheet" href="../../../../../local.css" type="text/css" />





</head>
<body>

<div class="page">

<div class="pageheader">
<div class="header">
<span>
<span class="parentlinks">

<a href="../../../../../">OAR</a>/ 

<a href="../../../../../">sources</a>/ 

<a href="../../../../../">2.5</a>/ 

<a href="../../../../../">docs</a>/ 

<a href="../../../../../">documentation</a>/ 

</span>
<span class="title">
OAR-DOCUMENTATION-ADMIN

</span>
</span>

<form method="get" action="http://oar.imag.fr//ikiwiki.cgi" id="searchform">
<div>
<input type="text" id="searchbox" name="P" value="" size="16"
 />
</div>
</form>


</div>





</div>


<div class="sidebar">
<ul>
<li><strong><a href="../../../../../">Home</a></strong></li>
<li><strong><a href="../../../../../about/">About</a></strong></li>
<li><strong><a href="../../../../../news/">News</a></strong></li>
<li><strong><a href="http://oar.imag.fr/archive/wiki-oar">Wiki</a></strong></li>
<li><strong>Getting OAR</strong>
<ul>
<li><a href="../../../../../repositories/">Repositories</a></li>
<li><a href="../../../../../installation/">Installation</a></li>
<li><a href="../../../../../changelog/">Changelog</a></li>
</ul></li>
<li><strong>Using OAR</strong>
<ul>
<li><a href="../../../../../user-quickstart/">First user steps</a></li>
<li><a href="../../../../../user-usecases/">Use cases</a></li>
<li><a href="../../../../../faq/">FAQ</a></li>
</ul></li>
<li><strong>Getting help</strong>
<ul>
<li><a href="../../../../../support/">Contact/Mailing lists</a></li>
<li><a href="../../../../../documentation/">Documentation</a></li>
</ul></li>
<li><strong>Contributing to OAR</strong>
<ul>
<li><a href="../../../../../contributing/repositories/">Source repositories</a></li>
<li><a href="../../../../../contributing/workflow/">Workflow</a></li>
<li><a href="../../../../../contributing/GSOCs/">GSOCs</a></li>
</ul></li>
<li><strong><a href="../../../../../research/">Researchers' Corner</a></strong></li>
<li><strong><a href="../../../../../partners-projects/">Partners &amp; Projects</a></strong></li>
</ul>

</div>


<div id="pagebody">

<div id="content">






OAR Documentation - Admin Guide



<div class="document" id="oar-documentation-admin-guide">
<h1 class="title">OAR Documentation - Admin Guide</h1>

<img alt="OAR logo" class="align-center" src="../schemas/oar_logo.png" />
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Authors:</th><td class="field-body">Capit Nicolas, Emeras Joseph</td>
</tr>
<tr class="field"><th class="field-name">Address:</th><td class="field-body">Laboratoire d'Informatique de Grenoble
Bat. ENSIMAG - antenne de Montbonnot
ZIRST 51, avenue Jean Kuntzmann
38330 MONTBONNOT SAINT MARTIN</td>
</tr>
<tr class="field"><th class="field-name">Contact:</th><td class="field-body"><a class="reference external" href="mailto:nicolas.capit@imag.fr">nicolas.capit&#64;imag.fr</a>, <a class="reference external" href="mailto:joseph.emeras@imag.fr">joseph.emeras&#64;imag.fr</a></td>
</tr>
<tr class="field"><th class="field-name">Authors:</th><td class="field-body">LIG laboratory</td>
</tr>
<tr class="field"><th class="field-name">Organization:</th><td class="field-body">LIG laboratory</td>
</tr>
<tr class="field"><th class="field-name">Status:</th><td class="field-body">Stable</td>
</tr>
<tr class="field"><th class="field-name">Copyright:</th><td class="field-body">licenced under the GNU GENERAL PUBLIC LICENSE</td>
</tr>
<tr class="field"><th class="field-name">Dedication:</th><td class="field-body">For administrators.</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Abstract:</th><td class="field-body">OAR is a resource manager (or batch scheduler) for large clusters. By it's
functionnalities, it's near of PBS, LSF, CCS and Condor. It's suitable for
productive plateforms and research experiments.</td>
</tr>
</tbody>
</table>
<p><strong>BE CAREFULL : THIS DOCUMENTATION IS FOR OAR &gt;= 2.3.0</strong></p>
<p>PDF version : <a class="reference external" href="OAR-DOCUMENTATION-ADMIN.pdf">OAR-DOCUMENTATION-ADMIN.pdf</a></p>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first">Table of Contents</p>
<ul class="auto-toc simple">
<li><a class="reference internal" href="#oar-capabilities" id="id17">1&nbsp;&nbsp;&nbsp;OAR capabilities</a></li>
<li><a class="reference internal" href="#installing-the-oar-batch-system" id="id18">2&nbsp;&nbsp;&nbsp;Installing the OAR batch system</a><ul class="auto-toc">
<li><a class="reference internal" href="#overview" id="id19">2.1&nbsp;&nbsp;&nbsp;Overview</a></li>
<li><a class="reference internal" href="#computing-nodes" id="id20">2.2&nbsp;&nbsp;&nbsp;Computing nodes</a><ul class="auto-toc">
<li><a class="reference internal" href="#installation-from-the-packages" id="id21">2.2.1&nbsp;&nbsp;&nbsp;Installation from the packages</a></li>
<li><a class="reference internal" href="#installation-from-the-tarball" id="id22">2.2.2&nbsp;&nbsp;&nbsp;Installation from the tarball</a></li>
<li><a class="reference internal" href="#configuration" id="id23">2.2.3&nbsp;&nbsp;&nbsp;Configuration</a><ul class="auto-toc">
<li><a class="reference internal" href="#oar-node-ssh-access" id="id24">2.2.3.1&nbsp;&nbsp;&nbsp;oar node ssh access</a></li>
<li><a class="reference internal" href="#init-d-scripts" id="id25">2.2.3.2&nbsp;&nbsp;&nbsp;Init.d scripts</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#server-node" id="id26">2.3&nbsp;&nbsp;&nbsp;Server node</a><ul class="auto-toc">
<li><a class="reference internal" href="#id1" id="id27">2.3.1&nbsp;&nbsp;&nbsp;Installation from the packages</a></li>
<li><a class="reference internal" href="#id2" id="id28">2.3.2&nbsp;&nbsp;&nbsp;Installation from the tarball</a></li>
<li><a class="reference internal" href="#id3" id="id29">2.3.3&nbsp;&nbsp;&nbsp;Configuration</a><ul class="auto-toc">
<li><a class="reference internal" href="#the-oar-database" id="id30">2.3.3.1&nbsp;&nbsp;&nbsp;The oar database</a></li>
<li><a class="reference internal" href="#id4" id="id31">2.3.3.2&nbsp;&nbsp;&nbsp;Init.d scripts</a></li>
<li><a class="reference internal" href="#adding-resources-to-the-system" id="id32">2.3.3.3&nbsp;&nbsp;&nbsp;Adding resources to the system</a></li>
</ul>
</li>
<li><a class="reference internal" href="#notes" id="id33">2.3.4&nbsp;&nbsp;&nbsp;Notes</a><ul class="auto-toc">
<li><a class="reference internal" href="#security-issues" id="id34">2.3.4.1&nbsp;&nbsp;&nbsp;Security issues</a></li>
<li><a class="reference internal" href="#postgresql-autovacuum" id="id35">2.3.4.2&nbsp;&nbsp;&nbsp;PostgreSQL : autovacuum</a></li>
<li><a class="reference internal" href="#postgresql-authentication" id="id36">2.3.4.3&nbsp;&nbsp;&nbsp;PostgreSQL : authentication</a></li>
<li><a class="reference internal" href="#about-x11-usage-in-oar" id="id37">2.3.4.4&nbsp;&nbsp;&nbsp;About X11 usage in OAR</a></li>
<li><a class="reference internal" href="#using-taktuk" id="id38">2.3.4.5&nbsp;&nbsp;&nbsp;Using Taktuk</a></li>
<li><a class="reference internal" href="#cpuset-feature" id="id39">2.3.4.6&nbsp;&nbsp;&nbsp;CPUSET feature</a></li>
<li><a class="reference internal" href="#energy-saving" id="id40">2.3.4.7&nbsp;&nbsp;&nbsp;Energy saving</a></li>
<li><a class="reference internal" href="#disabling-selinux" id="id41">2.3.4.8&nbsp;&nbsp;&nbsp;Disabling SELinux</a></li>
<li><a class="reference internal" href="#intel-cpuset-id-issue" id="id42">2.3.4.9&nbsp;&nbsp;&nbsp;Intel cpuset id issue</a></li>
<li><a class="reference internal" href="#other-issues" id="id43">2.3.4.10&nbsp;&nbsp;&nbsp;Other issues</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#frontend-nodes" id="id44">2.4&nbsp;&nbsp;&nbsp;Frontend nodes</a><ul class="auto-toc">
<li><a class="reference internal" href="#id5" id="id45">2.4.1&nbsp;&nbsp;&nbsp;Installation from the packages</a></li>
<li><a class="reference internal" href="#id6" id="id46">2.4.2&nbsp;&nbsp;&nbsp;Installation from the tarball</a></li>
<li><a class="reference internal" href="#id7" id="id47">2.4.3&nbsp;&nbsp;&nbsp;Configuration</a><ul class="auto-toc">
<li><a class="reference internal" href="#coherent-configuration-files-between-server-node-and-user-nodes" id="id48">2.4.3.1&nbsp;&nbsp;&nbsp;Coherent configuration files between server node and user nodes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#oar-restful-api-installation" id="id49">2.4.4&nbsp;&nbsp;&nbsp;OAR RESTful API Installation</a><ul class="auto-toc">
<li><a class="reference internal" href="#from-the-packaging" id="id50">2.4.4.1&nbsp;&nbsp;&nbsp;From the packaging</a></li>
<li><a class="reference internal" href="#from-the-sources" id="id51">2.4.4.2&nbsp;&nbsp;&nbsp;From the sources</a></li>
<li><a class="reference internal" href="#id8" id="id52">2.4.4.3&nbsp;&nbsp;&nbsp;Configuration</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#visualization-node" id="id53">2.5&nbsp;&nbsp;&nbsp;Visualization node</a><ul class="auto-toc">
<li><a class="reference internal" href="#description" id="id54">2.5.1&nbsp;&nbsp;&nbsp;Description</a></li>
<li><a class="reference internal" href="#id9" id="id55">2.5.2&nbsp;&nbsp;&nbsp;Installation from the packages</a></li>
<li><a class="reference internal" href="#id10" id="id56">2.5.3&nbsp;&nbsp;&nbsp;Installation from the tarball</a></li>
<li><a class="reference internal" href="#id11" id="id57">2.5.4&nbsp;&nbsp;&nbsp;Configuration</a></li>
</ul>
</li>
<li><a class="reference internal" href="#further-informations" id="id58">2.6&nbsp;&nbsp;&nbsp;Further informations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#security-aspects-in-oar" id="id59">3&nbsp;&nbsp;&nbsp;Security aspects in OAR</a></li>
<li><a class="reference internal" href="#administrator-commands" id="id60">4&nbsp;&nbsp;&nbsp;Administrator commands</a><ul class="auto-toc">
<li><a class="reference internal" href="#oarproperty" id="id61">4.1&nbsp;&nbsp;&nbsp;<em>oarproperty</em></a></li>
<li><a class="reference internal" href="#oarnodesetting" id="id62">4.2&nbsp;&nbsp;&nbsp;<em>oarnodesetting</em></a></li>
<li><a class="reference internal" href="#oaradmin" id="id63">4.3&nbsp;&nbsp;&nbsp;<em>oaradmin</em></a></li>
<li><a class="reference internal" href="#oarremoveresource" id="id64">4.4&nbsp;&nbsp;&nbsp;<em>oarremoveresource</em></a></li>
<li><a class="reference internal" href="#oaraccounting" id="id65">4.5&nbsp;&nbsp;&nbsp;<em>oaraccounting</em></a></li>
<li><a class="reference internal" href="#oarnotify" id="id66">4.6&nbsp;&nbsp;&nbsp;<em>oarnotify</em></a></li>
<li><a class="reference internal" href="#oarmonitor" id="id67">4.7&nbsp;&nbsp;&nbsp;<em>oarmonitor</em></a></li>
</ul>
</li>
<li><a class="reference internal" href="#database-scheme" id="id68">5&nbsp;&nbsp;&nbsp;Database scheme</a><ul class="auto-toc">
<li><a class="reference internal" href="#accounting" id="id69">5.1&nbsp;&nbsp;&nbsp;<em>accounting</em></a></li>
<li><a class="reference internal" href="#admission-rules" id="id70">5.2&nbsp;&nbsp;&nbsp;<em>admission_rules</em></a></li>
<li><a class="reference internal" href="#event-logs" id="id71">5.3&nbsp;&nbsp;&nbsp;<em>event_logs</em></a></li>
<li><a class="reference internal" href="#event-log-hostnames" id="id72">5.4&nbsp;&nbsp;&nbsp;<em>event_log_hostnames</em></a></li>
<li><a class="reference internal" href="#files" id="id73">5.5&nbsp;&nbsp;&nbsp;<em>files</em></a></li>
<li><a class="reference internal" href="#frag-jobs" id="id74">5.6&nbsp;&nbsp;&nbsp;<em>frag_jobs</em></a></li>
<li><a class="reference internal" href="#gantt-jobs-resources" id="id75">5.7&nbsp;&nbsp;&nbsp;<em>gantt_jobs_resources</em></a></li>
<li><a class="reference internal" href="#gantt-jobs-resources-visu" id="id76">5.8&nbsp;&nbsp;&nbsp;<em>gantt_jobs_resources_visu</em></a></li>
<li><a class="reference internal" href="#gantt-jobs-predictions" id="id77">5.9&nbsp;&nbsp;&nbsp;<em>gantt_jobs_predictions</em></a></li>
<li><a class="reference internal" href="#gantt-jobs-predictions-visu" id="id78">5.10&nbsp;&nbsp;&nbsp;<em>gantt_jobs_predictions_visu</em></a></li>
<li><a class="reference internal" href="#jobs" id="id79">5.11&nbsp;&nbsp;&nbsp;<em>jobs</em></a></li>
<li><a class="reference internal" href="#job-dependencies" id="id80">5.12&nbsp;&nbsp;&nbsp;<em>job_dependencies</em></a></li>
<li><a class="reference internal" href="#moldable-job-descriptions" id="id81">5.13&nbsp;&nbsp;&nbsp;<em>moldable_job_descriptions</em></a></li>
<li><a class="reference internal" href="#job-resource-groups" id="id82">5.14&nbsp;&nbsp;&nbsp;<em>job_resource_groups</em></a></li>
<li><a class="reference internal" href="#job-resource-descriptions" id="id83">5.15&nbsp;&nbsp;&nbsp;<em>job_resource_descriptions</em></a></li>
<li><a class="reference internal" href="#job-state-logs" id="id84">5.16&nbsp;&nbsp;&nbsp;<em>job_state_logs</em></a></li>
<li><a class="reference internal" href="#job-types" id="id85">5.17&nbsp;&nbsp;&nbsp;<em>job_types</em></a></li>
<li><a class="reference internal" href="#resources" id="id86">5.18&nbsp;&nbsp;&nbsp;<em>resources</em></a></li>
<li><a class="reference internal" href="#resource-logs" id="id87">5.19&nbsp;&nbsp;&nbsp;<em>resource_logs</em></a></li>
<li><a class="reference internal" href="#assigned-resources" id="id88">5.20&nbsp;&nbsp;&nbsp;<em>assigned_resources</em></a></li>
<li><a class="reference internal" href="#queues" id="id89">5.21&nbsp;&nbsp;&nbsp;<em>queues</em></a></li>
<li><a class="reference internal" href="#challenges" id="id90">5.22&nbsp;&nbsp;&nbsp;<em>challenges</em></a></li>
</ul>
</li>
<li><a class="reference internal" href="#configuration-file" id="id91">6&nbsp;&nbsp;&nbsp;Configuration file</a></li>
<li><a class="reference internal" href="#modules-descriptions" id="id92">7&nbsp;&nbsp;&nbsp;Modules descriptions</a><ul class="auto-toc">
<li><a class="reference internal" href="#almighty" id="id93">7.1&nbsp;&nbsp;&nbsp;Almighty</a></li>
<li><a class="reference internal" href="#sarko" id="id94">7.2&nbsp;&nbsp;&nbsp;Sarko</a></li>
<li><a class="reference internal" href="#judas" id="id95">7.3&nbsp;&nbsp;&nbsp;Judas</a></li>
<li><a class="reference internal" href="#leon" id="id96">7.4&nbsp;&nbsp;&nbsp;Leon</a></li>
<li><a class="reference internal" href="#runner" id="id97">7.5&nbsp;&nbsp;&nbsp;Runner</a></li>
<li><a class="reference internal" href="#nodechangestate" id="id98">7.6&nbsp;&nbsp;&nbsp;NodeChangeState</a></li>
<li><a class="reference internal" href="#scheduler" id="id99">7.7&nbsp;&nbsp;&nbsp;Scheduler</a><ul class="auto-toc">
<li><a class="reference internal" href="#oar-sched-gantt-with-timesharing" id="id100">7.7.1&nbsp;&nbsp;&nbsp;oar_sched_gantt_with_timesharing</a></li>
<li><a class="reference internal" href="#oar-sched-gantt-with-timesharing-and-fairsharing" id="id101">7.7.2&nbsp;&nbsp;&nbsp;oar_sched_gantt_with_timesharing_and_fairsharing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hulot" id="id102">7.8&nbsp;&nbsp;&nbsp;Hulot</a></li>
</ul>
</li>
<li><a class="reference internal" href="#internal-mechanisms" id="id103">8&nbsp;&nbsp;&nbsp;Internal mechanisms</a><ul class="auto-toc">
<li><a class="reference internal" href="#job-execution" id="id104">8.1&nbsp;&nbsp;&nbsp;Job execution</a></li>
<li><a class="reference internal" href="#scheduling" id="id105">8.2&nbsp;&nbsp;&nbsp;Scheduling</a></li>
</ul>
</li>
<li><a class="reference internal" href="#faq-admin" id="id106">9&nbsp;&nbsp;&nbsp;FAQ - ADMIN</a><ul class="auto-toc">
<li><a class="reference internal" href="#release-policy" id="id107">9.1&nbsp;&nbsp;&nbsp;Release policy</a></li>
<li><a class="reference internal" href="#what-means-the-error-bad-configuration-option-permitlocalcommand-when-i-am-using-oarsh" id="id108">9.2&nbsp;&nbsp;&nbsp;What means the error &quot;Bad configuration option: PermitLocalCommand&quot; when I am using oarsh?</a></li>
<li><a class="reference internal" href="#how-to-manage-start-stop-of-the-nodes" id="id109">9.3&nbsp;&nbsp;&nbsp;How to manage start/stop of the nodes?</a></li>
<li><a class="reference internal" href="#how-can-i-manage-scheduling-queues" id="id110">9.4&nbsp;&nbsp;&nbsp;How can I manage scheduling queues?</a></li>
<li><a class="reference internal" href="#how-can-i-handle-licence-tokens" id="id111">9.5&nbsp;&nbsp;&nbsp;How can I handle licence tokens?</a></li>
<li><a class="reference internal" href="#how-can-i-handle-multiple-clusters-with-one-oar" id="id112">9.6&nbsp;&nbsp;&nbsp;How can I handle multiple clusters with one OAR?</a></li>
<li><a class="reference internal" href="#how-to-configure-a-more-ecological-cluster-or-how-to-make-some-power-consumption-economies" id="id113">9.7&nbsp;&nbsp;&nbsp;How to configure a more ecological cluster (or how to make some power consumption economies)?</a></li>
<li><a class="reference internal" href="#how-to-configure-temporary-uid-for-each-job" id="id114">9.8&nbsp;&nbsp;&nbsp;How to configure temporary UID for each job?</a></li>
<li><a class="reference internal" href="#how-to-enable-jobs-to-connect-to-the-frontales-from-the-nodes-using-oarsh" id="id115">9.9&nbsp;&nbsp;&nbsp;How to enable jobs to connect to the frontales from the nodes using oarsh?</a></li>
<li><a class="reference internal" href="#a-job-remains-in-the-finishing-state-what-can-i-do" id="id116">9.10&nbsp;&nbsp;&nbsp;A job remains in the &quot;Finishing&quot; state, what can I do?</a></li>
<li><a class="reference internal" href="#how-can-i-write-my-own-scheduler" id="id117">9.11&nbsp;&nbsp;&nbsp;How can I write my own scheduler?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#oar-s-scheduler-in-ocaml" id="id118">10&nbsp;&nbsp;&nbsp;OAR's scheduler in ocaml</a><ul class="auto-toc">
<li><a class="reference internal" href="#intro" id="id119">10.1&nbsp;&nbsp;&nbsp;Intro</a></li>
<li><a class="reference internal" href="#features" id="id120">10.2&nbsp;&nbsp;&nbsp;Features:</a></li>
<li><a class="reference internal" href="#missing" id="id121">10.3&nbsp;&nbsp;&nbsp;Missing:</a></li>
<li><a class="reference internal" href="#next" id="id122">10.4&nbsp;&nbsp;&nbsp;Next:</a></li>
<li><a class="reference internal" href="#todo" id="id123">10.5&nbsp;&nbsp;&nbsp;ToDo:</a></li>
<li><a class="reference internal" href="#misc" id="id124">10.6&nbsp;&nbsp;&nbsp;Misc:</a></li>
<li><a class="reference internal" href="#done" id="id125">10.7&nbsp;&nbsp;&nbsp;Done:</a></li>
<li><a class="reference internal" href="#remarks-and-misc" id="id126">10.8&nbsp;&nbsp;&nbsp;Remarks and misc:</a></li>
<li><a class="reference internal" href="#bugs" id="id127">10.9&nbsp;&nbsp;&nbsp;Bugs:</a></li>
<li><a class="reference internal" href="#debug" id="id128">10.10&nbsp;&nbsp;&nbsp;Debug:</a></li>
<li><a class="reference internal" href="#what-is-the-syntax-of-this-documentation" id="id129">10.11&nbsp;&nbsp;&nbsp;What is the syntax of this documentation?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#oar-changelog" id="id130">11&nbsp;&nbsp;&nbsp;OAR CHANGELOG</a><ul class="auto-toc">
<li><a class="reference internal" href="#version-2-5-3" id="id131">11.1&nbsp;&nbsp;&nbsp;version 2.5.3:</a></li>
<li><a class="reference internal" href="#version-2-5-2" id="id132">11.2&nbsp;&nbsp;&nbsp;version 2.5.2:</a></li>
<li><a class="reference internal" href="#version-2-5-1" id="id133">11.3&nbsp;&nbsp;&nbsp;version 2.5.1:</a></li>
<li><a class="reference internal" href="#version-2-4-4" id="id134">11.4&nbsp;&nbsp;&nbsp;version 2.4.4:</a></li>
<li><a class="reference internal" href="#version-2-4-3" id="id135">11.5&nbsp;&nbsp;&nbsp;version 2.4.3:</a></li>
<li><a class="reference internal" href="#version-2-4-2" id="id136">11.6&nbsp;&nbsp;&nbsp;version 2.4.2:</a></li>
<li><a class="reference internal" href="#version-2-4-1" id="id137">11.7&nbsp;&nbsp;&nbsp;version 2.4.1:</a></li>
<li><a class="reference internal" href="#version-2-4-0" id="id138">11.8&nbsp;&nbsp;&nbsp;version 2.4.0:</a></li>
<li><a class="reference internal" href="#version-2-3-5" id="id139">11.9&nbsp;&nbsp;&nbsp;version 2.3.5:</a></li>
<li><a class="reference internal" href="#version-2-3-4" id="id140">11.10&nbsp;&nbsp;&nbsp;version 2.3.4:</a></li>
<li><a class="reference internal" href="#version-2-3-3" id="id141">11.11&nbsp;&nbsp;&nbsp;version 2.3.3:</a></li>
<li><a class="reference internal" href="#version-2-3-2" id="id142">11.12&nbsp;&nbsp;&nbsp;version 2.3.2:</a></li>
<li><a class="reference internal" href="#version-2-3-1" id="id143">11.13&nbsp;&nbsp;&nbsp;version 2.3.1:</a></li>
<li><a class="reference internal" href="#version-2-2-12" id="id144">11.14&nbsp;&nbsp;&nbsp;version 2.2.12:</a></li>
<li><a class="reference internal" href="#version-2-2-11" id="id145">11.15&nbsp;&nbsp;&nbsp;version 2.2.11:</a></li>
<li><a class="reference internal" href="#version-2-2-10" id="id146">11.16&nbsp;&nbsp;&nbsp;version 2.2.10:</a></li>
<li><a class="reference internal" href="#version-2-2-9" id="id147">11.17&nbsp;&nbsp;&nbsp;version 2.2.9:</a></li>
<li><a class="reference internal" href="#version-2-2-8" id="id148">11.18&nbsp;&nbsp;&nbsp;version 2.2.8:</a></li>
<li><a class="reference internal" href="#version-2-2-7" id="id149">11.19&nbsp;&nbsp;&nbsp;version 2.2.7:</a></li>
<li><a class="reference internal" href="#id12" id="id150">11.20&nbsp;&nbsp;&nbsp;version 2.2.11:</a></li>
<li><a class="reference internal" href="#id13" id="id151">11.21&nbsp;&nbsp;&nbsp;version 2.2.10:</a></li>
<li><a class="reference internal" href="#id14" id="id152">11.22&nbsp;&nbsp;&nbsp;version 2.2.9:</a></li>
<li><a class="reference internal" href="#id15" id="id153">11.23&nbsp;&nbsp;&nbsp;version 2.2.8:</a></li>
<li><a class="reference internal" href="#id16" id="id154">11.24&nbsp;&nbsp;&nbsp;version 2.2.7:</a></li>
<li><a class="reference internal" href="#version-2-2-6" id="id155">11.25&nbsp;&nbsp;&nbsp;version 2.2.6:</a></li>
<li><a class="reference internal" href="#version-2-2-5" id="id156">11.26&nbsp;&nbsp;&nbsp;version 2.2.5:</a></li>
<li><a class="reference internal" href="#version-2-2-4" id="id157">11.27&nbsp;&nbsp;&nbsp;version 2.2.4:</a></li>
<li><a class="reference internal" href="#version-2-2-3" id="id158">11.28&nbsp;&nbsp;&nbsp;version 2.2.3:</a></li>
<li><a class="reference internal" href="#version-2-2-2" id="id159">11.29&nbsp;&nbsp;&nbsp;version 2.2.2:</a></li>
<li><a class="reference internal" href="#version-2-2-1" id="id160">11.30&nbsp;&nbsp;&nbsp;version 2.2.1:</a></li>
<li><a class="reference internal" href="#version-2-2" id="id161">11.31&nbsp;&nbsp;&nbsp;version 2.2:</a></li>
<li><a class="reference internal" href="#version-2-1-0" id="id162">11.32&nbsp;&nbsp;&nbsp;version 2.1.0:</a></li>
<li><a class="reference internal" href="#version-2-0-2" id="id163">11.33&nbsp;&nbsp;&nbsp;version 2.0.2:</a></li>
<li><a class="reference internal" href="#version-2-0-0" id="id164">11.34&nbsp;&nbsp;&nbsp;version 2.0.0:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#oar-archives" id="id165">12&nbsp;&nbsp;&nbsp;OAR Archives</a><ul class="auto-toc">
<li><a class="reference internal" href="#module-accounting" id="id166">12.1&nbsp;&nbsp;&nbsp;module Accounting</a></li>
<li><a class="reference internal" href="#desktop-computing" id="id167">12.2&nbsp;&nbsp;&nbsp;desktop_computing</a></li>
<li><a class="reference internal" href="#drmaa-c" id="id168">12.3&nbsp;&nbsp;&nbsp;drmaa-c</a></li>
<li><a class="reference internal" href="#moldable" id="id169">12.4&nbsp;&nbsp;&nbsp;moldable</a></li>
<li><a class="reference internal" href="#ocaml-schedulers" id="id170">12.5&nbsp;&nbsp;&nbsp;ocaml-schedulers</a></li>
<li><a class="reference internal" href="#poar" id="id171">12.6&nbsp;&nbsp;&nbsp;poar</a></li>
<li><a class="reference internal" href="#poar-proto" id="id172">12.7&nbsp;&nbsp;&nbsp;poar-proto</a></li>
<li><a class="reference internal" href="#testsuite" id="id173">12.8&nbsp;&nbsp;&nbsp;testsuite</a></li>
<li><a class="reference internal" href="#tgoar" id="id174">12.9&nbsp;&nbsp;&nbsp;tgoar</a></li>
</ul>
</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="oar-capabilities">
<h1><a class="toc-backref" href="#id17">1&nbsp;&nbsp;&nbsp;OAR capabilities</a></h1>
<p>Oar is an opensource batch scheduler which provides a simple and flexible
exploitation of a cluster.</p>
<p>It manages resources of clusters as a traditional batch scheduler
(as PBS / Torque / LSF / SGE). In other words, it doesn't execute your job on
the resources but manages them (reservation, acces granting) in order to allow
you to connect these resources and use them.</p>
<p>Its design is based on high level tools:</p>
<blockquote>
<ul class="simple">
<li>relational database engine MySQL or PostgreSQL,</li>
<li>scripting language Perl,</li>
<li>confinement system mechanism cpuset,</li>
<li>scalable exploiting tool Taktuk.</li>
</ul>
</blockquote>
<p>It is flexible enough to be suitable for production clusters and research
experiments.
It currently manages over than 5000 nodes and has executed more than 5 million
jobs.</p>
<p>OAR advantages:</p>
<blockquote>
<ul class="simple">
<li>No specific daemon on nodes.</li>
<li>No dependence on specific computing libraries like MPI. We support all
sort of parallel user applications.</li>
<li>Upgrades are made on the servers, nothing to do on computing nodes.</li>
<li>CPUSET (2.6 linux kernel) integration which restricts the jobs on
assigned resources (also useful to clean completely a job, even
parallel jobs).</li>
<li>All administration tasks are performed with the taktuk command (a large
scale remote execution deployment): <a class="reference external" href="http://taktuk.gforge.inria.fr/">http://taktuk.gforge.inria.fr/</a>.</li>
<li>Hierarchical resource requests (handle heterogeneous clusters).</li>
<li>Gantt scheduling (so you can visualize the internal scheduler decisions).</li>
<li>Full or partial time-sharing.</li>
<li>Checkpoint/resubmit.</li>
<li>Licences servers management support.</li>
<li>Best effort jobs : if another job wants the same resources then it is
deleted automatically (useful to execute programs like <em>SETI&#64;home</em>).</li>
<li>Environment deployment support (Kadeploy):
<a class="reference external" href="http://kadeploy.imag.fr/">http://kadeploy.imag.fr/</a>.</li>
</ul>
</blockquote>
<p>Other more <em>common</em> features:</p>
<blockquote>
<ul class="simple">
<li>Batch and Interactive jobs.</li>
<li>Admission rules.</li>
<li>Walltime.</li>
<li>Multi-schedulers support.</li>
<li>Multi-queues with priority.</li>
<li>Backfilling.</li>
<li>First-Fit Scheduler.</li>
<li>Reservation.</li>
<li>Support of moldable tasks.</li>
<li>Check compute nodes.</li>
<li>Epilogue/Prologue scripts.</li>
<li>Support of dynamic nodes.</li>
<li>Logging/Accounting.</li>
<li>Suspend/resume jobs.</li>
</ul>
</blockquote>
</div>
<div class="section" id="installing-the-oar-batch-system">
<h1><a class="toc-backref" href="#id18">2&nbsp;&nbsp;&nbsp;Installing the OAR batch system</a></h1>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id19">2.1&nbsp;&nbsp;&nbsp;Overview</a></h2>
<p>There are currently 3 methods to install OAR (All of them are documented in this page) :</p>
<blockquote>
<ul class="simple">
<li>with the debian packages</li>
<li>with the rpm packages</li>
<li>with the sources</li>
</ul>
</blockquote>
<p>The first thing you have to know is about the OAR architecture. A common OAR
installation is composed of:</p>
<blockquote>
<ul class="simple">
<li>a <strong>server node</strong> which will hold all of OAR &quot;smartness&quot;. This node will run the oar server daemon;</li>
<li><strong>frontend nodes</strong> on which you will be allowed to login, then reserve some
computing nodes (oarsub, oarstat, oarnodes, ...);</li>
<li>several <strong>computing nodes</strong> (a.k.a. the nodes), on which the jobs will run.</li>
<li>and optionally a <strong>visualisation node</strong> on which all the visualisation
web interfaces (monika, draw-gantt, ...)  will be accessible ;</li>
</ul>
</blockquote>
</div>
<div class="section" id="computing-nodes">
<h2><a class="toc-backref" href="#id20">2.2&nbsp;&nbsp;&nbsp;Computing nodes</a></h2>
<div class="section" id="installation-from-the-packages">
<h3><a class="toc-backref" href="#id21">2.2.1&nbsp;&nbsp;&nbsp;Installation from the packages</a></h3>
<p><strong>Instructions</strong></p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Add the oar repository
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/oar.repo
[oar]
name=OAR Packages for Enterprise Linux 6 - \$basearch
baseurl=http://oar-ftp.imag.fr/oar/2.5/rpm/stable/
enabled=1
gpgcheck=0
EOF

# Install OAR node
yum install oar-node
</pre>
<p><em>For the debian like systems</em>:</p>
<pre class="literal-block">
# Add the OAR repository (choose the right one. See http://oar.imag.fr/repositories/)
echo &quot;deb http://oar-ftp.imag.fr/oar/2.5/debian squeeze main&quot; &gt; /etc/apt/sources.list.d/oar.list
curl http://oar-ftp.imag.fr/oar/oarmaster.asc | sudo apt-key add -
apt-get update

# Install OAR node
apt-get install oar-node
</pre>
</div>
<div class="section" id="installation-from-the-tarball">
<h3><a class="toc-backref" href="#id22">2.2.2&nbsp;&nbsp;&nbsp;Installation from the tarball</a></h3>
<p><strong>Requirements</strong></p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Build dependencies
yum install gcc make tar python-docutils

# Common dependencies
yum install Perl Perl-base openssh
</pre>
<p><em>For debian like system</em>:</p>
<pre class="literal-block">
# Build dependencies
apt-get install gcc make tar python-docutils

# Common dependencies
apt-get install perl perl-base openssh-client openssh-server
</pre>
<p><strong>Instructions</strong></p>
<p>Get the sources:</p>
<pre class="literal-block">
OAR_VERSION=2.5.2
curl http://oar-ftp.imag.fr/oar/2.5/sources/stable/oar-${OAR_VERSION}.tgz | tar xzvf -
cd oar-${OAR_VERSION}/
</pre>
<p>build/install/setup:</p>
<pre class="literal-block">
# build
make node-build
# install
make node-install
# setup
make node-setup
</pre>
</div>
<div class="section" id="configuration">
<h3><a class="toc-backref" href="#id23">2.2.3&nbsp;&nbsp;&nbsp;Configuration</a></h3>
<div class="section" id="oar-node-ssh-access">
<h4><a class="toc-backref" href="#id24">2.2.3.1&nbsp;&nbsp;&nbsp;oar node ssh access</a></h4>
<p>You need to ensure that the oar user can access to each nodes through ssh. To
ensure that, you can just copy the <tt class="docutils literal"><span class="pre">/var/lib/oar/.ssh</span></tt> folder from the oar
server to each nodes (ensure that <tt class="docutils literal"><span class="pre">/var/lib/oar/.ssh</span></tt> has the right
permissions).</p>
</div>
<div class="section" id="init-d-scripts">
<h4><a class="toc-backref" href="#id25">2.2.3.2&nbsp;&nbsp;&nbsp;Init.d scripts</a></h4>
<p>If you have installed OAR from sources, you need to become root user and
install manually the {init.d,default,sysconfig} scripts present in the folders:</p>
<pre class="literal-block">
$PREFIX/share/doc/oar-node/examples/scripts/{init.d,default,sysconfig}
</pre>
<p>Then you just need to use the script <tt class="docutils literal"><span class="pre">/etc/init.d/oar-node</span></tt> to start
the ssh daemon dedicated to oar-node.</p>
</div>
</div>
</div>
<div class="section" id="server-node">
<h2><a class="toc-backref" href="#id26">2.3&nbsp;&nbsp;&nbsp;Server node</a></h2>
<div class="section" id="id1">
<h3><a class="toc-backref" href="#id27">2.3.1&nbsp;&nbsp;&nbsp;Installation from the packages</a></h3>
<p><strong>Instructions</strong></p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Add the epel repository (choose the right version depending on your operating system)
rpm -i http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-5.noarch.rpm

# Add the oar repository
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/oar.repo
[oar]
name=OAR Packages for Enterprise Linux 6 - \$basearch
baseurl=http://oar-ftp.imag.fr/oar/2.5/rpm/stable/
enabled=1
gpgcheck=0
EOF

# Install OAR server for the PostgreSQL backend
yum install oar-server oar-server-pgsql

# or Install OAR server for the MySQL backend
yum install oar-server oar-server-mysql
</pre>
<p><em>For the debian like systems</em>:</p>
<pre class="literal-block">
# Add the OAR repository (choose the right one. See http://oar.imag.fr/repositories/)
echo &quot;deb http://oar-ftp.imag.fr/oar/2.5/debian squeeze main&quot; &gt; /etc/apt/sources.list.d/oar.list
curl http://oar-ftp.imag.fr/oar/oarmaster.asc | sudo apt-key add -
apt-get update

# Install OAR server for the PostgreSQL backend
apt-get install oar-server oar-server-pgsql

# or Install OAR server for the MySQL backend
apt-get install oar-server oar-server-mysql
</pre>
</div>
<div class="section" id="id2">
<h3><a class="toc-backref" href="#id28">2.3.2&nbsp;&nbsp;&nbsp;Installation from the tarball</a></h3>
<p><strong>Requirements</strong></p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Add the epel repository (choose the right version depending on your operating system)
rpm -i http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-5.noarch.rpm

# Build dependencies
yum install gcc make tar python-docutils

# Common dependencies
yum install Perl Perl-base openssh Perl-DBI perl-Sort-Versions

# MySQL dependencies
yum install mysql-server mysql perl-DBD-MySQL

# PostgreSQL dependencies
yum install postgresql-server postgresql perl-DBD-Pg
</pre>
<p><em>For debian like system</em>:</p>
<pre class="literal-block">
# Build dependencies
apt-get install gcc make tar python-docutils

# Common dependencies
apt-get install perl perl-base openssh-client openssh-server libdbi-perl libsort-versions-perl

# MySQL dependencies
apt-get install mysql-server mysql-client libdbd-mysql-perl

# PostgreSQL dependencies
apt-get install postgresql-server postgresql-client libdbd-pg-perl
</pre>
<p><strong>Instructions</strong></p>
<p>Get the sources:</p>
<pre class="literal-block">
OAR_VERSION=2.5.2
curl http://oar-ftp.imag.fr/oar/2.5/sources/stable/oar-${OAR_VERSION}.tgz | tar xzvf -
cd oar-${OAR_VERSION}/
</pre>
<p>Build/Install/Setup the OAR server:</p>
<pre class="literal-block">
# build
make server-build
# install
make server-install
# setup
make server-setup
</pre>
</div>
<div class="section" id="id3">
<h3><a class="toc-backref" href="#id29">2.3.3&nbsp;&nbsp;&nbsp;Configuration</a></h3>
<div class="section" id="the-oar-database">
<h4><a class="toc-backref" href="#id30">2.3.3.1&nbsp;&nbsp;&nbsp;The oar database</a></h4>
<p>Define the database configuration in /etc/oar/oar.conf. You need to set the
variables <tt class="docutils literal">DB_TYPE, DB_HOSTNAME, DB_PORT, DB_BASE_NAME, DB_BASE_LOGIN,
DB_BASE_PASSWD, DB_BASE_LOGIN_RO, DB_BASE_PASSWD_RO</tt>:</p>
<pre class="literal-block">
vi /etc/oar/oar.conf
</pre>
<p>Create the database and the database users:</p>
<pre class="literal-block">
# General case
oar-database --create --db-admin-user &lt;ADMIN_USER&gt; --db-admin-pass &lt;ADMIN_PASS&gt;

# OR, for PostgreSQL, in case the database is installed locally
oar-database --create --db-is-local
</pre>
</div>
<div class="section" id="id4">
<h4><a class="toc-backref" href="#id31">2.3.3.2&nbsp;&nbsp;&nbsp;Init.d scripts</a></h4>
<p>If you have installed OAR from sources, you need to become root user and
install manually the init.d/default/sysconfig scripts present in the folders:</p>
<pre class="literal-block">
$PREFIX/share/doc/oar-server/examples/scripts/{init.d,default,sysconfig}
</pre>
<p>Then use the script <tt class="docutils literal"><span class="pre">/etc/init.d/oar-server</span></tt> to start the OAR server daemon.</p>
</div>
<div class="section" id="adding-resources-to-the-system">
<h4><a class="toc-backref" href="#id32">2.3.3.3&nbsp;&nbsp;&nbsp;Adding resources to the system</a></h4>
<p>If you want to <strong>automatically</strong> initialize your cluster then you just need to
launch <tt class="docutils literal">oar_resources_init</tt>. It will detect the resources from the nodes that
you put in a file and store right OAR commands to initialize the database with
the appropriate values for the memory and the cpuset properties. Just try...</p>
<p>There is also a tool to help you managing your oar resources and admission
rules : <tt class="docutils literal">oaradmin</tt>.
Take a look at the oaradmin documentation in the administrator commands section
for more details. You can also read this tips:</p>
<pre class="literal-block">
http://oar.imag.fr/archive/wiki-oar/index.php/Customization_tips#Using_oaradmin_to_initiate_the_resources
</pre>
<p><em>Otherwise:</em></p>
<p>To add resources to your system, you can use (as root) the command oarnodesetting.
For a complete comprehension of what does this command, type man
oarnodesetting. For now, the two options you will need will be <strong>-a</strong> (means
add a resource) and <strong>-h</strong> (defines the resource hostname or ip adress).</p>
<p>For example, to add a computing resource on the node &lt;NODE_IP&gt; to OAR
installation, you can type:</p>
<pre class="literal-block">
oarnodesetting -a -h &lt;NODE_IP&gt;
</pre>
<p>This will add a resource with &lt;NODE_IP&gt; as host IP address.</p>
<p>You also can modify resources properties with <strong>-p</strong> option, for example:</p>
<pre class="literal-block">
oarnodesetting -r 1 -p &quot;deploy=YES&quot;
</pre>
<p>will allow the resource #1 to accept jobs of the type deploy.</p>
</div>
</div>
<div class="section" id="notes">
<h3><a class="toc-backref" href="#id33">2.3.4&nbsp;&nbsp;&nbsp;Notes</a></h3>
<div class="section" id="security-issues">
<h4><a class="toc-backref" href="#id34">2.3.4.1&nbsp;&nbsp;&nbsp;Security issues</a></h4>
<p>For security reasons it is hardly <strong>recommended</strong> to configure a read only
account for the OAR database (like the above example).  Thus you will be able
to add this data in DB_BASE_LOGIN_RO and DB_BASE_PASSWD_RO in <em>oar.conf</em>.</p>
</div>
<div class="section" id="postgresql-autovacuum">
<h4><a class="toc-backref" href="#id35">2.3.4.2&nbsp;&nbsp;&nbsp;PostgreSQL : autovacuum</a></h4>
<p>Be sure to activate the &quot;autovacuum&quot; feature in the &quot;postgresql.conf&quot; file (OAR
creates and deletes a lot of records and this setting cleans the postgres
database from unneeded records).</p>
</div>
<div class="section" id="postgresql-authentication">
<h4><a class="toc-backref" href="#id36">2.3.4.3&nbsp;&nbsp;&nbsp;PostgreSQL : authentication</a></h4>
<p>In case you've installed a PostgreSQL database remotly, if your PostgreSQL
installation doesn't authorize the local connections by default, you need to
enable the connections to this database for the oar users. Supposing the OAR
server has the address &lt;OAR_SERVER&gt;, you can add the following lines in the
<tt class="docutils literal">pg_hba.conf</tt>:</p>
<blockquote>
<dl class="docutils">
<dt># in /etc/postgresql/8.1/main/pg_hba.conf or /var/lib/pgsql/data/pg_hba.conf</dt>
<dd>host    oar         oar_ro            &lt;OAR_SERVER&gt;/32    md5
host    oar         oar               &lt;OAR_SERVER&gt;/32    md5</dd>
</dl>
</blockquote>
</div>
<div class="section" id="about-x11-usage-in-oar">
<h4><a class="toc-backref" href="#id37">2.3.4.4&nbsp;&nbsp;&nbsp;About X11 usage in OAR</a></h4>
<p>The easiest and scalable way to use X11 application on cluster nodes is to open
X11 ports and set the right DISPLAY environment variable by hand.  Otherwise
users can use X11 forwarding via ssh to access cluster frontal. After that you
must configure ssh server on this frontal with</p>
<pre class="literal-block">
X11Forwarding yes
X11UseLocalhost no
</pre>
<p>With this configuration, users can launch X11 applications after a 'oarsub -I'
on the given node or &quot;oarsh -X node12&quot;.</p>
</div>
<div class="section" id="using-taktuk">
<h4><a class="toc-backref" href="#id38">2.3.4.5&nbsp;&nbsp;&nbsp;Using Taktuk</a></h4>
<p>If you want to use taktuk to manage remote administration commands, you have to
install it. You can find information about taktuk from its website:
<a class="reference external" href="http://taktuk.gforge.inria.fr">http://taktuk.gforge.inria.fr</a>.</p>
<p><strong>Note</strong>: Taktuk is scalable remote command execution without the need to
install special stuffs on nodes. So it is very useful to administer a large
amount of server.</p>
<p>Then, you have to edit your oar configuration file and to fill in the different
related parameters:</p>
<blockquote>
<ul class="simple">
<li>TAKTUK_CMD (the path to the taktuk command)</li>
<li>PINGCHECKER_TAKTUK_ARG_COMMAND (the command used to check resources states)</li>
<li>SCHEDULER_NODE_MANAGER_SLEEP_CMD (command used for halting nodes)</li>
</ul>
</blockquote>
</div>
<div class="section" id="cpuset-feature">
<h4><a class="toc-backref" href="#id39">2.3.4.6&nbsp;&nbsp;&nbsp;CPUSET feature</a></h4>
<p>OAR uses the CPUSET features provided with the Linux kernel &gt;= 2.6. This
enables to restrict user processes only on reserved processors and to clean
correctly the nodes after the end of the jobs.</p>
<p>For more information, look at the CPUSET file.</p>
</div>
<div class="section" id="energy-saving">
<h4><a class="toc-backref" href="#id40">2.3.4.7&nbsp;&nbsp;&nbsp;Energy saving</a></h4>
<p>Starting with version 2.4.3, OAR provides a module responsible of advanced
management of wake-up/shut-down of nodes when they are not used.
To activate this feature, you have to:</p>
<blockquote>
<ul class="simple">
<li>provide 2 commands or scripts which will be executed on the oar server
to shutdown (or set into standby) some nodes and to wake-up some nodes
(configure the path of those commands into the
ENERGY_SAVING_NODE_MANAGER_WAKE_UP_CMD and
ENERGY_SAVING_NODE_MANAGER_SHUT_DOWN_CMD variables into oar.conf)</li>
<li>configure the &quot;available_upto&quot; property of all your nodes:<ul>
<li>available_upto=0           : to disable the wake-up and halt</li>
<li>available_upto=1           : to disable the wake-up (but not the halt)</li>
<li>available_upto=2147483647  : to disable the halt (but not the wake-up)</li>
<li>available_upto=2147483646  : to enable wake-up/halt forever</li>
<li>available_upto=&lt;timestamp&gt; : to enable the halt, and the wake-up until
the date given by &lt;timestamp&gt;</li>
</ul>
</li>
<li>activate the energy saving module by setting ENERGY_SAVING_INTERNAL=&quot;yes&quot;
and configuring the ENERGY_* variables into oar.conf</li>
<li>configure the metascheduler time values into SCHEDULER_NODE_MANAGER_IDLE_TIME,
SCHEDULER_NODE_MANAGER_SLEEP_TIME and SCHEDULER_NODE_MANAGER_WAKEUP_TIME
variables of the oar.conf file.</li>
<li>restart the oar server (you should see an &quot;Almighty&quot; process more).</li>
</ul>
</blockquote>
<p>You need to restart OAR each time you change an ENERGY_* variable.
More informations are available inside the oar.conf file itself. For more
details about the mechanism, take a look at the &quot;Hulot&quot; module documentation.</p>
</div>
<div class="section" id="disabling-selinux">
<h4><a class="toc-backref" href="#id41">2.3.4.8&nbsp;&nbsp;&nbsp;Disabling SELinux</a></h4>
<p>On some distributions, SELinux is enabled by default. There is currently no OAR
support for SELinux. So, you need to disable SELinux, if enabled.</p>
</div>
<div class="section" id="intel-cpuset-id-issue">
<h4><a class="toc-backref" href="#id42">2.3.4.9&nbsp;&nbsp;&nbsp;Intel cpuset id issue</a></h4>
<p>The cpuset ids on an intel platform are not persistent across reboot. So you need
to update the cpuset ids in the resource database at startup for each computing
node. You can do this by using the <tt class="docutils literal">/etc/oar/update_cpuset_id.sh</tt> script. The
following page give more informations on how configuring it:</p>
<blockquote>
<a class="reference external" href="http://oar.imag.fr/archive/wiki-oar/index.php/Configuration_tips#Start.2Fstop_of_nodes_using_ssh_keys">http://oar.imag.fr/archive/wiki-oar/index.php/Configuration_tips#Start.2Fstop_of_nodes_using_ssh_keys</a></blockquote>
</div>
<div class="section" id="other-issues">
<h4><a class="toc-backref" href="#id43">2.3.4.10&nbsp;&nbsp;&nbsp;Other issues</a></h4>
<p>You can take a look at the &quot;Customizaion tips&quot; on the OAR Wiki:</p>
<blockquote>
<a class="reference external" href="http://oar.imag.fr/archive/wiki-oar/index.php/Customization_tips">http://oar.imag.fr/archive/wiki-oar/index.php/Customization_tips</a></blockquote>
</div>
</div>
</div>
<div class="section" id="frontend-nodes">
<h2><a class="toc-backref" href="#id44">2.4&nbsp;&nbsp;&nbsp;Frontend nodes</a></h2>
<div class="section" id="id5">
<h3><a class="toc-backref" href="#id45">2.4.1&nbsp;&nbsp;&nbsp;Installation from the packages</a></h3>
<p><strong>Instructions</strong></p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Add the epel repository (choose the right version depending on your operating system)
rpm -i http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-5.noarch.rpm

# Add the oar repository
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/oar.repo
[oar]
name=OAR Packages for Enterprise Linux 6 - \$basearch
baseurl=http://oar-ftp.imag.fr/oar/2.5/rpm/stable/
enabled=1
gpgcheck=0
EOF

# Install OAR user for the PostgreSQL backend
yum install oar-user oar-user-pgsql

# or Install OAR user for the MySQL backend
yum install oar-user oar-user-mysql
</pre>
<p><em>For the debian like systems</em>:</p>
<pre class="literal-block">
# Add the OAR repository (choose the right one. See http://oar.imag.fr/repositories/)
echo &quot;deb http://oar-ftp.imag.fr/oar/2.5/debian squeeze main&quot; &gt; /etc/apt/sources.list.d/oar.list
curl http://oar-ftp.imag.fr/oar/oarmaster.asc | sudo apt-key add -
apt-get update

# Install OAR server for the PostgreSQL backend
apt-get install oar-user oar-user-pgsql

# or Install OAR server for the MySQL backend
apt-get install oar-user oar-user-mysql
</pre>
</div>
<div class="section" id="id6">
<h3><a class="toc-backref" href="#id46">2.4.2&nbsp;&nbsp;&nbsp;Installation from the tarball</a></h3>
<p><strong>Requirements</strong></p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Build dependencies
yum install gcc make tar python-docutils

# Common dependencies
yum install Perl Perl-base openssh Perl-DBI

# MySQL dependencies
yum install mysql perl-DBD-MySQL

# PostgreSQL dependencies
yum install postgresql perl-DBD-Pg
</pre>
<p><em>For debian like system</em>:</p>
<pre class="literal-block">
# Build dependencies
apt-get install gcc make tar python-docutils

# Common dependencies
apt-get install perl perl-base openssh-client openssh-server libdbi-perl

# MySQL dependencies
apt-get install mysql-client libdbd-mysql-perl

# PostgreSQL dependencies
apt-get install postgresql-client libdbd-pg-perl
</pre>
<p><strong>Instructions</strong></p>
<p>Get the sources:</p>
<pre class="literal-block">
OAR_VERSION=2.5.2
curl http://oar-ftp.imag.fr/oar/2.5/sources/stable/oar-${OAR_VERSION}.tgz | tar xzvf -
cd oar-${OAR_VERSION}/
</pre>
<p>Build/Install/setup:</p>
<pre class="literal-block">
# build
make user-build
# install
make user-install
# setup
make user-setup
</pre>
</div>
<div class="section" id="id7">
<h3><a class="toc-backref" href="#id47">2.4.3&nbsp;&nbsp;&nbsp;Configuration</a></h3>
<div class="section" id="coherent-configuration-files-between-server-node-and-user-nodes">
<h4><a class="toc-backref" href="#id48">2.4.3.1&nbsp;&nbsp;&nbsp;Coherent configuration files between server node and user nodes</a></h4>
<p>You need to have a coherent oar configuration between the server node and the
user nodes. So you can just copy the /etc/oar directory from to server node to
the user nodes.</p>
</div>
</div>
<div class="section" id="oar-restful-api-installation">
<h3><a class="toc-backref" href="#id49">2.4.4&nbsp;&nbsp;&nbsp;OAR RESTful API Installation</a></h3>
<p>Since the version 2.5.2, OAR offers an API for users and admins interactions. This api
must be installed on a frontend node (with the user module installed).</p>
<div class="section" id="from-the-packaging">
<h4><a class="toc-backref" href="#id50">2.4.4.1&nbsp;&nbsp;&nbsp;From the packaging</a></h4>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Add the oar repository
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/oar.repo
[oar]
name=OAR Packages for Enterprise Linux 6 - \$basearch
baseurl=http://oar-ftp.imag.fr/oar/2.5/rpm/stable/
enabled=1
gpgcheck=0
EOF

# Install apache FastCGI module (optional but highly recommended)
FIXME:

# Install OAR Restful api
yum install oar-restful-api
</pre>
<p><em>For the debian like systems</em>:</p>
<pre class="literal-block">
# Add the OAR repository (choose the right one. See http://oar.imag.fr/repositories/)
echo &quot;deb http://oar-ftp.imag.fr/oar/2.5/debian squeeze main&quot; &gt; /etc/apt/sources.list.d/oar.list
curl http://oar-ftp.imag.fr/oar/oarmaster.asc | sudo apt-key add -
apt-get update

# Install apache FastCGI module (optional but highly recommended)
apt-get install libapache2-mod-fastcgi

# Install OAR Restful api
apt-get install oar-restful-api
</pre>
</div>
<div class="section" id="from-the-sources">
<h4><a class="toc-backref" href="#id51">2.4.4.2&nbsp;&nbsp;&nbsp;From the sources</a></h4>
<p><strong>Requirements</strong>:</p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Build dependencies
yum install gcc make tar python-docutils

# Common dependencies
yum install perl perl-base perl-DBI perl-CGI perl-JSON perl-YAML perl-libwww-perl httpd

# FastCGI dependency (optional but highly recommended)
FIXME:

# MySQL dependencies
yum install mysql perl-DBD-MySQL

# PostgreSQL dependencies
yum install postgresql perl-DBD-Pg
</pre>
<p><em>For debian like system</em>:</p>
<pre class="literal-block">
# Build dependencies
apt-get install gcc make tar python-docutils

# Common dependencies
apt-get install perl perl-base libdbi-perl libjson-perl libyaml-perl libwww-perl httpd-cgi libcgi-fast-perl

# FastCGI dependency (optional but highly recommended)
apt-get install libapache2-mod-fastcgi

# MySQL dependencies
apt-get install mysql-server mysql-client libdbd-mysql-perl

# PostgreSQL dependencies
apt-get install postgresql-server postgresql-client libdbd-pg-perl
</pre>
<p><strong>Instructions</strong></p>
<p>Get the sources:</p>
<pre class="literal-block">
OAR_VERSION=2.5.2
curl http://oar-ftp.imag.fr/oar/2.5/sources/stable/oar-${OAR_VERSION}.tgz | tar xzvf -
cd oar-${OAR_VERSION}/
</pre>
<p>build/install/setup:</p>
<pre class="literal-block">
# build
make api-build
# install
make api-install
# setup
make api-setup
</pre>
</div>
<div class="section" id="id8">
<h4><a class="toc-backref" href="#id52">2.4.4.3&nbsp;&nbsp;&nbsp;Configuration</a></h4>
<p><em>Configuring OAR</em></p>
<blockquote>
For the moment, the API needs the user tools to be installed on the same host
('<tt class="docutils literal">make <span class="pre">user-install</span></tt>' or oar-user package). A suitable <tt class="docutils literal">/etc/oar/oar.conf</tt> should
be present. For the API to work, you should have the oarstat/oarnodes/oarsub
commands to work (on the same host you installed the API)</blockquote>
<p><em>Configuring Apache</em></p>
<blockquote>
<p>The api provides a default configuration file (<tt class="docutils literal"><span class="pre">/etc/oar/apache-api.conf</span></tt>) that
is using a identd user identification enabled only from localhost.  Edit the
<tt class="docutils literal"><span class="pre">/etc/oar/apache-api.conf</span></tt> file and customize it to reflect the authentication
mechanism you want to use. For ident, you may have to install a &quot;identd&quot; daemon
on your distrib. The steps may be:</p>
<blockquote>
<ul class="simple">
<li>Install and run an identd daemon on your server (like <em>pidentd</em>).</li>
<li>Activate the ident auth mechanism into apache (<tt class="docutils literal">a2enmod ident</tt>).</li>
<li>Activate the headers apache module (<tt class="docutils literal">a2enmod headers</tt>).</li>
<li>Activate the rewrite apache module (<tt class="docutils literal">a2enmod rewrite</tt>).</li>
<li>Customize apache-api.conf to allow the hosts you trust for ident.</li>
</ul>
</blockquote>
</blockquote>
<p><em>YAML, JSON, XML</em></p>
<blockquote>
You need at least one of the YAML or JSON perl module to be installed on the host running the API.</blockquote>
<p><em>Test</em></p>
<blockquote>
<p>You may test the API with a simple wget:</p>
<pre class="literal-block">
wget -O - http://localhost/oarapi/resources.html
</pre>
<p>It should give you the list of resources in the yaml format but enclosed in an
html page.  To test if the authentication works, you need to post a new job.
See the example.txt file that gives you example queries with a ruby rest
client.</p>
</blockquote>
</div>
</div>
</div>
<div class="section" id="visualization-node">
<h2><a class="toc-backref" href="#id53">2.5&nbsp;&nbsp;&nbsp;Visualization node</a></h2>
<div class="section" id="description">
<h3><a class="toc-backref" href="#id54">2.5.1&nbsp;&nbsp;&nbsp;Description</a></h3>
<p>There are two different tools. One, named Monika which displays the current
cluster state with all active and waiting jobs. The other, named drawgantt
which displays node occupation in a lapse of time. These tools are CGI scripts
and generate HTML pages.</p>
</div>
<div class="section" id="id9">
<h3><a class="toc-backref" href="#id55">2.5.2&nbsp;&nbsp;&nbsp;Installation from the packages</a></h3>
<p><strong>Instructions</strong></p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Add the oar repository
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/oar.repo
[oar]
name=OAR Packages for Enterprise Linux 6 - \$basearch
baseurl=http://oar-ftp.imag.fr/oar/2.5/rpm/stable/
enabled=1
gpgcheck=0
EOF

yum install oar-web-status
</pre>
<p><em>For the debian like systems</em>:</p>
<pre class="literal-block">
# Add the OAR repository (choose the right one. See http://oar.imag.fr/repositories/)
echo &quot;deb http://oar-ftp.imag.fr/oar/2.5/debian squeeze main&quot; &gt; /etc/apt/sources.list.d/oar.list
curl http://oar-ftp.imag.fr/oar/oarmaster.asc | sudo apt-key add -
apt-get update

apt-get install oar-web-status
</pre>
</div>
<div class="section" id="id10">
<h3><a class="toc-backref" href="#id56">2.5.3&nbsp;&nbsp;&nbsp;Installation from the tarball</a></h3>
<p><strong>Requirements</strong>:</p>
<p><em>For redhat like systems</em>:</p>
<pre class="literal-block">
# Build dependencies
yum install gcc make tar python-docutils

# Common dependencies
yum install perl perl-base perl-DBI ruby-GD ruby-DBI perl-Tie-IxHash perl-Sort-Naturally perl-AppConfig

# MySQL dependencies
yum install mysql perl-DBD-MySQL ruby-mysql

# PostgreSQL dependencies
yum install postgresql perl-DBD-Pg ruby-pg
</pre>
<p><em>For debian like system</em>:</p>
<pre class="literal-block">
# Build dependencies
apt-get install gcc make tar python-docutils

# Common dependencies
apt-get install perl perl-base ruby libgd-ruby1.8 libdbi-perl libtie-ixhash-perl libappconfig-perl libsort-naturally-perl

# MySQL dependencies
apt-get install libdbd-mysql-perl libdbd-mysql-ruby

# PostgreSQL dependencies
apt-get install libdbd-pg-perl libdbd-pg-ruby
</pre>
<p><strong>Instructions</strong></p>
<p>Get the sources:</p>
<pre class="literal-block">
OAR_VERSION=2.5.2
curl http://oar-ftp.imag.fr/oar/2.5/sources/stable/oar-${OAR_VERSION}.tgz | tar xzvf -
cd oar-${OAR_VERSION}/
</pre>
<p>build/install/setup:</p>
<pre class="literal-block">
# build
make monika-build draw-gantt-build www-conf-build
# install
make monika-install draw-gantt-install www-conf-install
# setup
make monika-setup draw-gantt-setup www-conf-setup
</pre>
</div>
<div class="section" id="id11">
<h3><a class="toc-backref" href="#id57">2.5.4&nbsp;&nbsp;&nbsp;Configuration</a></h3>
<p><strong>Drawgantt configuration</strong></p>
<blockquote>
<ul class="simple">
<li>Edit <tt class="docutils literal">/etc/oar/drawgantt.conf</tt> to fit your configuration.</li>
</ul>
</blockquote>
<p><strong>Monika configuration</strong></p>
<blockquote>
<ul class="simple">
<li>Edit <tt class="docutils literal">/etc/oar/monika.conf</tt> to fit your configuration.</li>
</ul>
</blockquote>
<p><strong>httpd configuration</strong></p>
<blockquote>
<ul class="simple">
<li>You need to edit <tt class="docutils literal">/etc/oar/apache.conf</tt> to fit your needs and verify that you
http server configured.</li>
</ul>
</blockquote>
</div>
</div>
<div class="section" id="further-informations">
<h2><a class="toc-backref" href="#id58">2.6&nbsp;&nbsp;&nbsp;Further informations</a></h2>
<p>For further information, please check the documentation section on the OAR
website <a class="reference external" href="http://oar.imag.fr/">http://oar.imag.fr/</a>.</p>
</div>
</div>
<div class="section" id="security-aspects-in-oar">
<h1><a class="toc-backref" href="#id59">3&nbsp;&nbsp;&nbsp;Security aspects in OAR</a></h1>
<p>In OAR2, security and user switching is managed by the &quot;oardodo&quot; script.
It is a suid script executable only by root and the oar group members that
is used to launch a command, a terminal or a script with
the privileges of a particular user.
When &quot;oardodo&quot; is called, it checks the value of an environment variable:
OARDO_BECOME_USER.</p>
<blockquote>
<ul class="simple">
<li>If this variable is empty, &quot;oardodo&quot; will execute the command with the
privileges of the superuser (root).</li>
<li>Else, this variable contains the name of the user that will be used to
execute the command.</li>
</ul>
</blockquote>
<p>Here are the scripts/modules where &quot;oardodo&quot; is called and which user is used
during this call:</p>
<blockquote>
<ul>
<li><dl class="first docutils">
<dt>OAR::Modules::Judas:</dt>
<dd><p class="first last">this module is used for logging and notification.</p>
</dd>
</dl>
<ul class="simple">
<li>user notification: email or command execution.OARDO_BECOME_USER = user</li>
</ul>
</li>
<li><dl class="first docutils">
<dt>oarsub:</dt>
<dd><p class="first last">this script is used for submitting jobs or reservations.</p>
</dd>
</dl>
<ul>
<li><p class="first">read user script</p>
</li>
<li><p class="first">connection to the job and the remote shell</p>
</li>
<li><p class="first">keys management</p>
</li>
<li><p class="first">job key export</p>
<blockquote>
<p>for all these functions, the user used in the OARDO_BECOME_USER variable is
the user that submits the job.</p>
</blockquote>
</li>
</ul>
</li>
<li><dl class="first docutils">
<dt>pingchecker:</dt>
<dd><p class="first last">this module is used to check resources health. Here, the user is root.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>oarexec:</dt>
<dd><p class="first last">executed on the first reserved node, oarexec executes the job prologue and
initiate the job.</p>
</dd>
</dl>
<ul class="simple">
<li>the &quot;clean&quot; method kills every oarsub connection process in superuser mode</li>
<li>&quot;kill_children&quot; method kills every child of the process in superuser mode</li>
<li>execution of a passive job in user mode</li>
<li>getting of the user shell in user mode</li>
<li>checkpointing in superuser mode</li>
</ul>
</li>
<li><dl class="first docutils">
<dt>job_resource_manager:</dt>
<dd><p class="first last">The job_resource_manager script is a perl script that oar server deploys on
nodes to manage cpusets, users, job keys...</p>
</dd>
</dl>
<ul class="simple">
<li>cpuset creation and clean is executed in superuser mode</li>
</ul>
</li>
<li><dl class="first docutils">
<dt>oarsh_shell:</dt>
<dd><p class="first last">shell program used with the oarsh script. It adds its own process in the
cpuset and launches the shell or the script of the user.</p>
</dd>
</dl>
<ul class="simple">
<li>cpuset filling, &quot;nice&quot; and display management are executed as root.</li>
<li>TTY login is executed as user.</li>
</ul>
</li>
<li><dl class="first docutils">
<dt>oarsh:</dt>
<dd><p class="first last">oar's ssh wrapper to connect from node to node. It contains all the context
variables usefull for this connection.</p>
</dd>
</dl>
<ul>
<li><dl class="first docutils">
<dt>display management and connection with a user job key file are executed</dt>
<dd><p class="first last">as user.</p>
</dd>
</dl>
</li>
</ul>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="administrator-commands">
<h1><a class="toc-backref" href="#id60">4&nbsp;&nbsp;&nbsp;Administrator commands</a></h1>
<div class="section" id="oarproperty">
<h2><a class="toc-backref" href="#id61">4.1&nbsp;&nbsp;&nbsp;<em>oarproperty</em></a></h2>
<p>This command manages OAR resource properties stored in the database.</p>
<p>Options are:</p>
<pre class="literal-block">
-l : list properties
-a NAME : add a property
  -c : sql new field of type VARCHAR(255) (default is integer)
-d NAME : delete a property
-r &quot;OLD_NAME,NEW_NAME&quot; : rename property OLD_NAME into NEW_NAME
</pre>
<p>Examples:</p>
<pre class="literal-block">
# oarproperty -a cpu_freq
# oarproperty -a type
# oarproperty -r &quot;cpu_freq,freq&quot;
</pre>
</div>
<div class="section" id="oarnodesetting">
<h2><a class="toc-backref" href="#id62">4.2&nbsp;&nbsp;&nbsp;<em>oarnodesetting</em></a></h2>
<p>This command permits to change the state or a property of a node or of several
resources resources.</p>
<p>By default the node name used by <a class="reference internal" href="#oarnodesetting">oarnodesetting</a> is the result of the command
<em>hostname</em>.</p>
<p>Options are:</p>
<pre class="literal-block">
-a    : add a new resource
-s    : state to assign to the node:
        * &quot;Alive&quot; : a job can be run on the node.
        * &quot;Absent&quot; : administrator wants to remove the node from the pool
           for a moment.
        * &quot;Dead&quot; : the node will not be used and will be deleted.
-h    : specify the node name (override hostname).
-r    : specify the resource number
--sql : get resource identifiers which respond to the
        SQL where clause on the table jobs
        (ex: &quot;type = 'default'&quot;)
-p    : change the value of a property specified resources.
-n    : specify this option if you do not want to wait the end of jobs running
        on this node when you change its state into &quot;Absent&quot; or &quot;Dead&quot;.
</pre>
</div>
<div class="section" id="oaradmin">
<h2><a class="toc-backref" href="#id63">4.3&nbsp;&nbsp;&nbsp;<em>oaradmin</em></a></h2>
<p>This command permits to create resources and manage admission rules easily. An optional feature permits versioning changes in admission rules and conf files.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Requirements:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
<p>For oaradmin, the following packages must be installed:</p>
<blockquote>
<ul class="simple">
<li>Perl-Yaml</li>
<li>Ruby 1.8 or greater</li>
<li>Ruby-Yaml</li>
<li>Ruby-DBI</li>
<li>Subversion for the optional versioning feature</li>
</ul>
</blockquote>
<p>Options for resources subcommand are:</p>
<pre class="literal-block">
-a, --add                        Add new resources
    --cpusetproperty=prop        Property name for cpuset numbers
-s, --select                     Select resources for update
-p, --property                   Set value for a property
-d, --delete                     Delete resources
-c, --commit                     Commit in oar database
</pre>
<p>Examples:</p>
<pre class="literal-block">
# oaradmin resources -a /node=mycluster{12}.domain/cpu={2}/core={2}
# oaradmin resources -a /node=mycluster-[1-250].domain/cpu={2}
# oaradmin resources -a /node=mycluster-[1-250].domain/cpu={2} -p memnode=1024 -p cpufreq=3.2 -p cputype=xeon
</pre>
<p>Options for rules subcommand are:</p>
<pre class="literal-block">
-l, --list                       List admission rules
-a, --add                        Add an admission rule
-f, --file                       File which contains script for admission rule
-d, --delete                     Delete admission rules
-x, --export                     Export admission rules
-e, --edit                       Edit an admission rule
-1, --enable                     Enable the admission rule (removing comments)
-0, --disable                    Disable the admission rule (commenting the code)
-H, --history                    Show all changes made on the admission rule
-R, --revert                     Revert to the admission rule as it existed in a revision number
</pre>
<p>Examples:</p>
<pre class="literal-block">
# oaradmin rules -l
# oaradmin rules -lll 3
# oaradmin rules -e 3
</pre>
<p>Options for conf subcommand are:</p>
<pre class="literal-block">
-e, --edit                       Edit the conf file
-H, --history                    Show all changes made on the conf file
-R, --revert                     Revert to the conf file as it existed in a revision number
</pre>
<p>Examples:</p>
<pre class="literal-block">
# oaradmin conf -e /etc/oar/oar.conf
# oaradmin conf -R /etc/oar/oar.conf 3
</pre>
</div>
<div class="section" id="oarremoveresource">
<h2><a class="toc-backref" href="#id64">4.4&nbsp;&nbsp;&nbsp;<em>oarremoveresource</em></a></h2>
<p>This command permits to remove a resource from the database.</p>
<p>The node must be in the state &quot;Dead&quot; (use <a class="reference internal" href="#oarnodesetting">oarnodesetting</a> to do this) and then
you can use this command to delete it.</p>
</div>
<div class="section" id="oaraccounting">
<h2><a class="toc-backref" href="#id65">4.5&nbsp;&nbsp;&nbsp;<em>oaraccounting</em></a></h2>
<p>This command permits to update the <a class="reference internal" href="#accounting">accounting</a> table for jobs ended since the
last launch.</p>
<p>Option &quot;--reinitialize&quot; removes everything in the <a class="reference internal" href="#accounting">accounting</a> table and
switches the &quot;accounted&quot; field of the table <a class="reference internal" href="#jobs">jobs</a> into &quot;NO&quot;. So when you will
launch the <a class="reference internal" href="#oaraccounting">oaraccounting</a> command again, it will take the whole jobs.</p>
<p>Option &quot;--delete_before&quot; removes records from the <a class="reference internal" href="#accounting">accounting</a> table that are
older than the amount of time specified. So if the table becomes too big you
can shrink old data; for example:</p>
<pre class="literal-block">
oaraccounting --delete_before 2678400
</pre>
<p>(Remove everything older than 31 days)</p>
</div>
<div class="section" id="oarnotify">
<h2><a class="toc-backref" href="#id66">4.6&nbsp;&nbsp;&nbsp;<em>oarnotify</em></a></h2>
<p>This command sends commands to the <a class="reference internal" href="#almighty">Almighty</a> module and manages scheduling
queues.</p>
<p>Option are:</p>
<pre class="literal-block">
    Almighty_tag    send this tag to the Almighty (default is TERM)
-e                  active an existing queue
-d                  inactive an existing queue
-E                  active all queues
-D                  inactive all queues
--add_queue         add a new queue; syntax is name,priority,scheduler
                    (ex: &quot;name,3,oar_sched_gantt_with_timesharing&quot;
--remove_queue      remove an existing queue
-l                  list all queues and there status
-h                  show this help screen
-v                  print OAR version number
</pre>
</div>
<div class="section" id="oarmonitor">
<h2><a class="toc-backref" href="#id67">4.7&nbsp;&nbsp;&nbsp;<em>oarmonitor</em></a></h2>
<p>This command collects monitoring data from compute nodes and stores them into
the database.</p>
<p>The <a class="reference internal" href="#taktuk-cmd">TAKTUK_CMD</a> is mandatory in the <em>oar.conf</em> and data comes from the sensor
file <a class="reference internal" href="#oarmonitor-sensor-file">OARMONITOR_SENSOR_FILE</a> (parse <em>/proc</em> filesystem for example) and print
it in the right way.</p>
<p>For example, the user &quot;oar&quot; or &quot;root&quot; can run the following command on the
server:</p>
<blockquote>
oarmonitor -j 4242 -f 10</blockquote>
<p>(Retrieve data from compute nodes of the job 4242 every 10 seconds and store
them into database tables monitoring_*)</p>
<p>For now, there is just a very minimalist command for the user to view these
data. It creates PNG images and a movie...</p>
<blockquote>
oarmonitor_graph_gen.pl -j 4242</blockquote>
<p>Then the user can look into the directory <em>OAR.1653.monitoring</em> in the current
directory.</p>
</div>
</div>
<div class="section" id="database-scheme">
<h1><a class="toc-backref" href="#id68">5&nbsp;&nbsp;&nbsp;Database scheme</a></h1>
<div class="figure">
<a class="reference external image-reference" href="../schemas/db_scheme.svg"><img alt="Database scheme" src="../schemas/db_scheme.png" /></a>
<p class="caption">Database scheme
(red lines seem PRIMARY KEY,
blue lines seem INDEX)</p>
</div>
<p>Note : all dates and duration are stored in an integer manner (number of
seconds since the EPOCH).</p>
<div class="section" id="accounting">
<h2><a class="toc-backref" href="#id69">5.1&nbsp;&nbsp;&nbsp;<em>accounting</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="26%" />
<col width="51%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>window_start</td>
<td>INT UNSIGNED</td>
<td>start date of the accounting interval</td>
</tr>
<tr><td>window_stop</td>
<td>INT UNSIGNED</td>
<td>stop date of the accounting interval</td>
</tr>
<tr><td>accounting_user</td>
<td>VARCHAR(20)</td>
<td>user name</td>
</tr>
<tr><td>accounting_project</td>
<td>VARCHAR(255)</td>
<td>name of the related project</td>
</tr>
<tr><td>queue_name</td>
<td>VARCHAR(100)</td>
<td>queue name</td>
</tr>
<tr><td>consumption_type</td>
<td>ENUM(&quot;ASKED&quot;,
&quot;USED&quot;)</td>
<td>&quot;ASKED&quot; corresponds to the walltimes
specified by the user. &quot;USED&quot;
corresponds to the effective time
used by the user.</td>
</tr>
<tr><td>consumption</td>
<td>INT UNSIGNED</td>
<td>number of seconds used</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">window_start, window_stop, accounting_user, queue_name,
accounting_project, consumption_type</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">window_start, window_stop, accounting_user, queue_name,
accounting_project, consumption_type</td>
</tr>
</tbody>
</table>
<p>This table is a summary of the consumption for each user on each queue. This
increases the speed of queries about user consumptions and statistic
generation.</p>
<p>Data are inserted through the command <a class="reference internal" href="#oaraccounting">oaraccounting</a> (when a job is treated
the field <em>accounted</em> in table jobs is passed into &quot;YES&quot;). So it is possible to
regenerate this table completely in this way :</p>
<blockquote>
<ul>
<li><p class="first">Delete all data of the table:</p>
<pre class="literal-block">
DELETE FROM accounting;
</pre>
</li>
<li><p class="first">Set the field <em>accounted</em> in the table jobs to &quot;NO&quot; for each row:</p>
<pre class="literal-block">
UPDATE jobs SET accounted = &quot;NO&quot;;
</pre>
</li>
<li><p class="first">Run the <a class="reference internal" href="#oaraccounting">oaraccounting</a> command.</p>
</li>
</ul>
</blockquote>
<p>You can change the amount of time for each window : edit the oar configuration
file and change the value of the tag <a class="reference internal" href="#accounting-window">ACCOUNTING_WINDOW</a>.</p>
</div>
<div class="section" id="admission-rules">
<h2><a class="toc-backref" href="#id70">5.2&nbsp;&nbsp;&nbsp;<em>admission_rules</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>id</td>
<td>INT UNSIGNED</td>
<td>id number</td>
</tr>
<tr><td>rule</td>
<td>TEXT</td>
<td>rule written in Perl applied when a
job is going to be registered</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body"><em>None</em></td>
</tr>
</tbody>
</table>
<p>You can use these rules to change some values of some properties when a job is
submitted. So each admission rule is executed in the order of the id field and
it can set several variables. If one of them exits then the others will not
be evaluated and oarsub returns an error.</p>
<p>Some examples are better than a long description :</p>
<blockquote>
<ul>
<li><p class="first">Specify the default value for queue parameter</p>
<pre class="literal-block">
INSERT INTO admission_rules (rule) VALUES('
  if (not defined($queue_name)) {
      $queue_name=&quot;default&quot;;
  }
');
</pre>
</li>
<li><p class="first">Avoid users except oar to go in the admin queue</p>
<pre class="literal-block">
INSERT INTO admission_rules (rule) VALUES ('
  if (($queue_name eq &quot;admin&quot;) &amp;&amp; ($user ne &quot;oar&quot;)) {
    die(&quot;[ADMISSION RULE] Only oar user can submit jobs in the admin queue\\n&quot;);
  }
');
</pre>
</li>
<li><p class="first">Restrict the maximum of the walltime for interactive jobs</p>
<pre class="literal-block">
INSERT INTO admission_rules (rule) VALUES ('
  my $max_walltime = OAR::IO::sql_to_duration(&quot;12:00:00&quot;);
  if ($jobType eq &quot;INTERACTIVE&quot;){
    foreach my $mold (&#64;{$ref_resource_list}){
      if (
        (defined($mold-&gt;[1])) and
        ($max_walltime &lt; $mold-&gt;[1])
      ){
        print(&quot;[ADMISSION RULE] Walltime to big for an INTERACTIVE job so it is set to $max_walltime.\\n&quot;);
        $mold-&gt;[1] = $max_walltime;
      }
    }
  }
');
</pre>
</li>
<li><p class="first">Specify the default walltime</p>
<pre class="literal-block">
INSERT INTO admission_rules (rule) VALUES ('
  my $default_wall = OAR::IO::sql_to_duration(&quot;2:00:00&quot;);
  foreach my $mold (&#64;{$ref_resource_list}){
    if (!defined($mold-&gt;[1])){
      print(&quot;[ADMISSION RULE] Set default walltime to $default_wall.\\n&quot;);
      $mold-&gt;[1] = $default_wall;
    }
  }
');
</pre>
</li>
<li><p class="first">How to perform actions if the user name is in a file</p>
<pre class="literal-block">
INSERT INTO admission_rules (rule) VALUES ('
  open(FILE, &quot;/tmp/users.txt&quot;);
  while (($queue_name ne &quot;admin&quot;) and ($_ = &lt;FILE&gt;)){
    if ($_ =~ m/^\\s*$user\\s*$/m){
      print(&quot;[ADMISSION RULE] Change assigned queue into admin\\n&quot;);
      $queue_name = &quot;admin&quot;;
    }
  }
  close(FILE);
');
</pre>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="event-logs">
<h2><a class="toc-backref" href="#id71">5.3&nbsp;&nbsp;&nbsp;<em>event_logs</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>event_id</td>
<td>INT UNSIGNED</td>
<td>event identifier</td>
</tr>
<tr><td>type</td>
<td>VARCHAR(50)</td>
<td>event type</td>
</tr>
<tr><td>job_id</td>
<td>INT UNSIGNED</td>
<td>job related of the event</td>
</tr>
<tr><td>date</td>
<td>INT UNSIGNED</td>
<td>event date</td>
</tr>
<tr><td>description</td>
<td>VARCHAR(255)</td>
<td>textual description of the event</td>
</tr>
<tr><td>to_check</td>
<td>ENUM('YES', 'NO')</td>
<td>specify if the module <em>NodeChangeState</em>
must check this event to Suspect or not
some nodes</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">event_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">type, to_check</td>
</tr>
</tbody>
</table>
<p>The different event types are:</p>
<blockquote>
<ul class="simple">
<li>&quot;PING_CHECKER_NODE_SUSPECTED&quot; : the system detected via the module &quot;finaud&quot;
that a node is not responding.</li>
<li>&quot;PROLOGUE_ERROR&quot; : an error occurred during the execution of the job
prologue (exit code != 0).</li>
<li>&quot;EPILOGUE_ERROR&quot; : an error occurred during the execution of the job
epilogue (exit code != 0).</li>
<li>&quot;CANNOT_CREATE_TMP_DIRECTORY&quot; : OAR cannot create the directory where all
information files will be stored.</li>
<li>&quot;CAN_NOT_WRITE_NODE_FILE&quot; : the system was not able to write file which had
to contain the node list on the first node (<em>/tmp/OAR_job_id</em>).</li>
<li>&quot;CAN_NOT_WRITE_PID_FILE&quot; : the system was not able to write the file which
had to contain the pid of oarexec process on the first node
(<em>/tmp/pid_of_oarexec_for_job_id</em>).</li>
<li>&quot;USER_SHELL&quot; : the system was not able to get informations about the user
shell on the first node.</li>
<li>&quot;EXIT_VALUE_OAREXEC&quot; : the oarexec process terminated with an unknown exit
code.</li>
<li>&quot;SEND_KILL_JOB&quot; : signal that OAR has transmitted a kill signal to the
oarexec of the specified job.</li>
<li>&quot;LEON_KILL_BIPBIP_TIMEOUT&quot; : Leon module has detected that something wrong
occurred during the kill of a job and so kill the local <em>bipbip</em> process.</li>
<li>&quot;EXTERMINATE_JOB&quot; : Leon module has detected that something wrong occurred
during the kill of a job and so clean the database and terminate the job
artificially.</li>
<li>&quot;WORKING_DIRECTORY&quot; : the directory from which the job was submitted does
not exist on the node assigned by the system.</li>
<li>&quot;OUTPUT_FILES&quot; : OAR cannot write the output files (stdout and stderr) in
the working directory.</li>
<li>&quot;CANNOT_NOTIFY_OARSUB&quot; : OAR cannot notify the <cite>oarsub</cite> process for an
interactive job (maybe the user has killed this process).</li>
<li>&quot;WALLTIME&quot; : the job has reached its walltime.</li>
<li>&quot;SCHEDULER_REDUCE_NB_NODES_FOR_RESERVATION&quot; : this means that there is not
enough nodes for the reservation and so the scheduler do the best and
gives less nodes than the user wanted (this occurres when nodes become
Suspected or Absent).</li>
<li>&quot;BESTEFFORT_KILL&quot; : the job is of the type <em>besteffort</em> and was killed
because a normal job wanted the nodes.</li>
<li>&quot;FRAG_JOB_REQUEST&quot; : someone wants to delete a job.</li>
<li>&quot;CHECKPOINT&quot; : the checkpoint signal was sent to the job.</li>
<li>&quot;CHECKPOINT_ERROR&quot; : OAR cannot send the signal to the job.</li>
<li>&quot;CHECKPOINT_SUCCESS&quot; : system has sent the signal correctly.</li>
<li>&quot;SERVER_EPILOGUE_TIMEOUT&quot; : epilogue server script has time outed.</li>
<li>&quot;SERVER_EPILOGUE_EXIT_CODE_ERROR&quot; : epilogue server script did not return 0.</li>
<li>&quot;SERVER_EPILOGUE_ERROR&quot; : cannot find epilogue server script file.</li>
<li>&quot;SERVER_PROLOGUE_TIMEOUT&quot; : prologue server script has time outed.</li>
<li>&quot;SERVER_PROLOGUE_EXIT_CODE_ERROR&quot; : prologue server script did not return 0.</li>
<li>&quot;SERVER_PROLOGUE_ERROR&quot; : cannot find prologue server script file.</li>
<li>&quot;CPUSET_CLEAN_ERROR&quot; : OAR cannot clean correctly cpuset files for a job
on the remote node.</li>
<li>&quot;MAIL_NOTIFICATION_ERROR&quot; : a mail cannot be sent.</li>
<li>&quot;USER_MAIL_NOTIFICATION&quot; : user mail notification cannot be performed.</li>
<li>&quot;USER_EXEC_NOTIFICATION_ERROR&quot; : user script execution notification cannot
be performed.</li>
<li>&quot;BIPBIP_BAD_JOBID&quot; : error when retrieving informations about a running job.</li>
<li>&quot;BIPBIP_CHALLENGE&quot; : OAR is configured to detach jobs when they are launched
on compute nodes and the job return a bad challenge number.</li>
<li>&quot;RESUBMIT_JOB_AUTOMATICALLY&quot; : the job was automatically resubmitted.</li>
<li>&quot;WALLTIME&quot; : the job reached its walltime.</li>
<li>&quot;REDUCE_RESERVATION_WALLTIME&quot; : the reservation job was shrunk.</li>
<li>&quot;SSH_TRANSFER_TIMEOUT&quot; : node OAR part script was too long to transfer.</li>
<li>&quot;BAD_HASHTABLE_DUMP&quot; : OAR transfered a bad hashtable.</li>
<li>&quot;LAUNCHING_OAREXEC_TIMEOUT&quot; : oarexec was too long to initialize itself.</li>
<li>&quot;RESERVATION_NO_NODE&quot; : All nodes were detected as bad for the reservation
job.</li>
</ul>
</blockquote>
</div>
<div class="section" id="event-log-hostnames">
<h2><a class="toc-backref" href="#id72">5.4&nbsp;&nbsp;&nbsp;<em>event_log_hostnames</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>event_id</td>
<td>INT UNSIGNED</td>
<td>event identifier</td>
</tr>
<tr><td>hostname</td>
<td>VARCHAR(255)</td>
<td>name of the node where the event
has occured</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">event_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">hostname</td>
</tr>
</tbody>
</table>
<p>This table stores hostnames related to events like
&quot;PING_CHECKER_NODE_SUSPECTED&quot;.</p>
</div>
<div class="section" id="files">
<h2><a class="toc-backref" href="#id73">5.5&nbsp;&nbsp;&nbsp;<em>files</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>idFile</td>
<td>INT UNSIGNED</td>
<td>&nbsp;</td>
</tr>
<tr><td>md5sum</td>
<td>VARCHAR(255)</td>
<td>&nbsp;</td>
</tr>
<tr><td>location</td>
<td>VARCHAR(255)</td>
<td>&nbsp;</td>
</tr>
<tr><td>method</td>
<td>VARCHAR(255)</td>
<td>&nbsp;</td>
</tr>
<tr><td>compression</td>
<td>VARCHAR(255)</td>
<td>&nbsp;</td>
</tr>
<tr><td>size</td>
<td>INT UNSIGNED</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">idFile</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">md5sum</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="frag-jobs">
<h2><a class="toc-backref" href="#id74">5.6&nbsp;&nbsp;&nbsp;<em>frag_jobs</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="35%" />
<col width="44%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>frag_id_job</td>
<td>INT UNSIGNED</td>
<td>job id</td>
</tr>
<tr><td>frag_date</td>
<td>INT UNSIGNED</td>
<td>kill job decision date</td>
</tr>
<tr><td>frag_state</td>
<td>ENUM('LEON', 'TIMER_ARMED'
, 'LEON_EXTERMINATE',
'FRAGGED')
DEFAULT 'LEON'</td>
<td>state to tell Leon what to do</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">frag_id_job</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">frag_state</td>
</tr>
</tbody>
</table>
<p>What do these states mean:</p>
<blockquote>
<ul class="simple">
<li>&quot;LEON&quot; : the Leon module must try to kill the job and change the state into
&quot;TIMER_ARMED&quot;.</li>
<li>&quot;TIMER_ARMED&quot; : the Sarko module must wait a response from the job during
a timeout (default is 60s)</li>
<li>&quot;LEON_EXTERMINATE&quot; : the Sarko module has decided that the job time outed and
asked Leon to clean up the database.</li>
<li>&quot;FRAGGED&quot; : job is fragged.</li>
</ul>
</blockquote>
</div>
<div class="section" id="gantt-jobs-resources">
<h2><a class="toc-backref" href="#id75">5.7&nbsp;&nbsp;&nbsp;<em>gantt_jobs_resources</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>moldable_job_id</td>
<td>INT UNSIGNED</td>
<td>moldable job id</td>
</tr>
<tr><td>resource_id</td>
<td>INT UNSIGNED</td>
<td>resource assigned to the job</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">moldable_job_id, resource_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body"><em>None</em></td>
</tr>
</tbody>
</table>
<p>This table specifies which resources are attributed to which jobs.</p>
</div>
<div class="section" id="gantt-jobs-resources-visu">
<h2><a class="toc-backref" href="#id76">5.8&nbsp;&nbsp;&nbsp;<em>gantt_jobs_resources_visu</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>moldable_job_id</td>
<td>INT UNSIGNED</td>
<td>moldable job id</td>
</tr>
<tr><td>resource_id</td>
<td>INT UNSIGNED</td>
<td>resource assigned to the job</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">moldable_job_id, resource_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body"><em>None</em></td>
</tr>
</tbody>
</table>
<p>This table is the same as <a class="reference internal" href="#gantt-jobs-resources">gantt_jobs_resources</a> and is used by visualisation
tools. It is updated atomically (a lock is used).</p>
</div>
<div class="section" id="gantt-jobs-predictions">
<h2><a class="toc-backref" href="#id77">5.9&nbsp;&nbsp;&nbsp;<em>gantt_jobs_predictions</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>moldable_job_id</td>
<td>INT UNSIGNED</td>
<td>job id</td>
</tr>
<tr><td>start_time</td>
<td>INT UNSIGNED</td>
<td>date when the job is scheduled to start</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">moldable_job_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body"><em>None</em></td>
</tr>
</tbody>
</table>
<p>With this table and <a class="reference internal" href="#gantt-jobs-resources">gantt_jobs_resources</a> you can know exactly what are the
decisions taken by the schedulers for each waiting jobs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">note:</th><td class="field-body">The special job id &quot;0&quot; is used to store the scheduling reference date.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="gantt-jobs-predictions-visu">
<h2><a class="toc-backref" href="#id78">5.10&nbsp;&nbsp;&nbsp;<em>gantt_jobs_predictions_visu</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>moldable_job_id</td>
<td>INT UNSIGNED</td>
<td>job id</td>
</tr>
<tr><td>start_time</td>
<td>INT UNSIGNED</td>
<td>date when the job is scheduled to start</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">job_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body"><em>None</em></td>
</tr>
</tbody>
</table>
<p>This table is the same as <a class="reference internal" href="#gantt-jobs-predictions">gantt_jobs_predictions</a> and is used by visualisation
tools. It is made up to date in an atomic action (with a lock).</p>
</div>
<div class="section" id="jobs">
<h2><a class="toc-backref" href="#id79">5.11&nbsp;&nbsp;&nbsp;<em>jobs</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="27%" />
<col width="48%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>job_id</td>
<td>INT UNSIGNED</td>
<td>job identifier</td>
</tr>
<tr><td>job_name</td>
<td>VARCHAR(100)</td>
<td>name given by the user</td>
</tr>
<tr><td>cpuset_name</td>
<td>VARCHAR(255)</td>
<td>name of the cpuset directory used for
this job on each nodes</td>
</tr>
<tr><td>job_type</td>
<td>ENUM('INTERACTIVE',
'PASSIVE') DEFAULT
'PASSIVE'</td>
<td>specify if the user wants to launch a
program or get an interactive shell</td>
</tr>
<tr><td>info_type</td>
<td>VARCHAR(255)</td>
<td>some informations about <cite>oarsub</cite>
command</td>
</tr>
<tr><td>state</td>
<td>ENUM('Waiting','Hold',
'toLaunch', 'toError',
'toAckReservation',
'Launching', 'Running'
'Suspended',
'Resuming',
, 'Finishing',
'Terminated', 'Error')</td>
<td>job state</td>
</tr>
<tr><td>reservation</td>
<td>ENUM('None',
'toSchedule',
'Scheduled') DEFAULT
'None'</td>
<td>specify if the job is a reservation
and the state of this one</td>
</tr>
<tr><td>message</td>
<td>VARCHAR(255)</td>
<td>readable information message for the
user</td>
</tr>
<tr><td>job_user</td>
<td>VARCHAR(255)</td>
<td>user name</td>
</tr>
<tr><td>command</td>
<td>TEXT</td>
<td>program to run</td>
</tr>
<tr><td>queue_name</td>
<td>VARCHAR(100)</td>
<td>queue name</td>
</tr>
<tr><td>properties</td>
<td>TEXT</td>
<td>properties that assigned nodes must
match</td>
</tr>
<tr><td>launching_directory</td>
<td>TEXT</td>
<td>path of the directory where to launch
the user process</td>
</tr>
<tr><td>submission_time</td>
<td>INT UNSIGNED</td>
<td>date when the job was submitted</td>
</tr>
<tr><td>start_time</td>
<td>INT UNSIGNED</td>
<td>date when the job was launched</td>
</tr>
<tr><td>stop_time</td>
<td>INT UNSIGNED</td>
<td>date when the job was stopped</td>
</tr>
<tr><td>file_id</td>
<td>INT UNSIGNED</td>
<td>&nbsp;</td>
</tr>
<tr><td>accounted</td>
<td>ENUM(&quot;YES&quot;, &quot;NO&quot;)
DEFAULT &quot;NO&quot;</td>
<td>specify if the job was considered by
the accounting mechanism or not</td>
</tr>
<tr><td>notify</td>
<td>VARCHAR(255)</td>
<td>gives the way to notify the user about
the job (mail or script )</td>
</tr>
<tr><td>assigned_moldable_job</td>
<td>INT UNSIGNED</td>
<td>moldable job chosen by the scheduler</td>
</tr>
<tr><td>checkpoint</td>
<td>INT UNSIGNED</td>
<td>number of seconds before the walltime
to send the checkpoint signal to the
job</td>
</tr>
<tr><td>checkpoint_signal</td>
<td>INT UNSIGNED</td>
<td>signal to use when checkpointing the
job</td>
</tr>
<tr><td>stdout_file</td>
<td>TEXT</td>
<td>file name where to redirect program
STDOUT</td>
</tr>
<tr><td>stderr_file</td>
<td>TEXT</td>
<td>file name where to redirect program
STDERR</td>
</tr>
<tr><td>resubmit_job_id</td>
<td>INT UNSIGNED</td>
<td>if a job is resubmitted then the new
one store the previous</td>
</tr>
<tr><td>project</td>
<td>VARCHAR(255)</td>
<td>arbitrary name given by the user or an
admission rule</td>
</tr>
<tr><td>suspended</td>
<td>ENUM(&quot;YES&quot;,&quot;NO&quot;)</td>
<td>specify if the job was suspended
(oarhold)</td>
</tr>
<tr><td>job_env</td>
<td>TEXT</td>
<td>environment variables to set for the
job</td>
</tr>
<tr><td>exit_code</td>
<td>INT DEFAULT 0</td>
<td>exit code for passive jobs</td>
</tr>
<tr><td>job_group</td>
<td>VARCHAR(255)</td>
<td>not used</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">job_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">state, reservation, queue_name, accounted, suspended</td>
</tr>
</tbody>
</table>
<p>Explications about the &quot;state&quot; field:</p>
<blockquote>
<ul class="simple">
<li>&quot;Waiting&quot; : the job is waiting OAR scheduler decision.</li>
<li>&quot;Hold&quot; : user or administrator wants to hold the job (<cite>oarhold</cite> command).
So it will not be scheduled by the system.</li>
<li>&quot;toLaunch&quot; : the OAR scheduler has attributed some nodes to the job. So it
will be launched.</li>
<li>&quot;toError&quot; : something wrong occurred and the job is going into the error
state.</li>
<li>&quot;toAckReservation&quot; : the OAR scheduler must say &quot;YES&quot; or &quot;NO&quot; to the waiting
<cite>oarsub</cite> command because it requested a reservation.</li>
<li>&quot;Launching&quot; : OAR has launched the job and will execute the user command
on the first node.</li>
<li>&quot;Running&quot; : the user command is executing on the first node.</li>
<li>&quot;Suspended&quot; : the job was in Running state and there was a request
(<cite>oarhold</cite> with &quot;-r&quot; option) to suspend this job. In this state other jobs
can be scheduled on the same resources (these resources has the
&quot;suspended_jobs&quot; field to &quot;YES&quot;).</li>
<li>&quot;Finishing&quot; : the user command has terminated and OAR is doing work internally</li>
<li>&quot;Terminated&quot; : the job has terminated normally.</li>
<li>&quot;Error&quot; : a problem has occurred.</li>
</ul>
</blockquote>
<p>Explications about the &quot;reservation&quot; field:</p>
<blockquote>
<ul class="simple">
<li>&quot;None&quot; : the job is not a reservation.</li>
<li>&quot;toSchedule&quot; : the job is a reservation and must be approved by the
scheduler.</li>
<li>&quot;Scheduled&quot; : the job is a reservation and is scheduled by OAR.</li>
</ul>
</blockquote>
</div>
<div class="section" id="job-dependencies">
<h2><a class="toc-backref" href="#id80">5.12&nbsp;&nbsp;&nbsp;<em>job_dependencies</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>job_id</td>
<td>INT UNSIGNED</td>
<td>job identifier</td>
</tr>
<tr><td>job_id_required</td>
<td>INT UNSIGNED</td>
<td>job needed to be completed before
launching job_id</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">job_id, job_id_required</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">job_id, job_id_required</td>
</tr>
</tbody>
</table>
<p>This table is feeded by <cite>oarsub</cite> command with the &quot;-a&quot; option.</p>
</div>
<div class="section" id="moldable-job-descriptions">
<h2><a class="toc-backref" href="#id81">5.13&nbsp;&nbsp;&nbsp;<em>moldable_job_descriptions</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="26%" />
<col width="51%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>moldable_id</td>
<td>INT UNSIGNED</td>
<td>moldable job identifier</td>
</tr>
<tr><td>moldable_job_id</td>
<td>INT UNSIGNED</td>
<td>corresponding job identifier</td>
</tr>
<tr><td>moldable_walltime</td>
<td>INT UNSIGNED</td>
<td>instance duration</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">moldable_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">moldable_job_id</td>
</tr>
</tbody>
</table>
<p>A job can be described with several instances. Thus OAR scheduler can choose one
of them. For example it can calculate which instance will finish first.
So this table stores all instances for all jobs.</p>
</div>
<div class="section" id="job-resource-groups">
<h2><a class="toc-backref" href="#id82">5.14&nbsp;&nbsp;&nbsp;<em>job_resource_groups</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="25%" />
<col width="49%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>res_group_id</td>
<td>INT UNSIGNED</td>
<td>group identifier</td>
</tr>
<tr><td>res_group_moldable_id</td>
<td>INT UNSIGNED</td>
<td>corresponding moldable job identifier</td>
</tr>
<tr><td>res_group_property</td>
<td>TEXT</td>
<td>SQL constraint properties</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">res_group_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">res_group_moldable_id</td>
</tr>
</tbody>
</table>
<p>As you can specify job global properties with <cite>oarsub</cite> and the &quot;-p&quot; option,
you can do the same thing for each resource groups that you define with
the &quot;-l&quot; option.</p>
</div>
<div class="section" id="job-resource-descriptions">
<h2><a class="toc-backref" href="#id83">5.15&nbsp;&nbsp;&nbsp;<em>job_resource_descriptions</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="25%" />
<col width="49%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>res_job_group_id</td>
<td>INT UNSIGNED</td>
<td>corresponding group identifier</td>
</tr>
<tr><td>res_job_resource_type</td>
<td>VARCHAR(255)</td>
<td>resource type (name of a field in
resources)</td>
</tr>
<tr><td>res_job_value</td>
<td>INT</td>
<td>wanted resource number</td>
</tr>
<tr><td>res_job_order</td>
<td>INT UNSIGNED</td>
<td>order of the request</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">res_job_group_id, res_job_resource_type, res_job_order</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">res_job_group_id</td>
</tr>
</tbody>
</table>
<p>This table store the hierarchical resource description given with <cite>oarsub</cite> and
the &quot;-l&quot; option.</p>
</div>
<div class="section" id="job-state-logs">
<h2><a class="toc-backref" href="#id84">5.16&nbsp;&nbsp;&nbsp;<em>job_state_logs</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="26%" />
<col width="51%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>job_state_log_id</td>
<td>INT UNSIGNED</td>
<td>identifier</td>
</tr>
<tr><td>job_id</td>
<td>INT UNSIGNED</td>
<td>corresponding job identifier</td>
</tr>
<tr><td>job_state</td>
<td>ENUM('Waiting',
'Hold', 'toLaunch',
'toError',
'toAckReservation',
'Launching',
'Finishing',
'Running',
'Suspended',
'Resuming',
'Terminated',
'Error')</td>
<td>job state during the interval</td>
</tr>
<tr><td>date_start</td>
<td>INT UNSIGNED</td>
<td>start date of the interval</td>
</tr>
<tr><td>date_stop</td>
<td>INT UNSIGNED</td>
<td>end date of the interval</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">job_state_log_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">job_id, job_state</td>
</tr>
</tbody>
</table>
<p>This table keeps informations about state changes of jobs.</p>
</div>
<div class="section" id="job-types">
<h2><a class="toc-backref" href="#id85">5.17&nbsp;&nbsp;&nbsp;<em>job_types</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>job_type_id</td>
<td>INT UNSIGNED</td>
<td>identifier</td>
</tr>
<tr><td>job_id</td>
<td>INT UNSIGNED</td>
<td>corresponding job identifier</td>
</tr>
<tr><td>type</td>
<td>VARCHAR(255)</td>
<td>job type like &quot;deploy&quot;, &quot;timesharing&quot;,
...</td>
</tr>
<tr><td>type_index</td>
<td>ENUM('CURRENT',
'LOG')</td>
<td>index field</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">job_type_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">job_id, type</td>
</tr>
</tbody>
</table>
<p>This table stores job types given with the <cite>oarsub</cite> command and &quot;-t&quot; options.</p>
</div>
<div class="section" id="resources">
<h2><a class="toc-backref" href="#id86">5.18&nbsp;&nbsp;&nbsp;<em>resources</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="49%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>resource_id</td>
<td>INT UNSIGNED</td>
<td>resource identifier</td>
</tr>
<tr><td>type</td>
<td>VARCHAR(100)
DEFAULT &quot;default&quot;</td>
<td>resource type (used for licence
resources for example)</td>
</tr>
<tr><td>network_address</td>
<td>VARCHAR(100)</td>
<td>node name (used to connect via SSH)</td>
</tr>
<tr><td>state</td>
<td>ENUM('Alive', 'Dead'
, 'Suspected',
'Absent')</td>
<td>resource state</td>
</tr>
<tr><td>next_state</td>
<td>ENUM('UnChanged',
'Alive', 'Dead',
'Absent',
'Suspected') DEFAULT
'UnChanged'</td>
<td>state for the resource to switch</td>
</tr>
<tr><td>finaud_decision</td>
<td>ENUM('YES', 'NO')
DEFAULT 'NO'</td>
<td>tell if the actual state results in a
&quot;finaud&quot; module decision</td>
</tr>
<tr><td>next_finaud_decision</td>
<td>ENUM('YES', 'NO')
DEFAULT 'NO'</td>
<td>tell if the next node state results in
a &quot;finaud&quot; module decision</td>
</tr>
<tr><td>state_num</td>
<td>INT</td>
<td>corresponding state number (useful
with the SQL &quot;ORDER&quot; query)</td>
</tr>
<tr><td>suspended_jobs</td>
<td>ENUM('YES','NO')</td>
<td>specify if there is at least one
suspended job on the resource</td>
</tr>
<tr><td>scheduler_priority</td>
<td>INT UNSIGNED</td>
<td>arbitrary number given by the system
to select resources with more
intelligence</td>
</tr>
<tr><td>switch</td>
<td>VARCHAR(50)</td>
<td>name of the switch</td>
</tr>
<tr><td>cpu</td>
<td>INT UNSIGNED</td>
<td>global cluster cpu number</td>
</tr>
<tr><td>cpuset</td>
<td>INT UNSIGNED</td>
<td>field used with the
<a class="reference internal" href="#job-resource-manager-property-db-field">JOB_RESOURCE_MANAGER_PROPERTY_DB_FIELD</a></td>
</tr>
<tr><td>besteffort</td>
<td>ENUM('YES','NO')</td>
<td>accept or not besteffort jobs</td>
</tr>
<tr><td>deploy</td>
<td>ENUM('YES','NO')</td>
<td>specify if the resource is deployable</td>
</tr>
<tr><td>expiry_date</td>
<td>INT UNSIGNED</td>
<td>field used for the desktop computing
feature</td>
</tr>
<tr><td>desktop_computing</td>
<td>ENUM('YES','NO')</td>
<td>tell if it is a desktop computing
resource (with an agent)</td>
</tr>
<tr><td>last_job_date</td>
<td>INT UNSIGNED</td>
<td>store the date when the resource
was used for the last time</td>
</tr>
<tr><td>available_upto</td>
<td>INT UNSIGNED</td>
<td>used with compute mode features to
know if an Absent resource can be
switch on</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">resource_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">state, next_state, type, suspended_jobs</td>
</tr>
</tbody>
</table>
<p>State explications:</p>
<blockquote>
<ul class="simple">
<li>&quot;Alive&quot; : the resource is ready to accept a job.</li>
<li>&quot;Absent&quot; : the oar administrator has decided to pull out the resource. This
computer can come back.</li>
<li>&quot;Suspected&quot; : OAR system has detected a problem on this resource and so has
suspected it (you can look in the <a class="reference internal" href="#event-logs">event_logs</a> table to know what has
happened). This computer can come back (automatically if this is a
&quot;finaud&quot; module decision).</li>
<li>&quot;Dead&quot; : The oar administrator considers that the resource will not come back
and will be removed from the pool.</li>
</ul>
</blockquote>
<p>This table permits to specify different properties for each resources. These can
be used with the <cite>oarsub</cite> command (&quot;-p&quot; and &quot;-l&quot; options).</p>
<p>You can add your own properties with <a class="reference internal" href="#oarproperty">oarproperty</a> command.</p>
<p>These properties can be updated with the <a class="reference internal" href="#oarnodesetting">oarnodesetting</a> command (&quot;-p&quot; option).</p>
<p>Several properties are added by default:</p>
<blockquote>
<ul class="simple">
<li>switch : you have to register the name of the switch where the node is
plugged.</li>
<li>cpu : this is a unique name given to each cpus. This enables OAR scheduler
to distinguish all cpus.</li>
<li>cpuset : this is the name of the cpu on the node. The Linux kernel sets this
to an integer beginning at 0. This field is linked to the configuration tag
<a class="reference internal" href="#job-resource-manager-property-db-field">JOB_RESOURCE_MANAGER_PROPERTY_DB_FIELD</a>.</li>
</ul>
</blockquote>
</div>
<div class="section" id="resource-logs">
<h2><a class="toc-backref" href="#id87">5.19&nbsp;&nbsp;&nbsp;<em>resource_logs</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="26%" />
<col width="51%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>resource_log_id</td>
<td>INT UNSIGNED</td>
<td>unique id</td>
</tr>
<tr><td>resource_id</td>
<td>INT UNSIGNED</td>
<td>resource identifier</td>
</tr>
<tr><td>attribute</td>
<td>VARCHAR(255)</td>
<td>name of corresponding field in
resources</td>
</tr>
<tr><td>value</td>
<td>VARCHAR(255)</td>
<td>value of the field</td>
</tr>
<tr><td>date_start</td>
<td>INT UNSIGNED</td>
<td>interval start date</td>
</tr>
<tr><td>date_stop</td>
<td>INT UNSIGNED</td>
<td>interval stop date</td>
</tr>
<tr><td>finaud_decision</td>
<td>ENUM('YES','NO')</td>
<td>store if this is a system change or a
human one</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body"><em>None</em></td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">resource_id, attribute</td>
</tr>
</tbody>
</table>
<p>This table permits to keep a trace of every property changes (consequence of
the <a class="reference internal" href="#oarnodesetting">oarnodesetting</a> command with the &quot;-p&quot; option).</p>
</div>
<div class="section" id="assigned-resources">
<h2><a class="toc-backref" href="#id88">5.20&nbsp;&nbsp;&nbsp;<em>assigned_resources</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>moldable_job_id</td>
<td>INT UNSIGNED</td>
<td>job id</td>
</tr>
<tr><td>resource_id</td>
<td>INT UNSIGNED</td>
<td>resource assigned to the job</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">moldable_job_id, resource_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body">moldable_job_id</td>
</tr>
</tbody>
</table>
<p>This table keeps informations for jobs on which resources they were
scheduled.</p>
</div>
<div class="section" id="queues">
<h2><a class="toc-backref" href="#id89">5.21&nbsp;&nbsp;&nbsp;<em>queues</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>queue_name</td>
<td>VARCHAR(100)</td>
<td>queue name</td>
</tr>
<tr><td>priority</td>
<td>INT UNSIGNED</td>
<td>the scheduling priority</td>
</tr>
<tr><td>scheduler_policy</td>
<td>VARCHAR(100)</td>
<td>path of the associated scheduler</td>
</tr>
<tr><td>state</td>
<td>ENUM('Active',
'notActive')
DEFAULT 'Active'</td>
<td>permits to stop the scheduling for a
queue</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">queue_name</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body"><em>None</em></td>
</tr>
</tbody>
</table>
<p>This table contains the schedulers executed by the <em>oar_meta_scheduler</em> module.
Executables are launched one after one in the specified priority.</p>
</div>
<div class="section" id="challenges">
<h2><a class="toc-backref" href="#id90">5.22&nbsp;&nbsp;&nbsp;<em>challenges</em></a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="27%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Fields</th>
<th class="head">Types</th>
<th class="head">Descriptions</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>job_id</td>
<td>INT UNSIGNED</td>
<td>job identifier</td>
</tr>
<tr><td>challenge</td>
<td>VARCHAR(255)</td>
<td>challenge string</td>
</tr>
<tr><td>ssh_private_key</td>
<td>TEXT DEFAULT NULL</td>
<td>ssh private key given by the user
(in grid usage it enables to connect
onto all nodes of the job of all
clusers with oarsh)</td>
</tr>
<tr><td>ssh_public_key</td>
<td>TEXT DEFAULT NULL</td>
<td>ssh public key</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Primary key:</th><td class="field-body">job_id</td>
</tr>
<tr class="field"><th class="field-name">Index fields:</th><td class="field-body"><em>None</em></td>
</tr>
</tbody>
</table>
<p>This table is used to share a secret between OAR server and oarexec process on
computing nodes (avoid a job id being stolen/forged by malicious user).</p>
<p>For security reasons, this table <strong>must not be readable</strong> for a database
account given to users who want to access OAR internal informations(like statistics).</p>
</div>
</div>
<div class="section" id="configuration-file">
<h1><a class="toc-backref" href="#id91">6&nbsp;&nbsp;&nbsp;Configuration file</a></h1>
<p>Be careful, the syntax of this file must be bash compliant(so after editing
you must be able to launch in bash 'source /etc/oar.conf' and have variables
assigned).
Each configuration tag found in /etc/oar.conf is now described:</p>
<blockquote>
<ul>
<li><p class="first">Database type : you can use a MySQL or a PostgreSQL database (tags are
&quot;mysql&quot; or &quot;Pg&quot;):</p>
<pre class="literal-block">
DB_TYPE=mysql
</pre>
</li>
<li><p class="first">Database hostname:</p>
<pre class="literal-block">
DB_HOSTNAME=localhost

  - Database port::

DB_PORT=3306
</pre>
</li>
<li><p class="first">Database base name:</p>
<pre class="literal-block">
DB_BASE_NAME=oar
</pre>
</li>
<li><p class="first">DataBase user name:</p>
<pre class="literal-block">
DB_BASE_LOGIN=oar
</pre>
</li>
<li><p class="first">DataBase user password:</p>
<pre class="literal-block">
DB_BASE_PASSWD=oar
</pre>
</li>
</ul>
</blockquote>
<blockquote id="db-base-login-ro">
<ul>
<li><p class="first">DataBase read only user name:</p>
<pre class="literal-block">
DB_BASE_LOGIN_RO=oar_ro
</pre>
</li>
</ul>
</blockquote>
<blockquote id="db-base-passwd-ro">
<ul>
<li><p class="first">DataBase read only user password:</p>
<pre class="literal-block">
DB_BASE_PASSWD_RO=oar_ro
</pre>
</li>
<li><p class="first">OAR server hostname:</p>
<pre class="literal-block">
SERVER_HOSTNAME=localhost
</pre>
</li>
</ul>
</blockquote>
<blockquote id="server-port">
<ul>
<li><p class="first">OAR server port:</p>
<pre class="literal-block">
SERVER_PORT=6666
</pre>
</li>
<li><p class="first">When the user does not specify a -l option then oar use this:</p>
<pre class="literal-block">
OARSUB_DEFAULT_RESOURCES=&quot;/resource_id=1&quot;
</pre>
</li>
<li><p class="first">Force use of job key even if --use-job-key or -k is not set in oarsub:</p>
<pre class="literal-block">
OARSUB_FORCE_JOB_KEY=&quot;no&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="deploy-hostname">
<ul>
<li><p class="first">Specify where we are connected in the deploy queue(the node to connect
to when the job is in the deploy queue):</p>
<pre class="literal-block">
DEPLOY_HOSTNAME=&quot;127.0.0.1&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="cosystem-hostname">
<ul>
<li><p class="first">Specify where we are connected with a job of the cosystem type:</p>
<pre class="literal-block">
COSYSTEM_HOSTNAME=&quot;127.0.0.1&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="detach-job-from-server">
<ul>
<li><p class="first">Set DETACH_JOB_FROM_SERVER to 1 if you do not want to keep a ssh
connection between the node and the server. Otherwise set this tag to 0:</p>
<pre class="literal-block">
DETACH_JOB_FROM_SERVER=1
</pre>
</li>
<li><p class="first">Set the directory where OAR will store its temporary files on each nodes
of the cluster. This value MUST be the same in all oar.conf on
all nodes:</p>
<pre class="literal-block">
OAR_RUNTIME_DIRECTORY=&quot;/tmp/oar_runtime&quot;
</pre>
</li>
<li><p class="first">Specify the database field to use to fill the file on the first node of
the job in $OAR_NODE_FILE (default is 'network_address'). Only resources
with type=default are displayed in this file:</p>
<pre class="literal-block">
NODE_FILE_DB_FIELD=&quot;network_address&quot;
</pre>
</li>
<li><p class="first">Specify the database field that will be considered to fill the node file
used by the user on the first node of the job. for each different value
of this field then OAR will put 1 line in the node file(by default &quot;cpu&quot;):</p>
<pre class="literal-block">
NODE_FILE_DB_FIELD_DISTINCT_VALUES=&quot;core&quot;
</pre>
</li>
<li><p class="first">By default OAR uses the ping command to detect if nodes are down or not.
To enhance this diagnostic you can specify one of these other methods (
give the complete command path):</p>
<blockquote>
<ul>
<li><p class="first">OAR taktuk:</p>
<pre class="literal-block">
PINGCHECKER_TAKTUK_ARG_COMMAND=&quot;-t 3 broadcast exec [ true ]&quot;
</pre>
<p>If you use sentinelle.pl then you must use this tag:</p>
<pre class="literal-block">
PINGCHECKER_SENTINELLE_SCRIPT_COMMAND=&quot;/var/lib/oar/sentinelle.pl -t 5 -w 20&quot;
</pre>
</li>
<li><p class="first">OAR fping:</p>
<pre class="literal-block">
PINGCHECKER_FPING_COMMAND=&quot;/usr/bin/fping -q&quot;
</pre>
</li>
<li><p class="first">OAR nmap : it will test to connect on the ssh port (22):</p>
<pre class="literal-block">
PINGCHECKER_NMAP_COMMAND=&quot;/usr/bin/nmap -p 22 -n -T5&quot;
</pre>
</li>
<li><p class="first">OAR generic : a specific script may be used instead of ping to check
aliveness of nodes. The script must return bad nodes on STDERR (1 line
for a bad node and it must have exactly the same name that OAR has
given in argument of the command):</p>
<pre class="literal-block">
PINGCHECKER_GENERIC_COMMAND=&quot;/path/to/command arg1 arg2&quot;
</pre>
</li>
</ul>
</blockquote>
</li>
<li><p class="first">OAR log level: 3(debug+warnings+errors), 2(warnings+errors), 1(errors):</p>
<pre class="literal-block">
LOG_LEVEL=2
</pre>
</li>
<li><p class="first">OAR log file:</p>
<pre class="literal-block">
LOG_FILE=&quot;/var/log/oar.log&quot;
</pre>
</li>
<li><p class="first">If you want to debug oarexec on nodes then affect 1 (only effective if
DETACH_JOB_FROM_SERVER = 1):</p>
<pre class="literal-block">
OAREXEC_DEBUG_MODE=0
</pre>
</li>
</ul>
</blockquote>
<blockquote id="accounting-window">
<ul>
<li><p class="first">Set the granularity of the OAR accounting feature (in seconds). Default is
1 day (86400s):</p>
<pre class="literal-block">
ACCOUNTING_WINDOW=&quot;86400&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="mail">
<ul>
<li><p class="first">OAR informations may be notified by email to the administror.
Set accordingly to your configuration the next lines to activate
this feature:</p>
<pre class="literal-block">
MAIL_SMTP_SERVER=&quot;smtp.serveur.com&quot;
MAIL_RECIPIENT=&quot;user&#64;domain.com&quot;
MAIL_SENDER=&quot;oar&#64;domain.com&quot;
</pre>
</li>
<li><p class="first">Set the timeout for the prologue and epilogue execution on computing
nodes:</p>
<pre class="literal-block">
PROLOGUE_EPILOGUE_TIMEOUT=60
</pre>
</li>
<li><p class="first">Files to execute before and after each job on the first computing node
(by default nothing is executed):</p>
<pre class="literal-block">
PROLOGUE_EXEC_FILE=&quot;/path/to/prog&quot;
EPILOGUE_EXEC_FILE=&quot;/path/to/prog&quot;
</pre>
</li>
<li><p class="first">Set the timeout for the prologue and epilogue execution on the OAR server:</p>
<pre class="literal-block">
SERVER_PROLOGUE_EPILOGUE_TIMEOUT=60
</pre>
</li>
</ul>
</blockquote>
<blockquote id="server-script-exec-file">
<ul>
<li><p class="first">Files to execute before and after each job on the OAR server
(by default nothing is executed):</p>
<pre class="literal-block">
SERVER_PROLOGUE_EXEC_FILE=&quot;/path/to/prog&quot;
SERVER_EPILOGUE_EXEC_FILE=&quot;/path/to/prog&quot;
</pre>
</li>
<li><p class="first">Set the frequency for checking Alive and Suspected resources:</p>
<pre class="literal-block">
FINAUD_FREQUENCY=300
</pre>
</li>
</ul>
</blockquote>
<blockquote id="dead-switch-time">
<ul>
<li><p class="first">Set time after which resources become Dead (default is 0 and it means
never):</p>
<pre class="literal-block">
DEAD_SWITCH_TIME=600
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-timeout">
<ul>
<li><p class="first">Maximum of seconds used by a scheduler:</p>
<pre class="literal-block">
SCHEDULER_TIMEOUT=10
</pre>
</li>
<li><p class="first">Time to wait when a reservation has not got all resources that it has
reserved (some resources could have become Suspected or Absent since the
job submission) before to launch the job in the remaining resources:</p>
<pre class="literal-block">
RESERVATION_WAITING_RESOURCES_TIMEOUT=300
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-job-security-time">
<ul>
<li><p class="first">Time to add between each jobs (time for administration tasks or time to
let computers to reboot):</p>
<pre class="literal-block">
SCHEDULER_JOB_SECURITY_TIME=1
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-gantt-hole-minimum-time">
<ul>
<li><p class="first">Minimum time in seconds that can be considered like a hole where a job
could be scheduled in:</p>
<pre class="literal-block">
SCHEDULER_GANTT_HOLE_MINIMUM_TIME=300
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-resource-order">
<ul>
<li><p class="first">You can add an order preference on resource assigned by the system(SQL
ORDER syntax):</p>
<pre class="literal-block">
SCHEDULER_RESOURCE_ORDER=&quot;switch ASC, network_address DESC, resource_id ASC&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-resources-always-assigned-type">
<ul>
<li><p class="first">You can specify resources from a resource type that will be always assigned for
each job (for example: enable all jobs to be able to log on the cluster
frontales).
For more information, see the FAQ:</p>
<pre class="literal-block">
SCHEDULER_RESOURCES_ALWAYS_ASSIGNED_TYPE=&quot;42 54 12 34&quot;
</pre>
</li>
<li><p class="first">This says to the scheduler to treate resources of these types, where there is
a suspended job, like free ones. So some other jobs can be scheduled on these
resources. (list resource types separate with spaces; Default value is
nothing so no other job can be scheduled on suspended job resources):</p>
<pre class="literal-block">
SCHEDULER_AVAILABLE_SUSPENDED_RESOURCE_TYPE=&quot;default licence vlan&quot;
</pre>
</li>
<li><p class="first">Name of the perl script that manages suspend/resume. You have to install your
script in $OARDIR and give only the name of the file without the entire path.
(default is suspend_resume_manager.pl):</p>
<pre class="literal-block">
SUSPEND_RESUME_FILE=&quot;suspend_resume_manager.pl&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="just-before-resume-exec-file">
<span id="just-after-suspend-exec-file"></span><ul>
<li><p class="first">Files to execute just after a job was suspended and just before a job was
resumed:</p>
<pre class="literal-block">
JUST_AFTER_SUSPEND_EXEC_FILE=&quot;/path/to/prog&quot;
JUST_BEFORE_RESUME_EXEC_FILE=&quot;/path/to/prog&quot;
</pre>
</li>
<li><p class="first">Timeout for the two previous scripts:</p>
<pre class="literal-block">
SUSPEND_RESUME_SCRIPT_TIMEOUT=60
</pre>
</li>
</ul>
</blockquote>
<blockquote id="job-resource-manager-property-db-field">
<ul>
<li><p class="first">Indicate the name of the database field that contains the cpu number of
the node. If this option is set then users must use oarsh instead of
ssh to walk on each nodes that they have reserved via oarsub.</p>
<pre class="literal-block">
JOB_RESOURCE_MANAGER_PROPERTY_DB_FIELD=cpuset
</pre>
</li>
</ul>
</blockquote>
<blockquote id="job-resource-manager-file">
<ul>
<li><p class="first">Name of the perl script that manages cpuset. You have to install your
script in $OARDIR and give only the name of the file without the
entire path.
(default is cpuset_manager.pl which handles the linux kernel cpuset)</p>
<pre class="literal-block">
JOB_RESOURCE_MANAGER_FILE=&quot;cpuset_manager.pl&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="job-resource-manager-job-uid-type">
<ul>
<li><p class="first">Resource &quot;type&quot; DB field to use if you want to enable the job uid feature.
(create a unique user id per job on each nodes of the job)</p>
<pre class="literal-block">
JOB_RESOURCE_MANAGER_JOB_UID_TYPE=&quot;userid&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="taktuk-cmd">
<ul>
<li><p class="first">If you have installed taktuk and want to use it to manage cpusets
then give the full command path (with your options except &quot;-m&quot; and &quot;-o&quot;
and &quot;-c&quot;).
You don't also have to give any taktuk command.(taktuk version must be &gt;=
3.6)</p>
<pre class="literal-block">
TAKTUK_CMD=&quot;/usr/bin/taktuk -s&quot;
</pre>
</li>
<li><p class="first">If you want to manage nodes to be started and stoped. OAR gives you this
API:</p>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-node-manager-wake-up-cmd">
<ul>
<li><p class="first">When OAR scheduler wants some nodes to wake up then it launches this
command and puts on its STDIN the list of nodes to wake up (one hostname
by line).The scheduler looks at <em>available_upto</em> field in the <a class="reference internal" href="#resources">resources</a>
table to know if the node will be started for enough time:</p>
<pre class="literal-block">
SCHEDULER_NODE_MANAGER_WAKE_UP_CMD=&quot;/path/to/the/command with your args&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-node-manager-sleep-cmd">
<ul>
<li><p class="first">When OAR considers that some nodes can be shut down, it launches this
command and puts the node list on its STDIN(one hostname by line):</p>
<pre class="literal-block">
SCHEDULER_NODE_MANAGER_SLEEP_CMD=&quot;/path/to/the/command args&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-node-manager-idle-time">
<ul>
<li><p class="first">Parameters for the scheduler to decide when a node is idle(number of
seconds since the last job was terminated on the nodes):</p>
<pre class="literal-block">
SCHEDULER_NODE_MANAGER_IDLE_TIME=600
</pre>
</li>
</ul>
</blockquote>
<blockquote id="scheduler-node-manager-sleep-time">
<ul>
<li><p class="first">Parameters for the scheduler to decide if a node will have enough time
to sleep(number of seconds before the next job):</p>
<pre class="literal-block">
SCHEDULER_NODE_MANAGER_SLEEP_TIME=600
</pre>
</li>
</ul>
</blockquote>
<blockquote id="openssh-cmd">
<ul>
<li><p class="first">Command to use to connect to other nodes (default is &quot;ssh&quot; in the PATH)</p>
<pre class="literal-block">
OPENSSH_CMD=&quot;/usr/bin/ssh&quot;
</pre>
</li>
<li><p class="first">These are configuration tags for OAR in the desktop-computing mode:</p>
<pre class="literal-block">
DESKTOP_COMPUTING_ALLOW_CREATE_NODE=0
DESKTOP_COMPUTING_EXPIRY=10
STAGEOUT_DIR=&quot;/var/lib/oar/stageouts/&quot;
STAGEIN_DIR=&quot;/var/lib/oar/stageins&quot;
STAGEIN_CACHE_EXPIRY=144
</pre>
</li>
<li><p class="first">This variable must be set to enable the use of oarsh from a frontale node.
Otherwise you must not set this variable if you are not on a frontale:</p>
<pre class="literal-block">
OARSH_OARSTAT_CMD=&quot;/usr/bin/oarstat&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="oarsh-openssh-default-options">
<ul>
<li><p class="first">The following variable adds options to ssh. If one option is not handled
by your ssh version just remove it BUT be careful because these options are
there for security reasons:</p>
<pre class="literal-block">
OARSH_OPENSSH_DEFAULT_OPTIONS=&quot;-oProxyCommand=none -oPermitLocalCommand=no&quot;
</pre>
</li>
</ul>
</blockquote>
<blockquote id="oarmonitor-sensor-file">
<ul>
<li><p class="first">Name of the perl script the retrive monitoring data from compute nodes.
This is used in oarmonitor command.</p>
<blockquote>
<p>OARMONITOR_SENSOR_FILE=&quot;/etc/oar/oarmonitor_sensor.pl&quot;</p>
</blockquote>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="modules-descriptions">
<h1><a class="toc-backref" href="#id92">7&nbsp;&nbsp;&nbsp;Modules descriptions</a></h1>
<p>OAR can be decomposed into several modules which perform different tasks.</p>
<div class="section" id="almighty">
<h2><a class="toc-backref" href="#id93">7.1&nbsp;&nbsp;&nbsp;Almighty</a></h2>
<p>This module is the OAR server. It decides what actions must be performed. It
is divided into 2 processes:</p>
<blockquote>
<ul class="simple">
<li>One listens to a TCP/IP socket. It waits informations or commands from OAR
user program or from the other modules.</li>
<li>Another one deals with commands thanks to an automaton and launch right
modules one after one.</li>
</ul>
</blockquote>
<p>It's behaviour is represented in these schemes.</p>
<blockquote>
<ul class="simple">
<li>General schema:</li>
</ul>
<img alt="../schemas/almighty_automaton_general.png" src="../schemas/almighty_automaton_general.png" />
</blockquote>
<p>When the Almighty automaton starts it will first open a socket and creates a
pipe for the process communication with it's forked son. Then, Almighty will
fork itself in a process called &quot;appendice&quot; which role is to listen to incoming
connections on the socket and catch clients messages. These messages will be
thereafter piped to Almighty. Then, the automaton will change it's state
according to what message has been received.</p>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Scheduler schema:</li>
</ul>
<img alt="../schemas/almighty_automaton_scheduler_part.png" src="../schemas/almighty_automaton_scheduler_part.png" />
</blockquote>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Finaud schema:</li>
</ul>
<img alt="../schemas/almighty_automaton_finaud_part.png" src="../schemas/almighty_automaton_finaud_part.png" />
</blockquote>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Leon schema:</li>
</ul>
<img alt="../schemas/almighty_automaton_leon_part.png" src="../schemas/almighty_automaton_leon_part.png" />
</blockquote>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Sarko schema:</li>
</ul>
<img alt="../schemas/almighty_automaton_villains_part.png" src="../schemas/almighty_automaton_villains_part.png" />
</blockquote>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>ChangeNode schema:</li>
</ul>
<img alt="../schemas/almighty_automaton_changenode_part.png" src="../schemas/almighty_automaton_changenode_part.png" />
</blockquote>
</div>
<div class="section" id="sarko">
<h2><a class="toc-backref" href="#id94">7.2&nbsp;&nbsp;&nbsp;Sarko</a></h2>
<p>This module is executed periodically by the Almighty (default is every
30 seconds).</p>
<p>The jobs of Sarko are :</p>
<blockquote>
<ul class="simple">
<li>Look at running job walltimes and ask to frag them if they had expired.</li>
<li>Detect if fragged jobs are really fragged otherwise asks to exterminate
them.</li>
<li>In &quot;Desktop Computing&quot; mode, it detects if a node date has expired and
asks to change its state into &quot;Suspected&quot;.</li>
<li>Can change &quot;Suspected&quot; resources into &quot;Dead&quot; after <a class="reference internal" href="#dead-switch-time">DEAD_SWITCH_TIME</a> seconds.</li>
</ul>
</blockquote>
</div>
<div class="section" id="judas">
<h2><a class="toc-backref" href="#id95">7.3&nbsp;&nbsp;&nbsp;Judas</a></h2>
<p>This is the module dedicated to print and log every debugging, warning and
error messages.</p>
<p>The notification functions are the following:</p>
<blockquote>
<ul class="simple">
<li>send_mail(mail_recipient_address, object, body, job_id) that sends
emails to the OAR admin</li>
<li>notify_user(base, method, host, user, job_id, job_name, tag, comments)
that parses the notify method. This method can be a user script or a
mail to send. If the &quot;method&quot; field begins with
&quot;mail:&quot;, notify_user will send an email to the user. If the
beginning is &quot;exec:&quot;, it will execute the script as the &quot;user&quot;.</li>
</ul>
</blockquote>
<p>The main logging functions are the following:</p>
<blockquote>
<ul class="simple">
<li>redirect_everything() this function redirects STDOUT and STDERR into
the log file</li>
<li>oar_debug(message)</li>
<li>oar_warn(message)</li>
<li>oar_error(message)</li>
</ul>
</blockquote>
<p>The three last functions are used to set the log level of the message.</p>
</div>
<div class="section" id="leon">
<h2><a class="toc-backref" href="#id96">7.4&nbsp;&nbsp;&nbsp;Leon</a></h2>
<p>This module is in charge to delete the jobs. Other OAR modules or commands
can ask to kill a job and this is Leon which performs that.</p>
<p>There are 2 frag types :</p>
<blockquote>
<ul class="simple">
<li><em>normal</em> : Leon tries to connect to the first node allocated for the job and
terminates the job.</li>
<li><em>exterminate</em> : after a timeout if the <em>normal</em> method did not succeed
then Leon notifies this case and clean up the database for these jobs. So
OAR doesn't know what occured on the node and Suspects it.</li>
</ul>
</blockquote>
</div>
<div class="section" id="runner">
<h2><a class="toc-backref" href="#id97">7.5&nbsp;&nbsp;&nbsp;Runner</a></h2>
<p>This module launches OAR effective jobs. These processes are run asynchronously
with all modules.</p>
<p>For each job, the <a class="reference internal" href="#runner">Runner</a> uses <a class="reference internal" href="#openssh-cmd">OPENSSH_CMD</a> to connect to the first node of the
reservation and propagate a Perl script which handles the execution of the user
command.</p>
<blockquote>
<ul class="simple">
<li>for each job in &quot;toError&quot; state, answer to the oarsub client: &quot;BAD JOB&quot;.
This will exit the client with an error code.</li>
<li>for each job in &quot;toAckReservation&quot; state, try to acknowledge the
oarsub client reservation. If runner cannot contact the client, it will
frag the job.</li>
<li>for each job to launch, launch job's bipbip.</li>
</ul>
</blockquote>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Runner schema:</li>
</ul>
<img alt="../schemas/runner.png" src="../schemas/runner.png" />
</blockquote>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>bipbip schema:</li>
</ul>
<img alt="../schemas/bipbip.png" src="../schemas/bipbip.png" />
</blockquote>
</div>
<hr class="docutils" />
<div class="section" id="nodechangestate">
<h2><a class="toc-backref" href="#id98">7.6&nbsp;&nbsp;&nbsp;NodeChangeState</a></h2>
<p>This module is in charge of changing resource states and checking if there are
jobs on these.</p>
<p>It also checks all pending events in the table <a class="reference internal" href="#event-logs">event_logs</a>.</p>
</div>
<div class="section" id="scheduler">
<h2><a class="toc-backref" href="#id99">7.7&nbsp;&nbsp;&nbsp;Scheduler</a></h2>
<p>This module checks for each reservation jobs if it is valid and launches them
at the right time.</p>
<p><a class="reference internal" href="#scheduler">Scheduler</a> launches all gantt scheduler in the order of the priority specified
in the database and update all visualization tables
(<a class="reference internal" href="#gantt-jobs-predictions-visu">gantt_jobs_predictions_visu</a> and <a class="reference internal" href="#gantt-jobs-resources-visu">gantt_jobs_resources_visu</a>).</p>
<div class="section" id="oar-sched-gantt-with-timesharing">
<h3><a class="toc-backref" href="#id100">7.7.1&nbsp;&nbsp;&nbsp;oar_sched_gantt_with_timesharing</a></h3>
<p>This is the default OAR scheduler. It implements all functionalities like
timesharing, moldable jobs, <cite>besteffort jobs</cite>, ...</p>
<p>By default, this scheduler is used by all default queues.</p>
<p>We have implemented the FIFO with backfilling algorithm. Some parameters
can be changed in the <a class="reference internal" href="#configuration-file">configuration file</a> (see <a class="reference internal" href="#scheduler-timeout">SCHEDULER_TIMEOUT</a>,
<a class="reference internal" href="#scheduler-job-security-time">SCHEDULER_JOB_SECURITY_TIME</a>, <a class="reference internal" href="#scheduler-gantt-hole-minimum-time">SCHEDULER_GANTT_HOLE_MINIMUM_TIME</a>,
<a class="reference internal" href="#scheduler-resource-order">SCHEDULER_RESOURCE_ORDER</a>).</p>
</div>
<div class="section" id="oar-sched-gantt-with-timesharing-and-fairsharing">
<h3><a class="toc-backref" href="#id101">7.7.2&nbsp;&nbsp;&nbsp;oar_sched_gantt_with_timesharing_and_fairsharing</a></h3>
<p>This scheduler is the same than <a class="reference internal" href="#oar-sched-gantt-with-timesharing">oar_sched_gantt_with_timesharing</a> but it looks
at the consumption past and try to order waiting jobs with fairsharing in mind.</p>
<p>Some parameters can be changed directly in the file:</p>
<pre class="literal-block">
###############################################################################
# Fairsharing parameters #
##########################
# Avoid problems if there are too many waiting jobs
my $Karma_max_number_of_jobs_treated = 1000;
# number of seconds to consider for the fairsharing
my $Karma_window_size = 3600 * 30;
# specify the target percentages for project names (0 if not specified)
my $Karma_project_targets = {
    first =&gt; 75,
    default =&gt; 25
};

# specify the target percentages for users (0 if not specified)
my $Karma_user_targets = {
    oar =&gt; 100
};
# weight given to each criteria
my $Karma_coeff_project_consumption = 3;
my $Karma_coeff_user_consumption = 2;
my $Karma_coeff_user_asked_consumption = 1;
###############################################################################
</pre>
<p>This scheduler takes its historical data in the <a class="reference internal" href="#accounting">accounting</a> table. To fill this,
the command <a class="reference internal" href="#oaraccounting">oaraccounting</a> have to be run periodically (in a cron job for
example). Otherwise the scheduler cannot be aware of new user consumptions.</p>
</div>
</div>
<div class="section" id="hulot">
<h2><a class="toc-backref" href="#id102">7.8&nbsp;&nbsp;&nbsp;Hulot</a></h2>
<p>This module is responsible of the advanced management of the standby mode of the
nodes. It's related to the energy saving features of OAR. It is an optional module
activated with the ENERGY_SAVING_INTERNAL=yes configuration variable.</p>
<p>It runs as a fourth &quot;Almighty&quot; daemon and opens a pipe on which it receives commands
from the MetaScheduler. It also communicates with a library called &quot;WindowForker&quot;
that is responsible of forking shut-down/wake-up commands in a way that not too much
commands are started at a time.</p>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Hulot general commands process schema:</li>
</ul>
<img alt="../schemas/hulot_general_commands_process.png" src="../schemas/hulot_general_commands_process.png" />
</blockquote>
<p>When Hulot is activated, the metascheduler sends, each time it is executed, a
list of nodes that need to be woken-up or may be halted. Hulot maintains a
list of commands that have already been sent to the nodes and asks to the
windowforker to actually execute the commands only when it is appropriate.
A special feature is the &quot;keepalive&quot; of nodes depending on some properties:
even if the metascheduler asks to shut-down some nodes, it's up to Hulot to
check if the keepalive constraints are still satisfied. If not, Hulot refuses
to halt the corresponding nodes.</p>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Hulot checking process schema:</li>
</ul>
<img alt="../schemas/hulot_checking_process.png" src="../schemas/hulot_checking_process.png" />
</blockquote>
<p>Hulot is called each time the metascheduler is called, to do all the checking
process. This process is also executed when Hulot receives normal halt or wake-up
commands from the scheduler. Hulot checks if waking-up nodes are actually Alive
or not and suspects the nodes if they haven't woken-up before the timeout.
It also checks keepalive constraints and decides to wake-up nodes if a constraint
is no more satisfied (for example because new jobs are running on nodes that are
now busy, and no more idle).
Hulot also checks the results of the commands sent by the windowforker and may
also suspect a node if the command exited with non-zero status.</p>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Hulot wake-up process schema</li>
</ul>
<img alt="../schemas/hulot_wakeup_process.png" src="../schemas/hulot_wakeup_process.png" />
</blockquote>
<hr class="docutils" />
<blockquote>
<ul class="simple">
<li>Hulot shutdown process schema</li>
</ul>
<img alt="../schemas/hulot_shutdown_process.png" src="../schemas/hulot_shutdown_process.png" />
</blockquote>
</div>
</div>
<hr class="docutils" />
<div class="section" id="internal-mechanisms">
<h1><a class="toc-backref" href="#id103">8&nbsp;&nbsp;&nbsp;Internal mechanisms</a></h1>
<div class="section" id="job-execution">
<h2><a class="toc-backref" href="#id104">8.1&nbsp;&nbsp;&nbsp;Job execution</a></h2>
<div class="figure">
<img alt="../schemas/job_execution.png" src="../schemas/job_execution.png" />
</div>
</div>
<hr class="docutils" />
<div class="section" id="scheduling">
<h2><a class="toc-backref" href="#id105">8.2&nbsp;&nbsp;&nbsp;Scheduling</a></h2>
<blockquote>
<div class="figure">
<img alt="../schemas/scheduling.png" src="../schemas/scheduling.png" />
</div>
</blockquote>
</div>
</div>
<div class="section" id="faq-admin">
<h1><a class="toc-backref" href="#id106">9&nbsp;&nbsp;&nbsp;FAQ - ADMIN</a></h1>
<div class="section" id="release-policy">
<h2><a class="toc-backref" href="#id107">9.1&nbsp;&nbsp;&nbsp;Release policy</a></h2>
<dl class="docutils">
<dt>Since the version 2.2, release numbers are divided into 3 parts:</dt>
<dd><ul class="first last simple">
<li>The first represents the design and the implementation used.</li>
<li>The second represents a set of OAR functionalities.</li>
<li>The third is incremented after bug fixes.</li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="what-means-the-error-bad-configuration-option-permitlocalcommand-when-i-am-using-oarsh">
<h2><a class="toc-backref" href="#id108">9.2&nbsp;&nbsp;&nbsp;What means the error &quot;Bad configuration option: PermitLocalCommand&quot; when I am using oarsh?</a></h2>
<p>For security reasons, on the latest OpenSSH releases you are able to execute
a local command when you are connecting to the remote host and we must
deactivate this option because the oarsh wrapper executes the <em>ssh</em> command
into the user oar.</p>
<p>So if you encounter this error message it means that your OpenSSH does
not know this option and you have to remove it from the oar.conf.
There is a variable named <a class="reference internal" href="#oarsh-openssh-default-options">OARSH_OPENSSH_DEFAULT_OPTIONS</a> in oar.conf used by oarsh.
So you have just to remove the not yet implemented option.</p>
</div>
<div class="section" id="how-to-manage-start-stop-of-the-nodes">
<h2><a class="toc-backref" href="#id109">9.3&nbsp;&nbsp;&nbsp;How to manage start/stop of the nodes?</a></h2>
<p>You have to add a script in /etc/init.d which switches resources of the node
into the &quot;Alive&quot; or &quot;Absent&quot; state.
So when this script is called at boot time, it will change the state into
&quot;Alive&quot;. And when it is called at halt time, it will change into &quot;Absent&quot;.</p>
<p>There two ways to perform this action:</p>
<blockquote>
<ol class="arabic">
<li><p class="first">Install OAR &quot;oar-libs&quot; part on all nodes. Thus you will be able to launch
the command <a class="reference internal" href="#oarnodesetting">oarnodesetting</a> (be careful to right configure &quot;oar.conf&quot; with
database login and password AND to allow network connections on this
database).
So you can execute:</p>
<pre class="literal-block">
oarnodesetting -s Alive -h node_hostname
    or
oarnodesetting -s Absent -h node_hostname
</pre>
</li>
<li><p class="first">You do not want to install anything else on each node. So you have to
enable oar user to connect to the server via ssh (for security you
can use another SSH key with restrictions on the command that oar can
launch with this one). Thus you will have in you init script
something like:</p>
<pre class="literal-block">
sudo -u oar ssh oar-server &quot;oarnodesetting -s Alive -h node_hostname&quot;
    or
sudo -u oar ssh oar-server &quot;oarnodesetting -s Absent -h node_hostname&quot;
</pre>
<p>In this case, further OAR software upgrade will be more painless.</p>
</li>
</ol>
</blockquote>
</div>
<div class="section" id="how-can-i-manage-scheduling-queues">
<h2><a class="toc-backref" href="#id110">9.4&nbsp;&nbsp;&nbsp;How can I manage scheduling queues?</a></h2>
<p>see <a class="reference internal" href="#oarnotify">oarnotify</a>.</p>
</div>
<div class="section" id="how-can-i-handle-licence-tokens">
<h2><a class="toc-backref" href="#id111">9.5&nbsp;&nbsp;&nbsp;How can I handle licence tokens?</a></h2>
<p>OAR does not manage resources with an empty &quot;network_address&quot;. So you can
define resources that are not linked with a real node.</p>
<p>So the steps to configure OAR with the possibility to reserve licences (or
whatever you want that are other notions):</p>
<blockquote>
<ol class="arabic">
<li><p class="first">Add a new field in the table <a class="reference internal" href="#resources">resources</a> to specify the licence name.</p>
<pre class="literal-block">
oarproperty -a licence -c
</pre>
</li>
<li><p class="first">Add your licence name resources with <a class="reference internal" href="#oarnodesetting">oarnodesetting</a>.</p>
<pre class="literal-block">
oarnodesetting -a -h &quot;&quot; -p type=mathlab -p licence=l1
oarnodesetting -a -h &quot;&quot; -p type=mathlab -p licence=l2
oarnodesetting -a -h &quot;&quot; -p type=fluent -p licence=l1
...
</pre>
</li>
</ol>
</blockquote>
<p>After this configuration, users can perform submissions like</p>
<pre class="literal-block">
oarsub -I -l &quot;/switch=2/nodes=10+{type = 'mathlab'}/licence=20&quot;
</pre>
<p>So users ask OAR to give them some other resource types but nothing block
their program to take more licences than they asked.
You can resolve this problem with the <a class="reference internal" href="#server-script-exec-file">SERVER_SCRIPT_EXEC_FILE</a> configuration.
In these files you have to bind OAR allocated resources to the licence servers
to restrict user consumptions to what they asked. This is very dependant of
the licence management.</p>
</div>
<div class="section" id="how-can-i-handle-multiple-clusters-with-one-oar">
<h2><a class="toc-backref" href="#id112">9.6&nbsp;&nbsp;&nbsp;How can I handle multiple clusters with one OAR?</a></h2>
<p>These are the steps to follow:</p>
<blockquote>
<ol class="arabic">
<li><p class="first">create a resource property to identify the corresponding cluster (like &quot;cluster&quot;):</p>
<pre class="literal-block">
oarproperty -a cluster
</pre>
<p>(you can see this new property when you use oarnodes)</p>
</li>
<li><p class="first">with <a class="reference internal" href="#oarnodesetting">oarnodesetting</a> you have to fill this field for all resources; for example:</p>
<pre class="literal-block">
oarnodesetting -h node42.cluster1.com -p cluster=1
oarnodesetting -h node43.cluster1.com -p cluster=1
oarnodesetting -h node2.cluster2.com -p cluster=2
...
</pre>
</li>
<li><p class="first">Then you have to restrict properties for new job type.
So an admission rule performs this job (this is a SQL syntax to use in a database interpreter):</p>
<pre class="literal-block">
INSERT IGNORE INTO admission_rules (rule) VALUES ('
    my $cluster_constraint = 0;
    if (grep(/^cluster1$/, &#64;{$type_list})){
        $cluster_constraint = 1;
    }elsif (grep(/^cluster2$/, &#64;{$type_list})){
        $cluster_constraint = 2;
    }
if ($cluster_constraint &gt; 0){
    if ($jobproperties ne &quot;&quot;){
        $jobproperties = &quot;($jobproperties) AND cluster = $cluster_constraint&quot;;
    }else{
        $jobproperties = &quot;cluster = $cluster_constraint&quot;;
    }
    print(&quot;[ADMISSION RULE] Added automatically cluster resource constraint\\n&quot;);
}
');
</pre>
</li>
<li><p class="first">Edit the admission rule which checks the right job types and add
&quot;cluster1&quot; and &quot;cluster2&quot; in.</p>
</li>
</ol>
</blockquote>
<p>So when you will use oarsub to submit a &quot;cluster2&quot; job type only resources
with the property &quot;cluster=2&quot; is used. This is the same when you will use the
&quot;cluster1&quot; type.</p>
</div>
<div class="section" id="how-to-configure-a-more-ecological-cluster-or-how-to-make-some-power-consumption-economies">
<h2><a class="toc-backref" href="#id113">9.7&nbsp;&nbsp;&nbsp;How to configure a more ecological cluster (or how to make some power consumption economies)?</a></h2>
<p>This feature can be performed with the <cite>Dynamic nodes coupling features</cite>.</p>
<p>First you have to make sure that you have a command to wake up a computer
that is stopped. For example you can use the WoL (Wake on Lan) feature
(generally you have to right configure the BIOS and add right options to the
Linux Ethernet driver; see &quot;ethtool&quot;).</p>
<p>If you want to enable a node to be woke up the next 12 hours:</p>
<pre class="literal-block">
((DATE=$(date +%s)+3600*12))
oarnodesetting -h host_name -p cm_availability=$DATE
</pre>
<p>Otherwise you can disable the wake up of nodes (but not the halt) by:</p>
<pre class="literal-block">
oarnodesetting -h host_name -p cm_availability=1
</pre>
<p>If you want to disable the halt on a node (but not the wakeup):</p>
<pre class="literal-block">
oarnodesetting -h host_name -p cm_availability=2147483647
</pre>
<p>2147483647 = 2^31 - 1 : we take this value as infinite and it is used to
disable the halt mechanism.</p>
<p>And if you want to disable the halt and the wakeup:</p>
<pre class="literal-block">
oarnodesetting -h host_name -p cm_availability=0
</pre>
<p>Note: In the unstable 2.4 OAR version, cm_availability has been renamed
into available_upto.</p>
<p>Your <a class="reference internal" href="#scheduler-node-manager-wake-up-cmd">SCHEDULER_NODE_MANAGER_WAKE_UP_CMD</a> must be a script that read node
names and translate them into the right wake up command.</p>
<p>So with the right OAR and node configurations you can optimize the power
consumption of your cluster (and your air conditioning infrastructure)
without drawback for the users.</p>
<p>Take a look at your cluster occupation and your electricity bill to know if it
could be interesting for you ;-)</p>
</div>
<div class="section" id="how-to-configure-temporary-uid-for-each-job">
<h2><a class="toc-backref" href="#id114">9.8&nbsp;&nbsp;&nbsp;How to configure temporary UID for each job?</a></h2>
<p>For a better way to handle job processes we introduce the temporary user id
feature.</p>
<p>This feature creates a user for each job on assigned nodes. Hence it is
possible to clean temporary files, IPC, every generated processes, ...
Furthermore a lot of system features could be used like bandwidth management
(iptables rules on the user id).</p>
<p>To configure this feature, CPUSET must be activated and the tag
JOB_RESOURCE_MANAGER_JOB_UID_TYPE has to be configured in the oar.conf file.
The value is the content of the &quot;type&quot; field into the <a class="reference internal" href="#resources">resources</a> table. After
that you have to add resources in the database with this type and fill the
cpuset field with a unique UID (not used by real users). The maximum number of
concurrent jobs is the number of resources of this type.</p>
<p>For example, if you put this in your oar.onf:</p>
<pre class="literal-block">
JOB_RESOURCE_MANAGER_PROPERTY_DB_FIELD=&quot;cpuset&quot;
JOB_RESOURCE_MANAGER_JOB_UID_TYPE=&quot;user&quot;
</pre>
<p>Then you can add temporary UID:</p>
<pre class="literal-block">
oarnodesetting -a -h fake -p cpuset=23000 -p type=user
oarnodesetting -a -h fake -p cpuset=23001 -p type=user
oarnodesetting -a -h fake -p cpuset=23002 -p type=user
...
</pre>
<p>You can put what you want in the place of the hostname (here &quot;fake&quot;).</p>
<p>The drawback of this feature is that users haven't their UID only their GID.</p>
</div>
<div class="section" id="how-to-enable-jobs-to-connect-to-the-frontales-from-the-nodes-using-oarsh">
<h2><a class="toc-backref" href="#id115">9.9&nbsp;&nbsp;&nbsp;How to enable jobs to connect to the frontales from the nodes using oarsh?</a></h2>
<p>First you have to install the node part of OAR on the wanted nodes.</p>
<p>After that you have to register the frontales into the database using
oarnodesetting with the &quot;frontal&quot; (for example) type and assigned the desired
cpus into the cpuset field; for example:</p>
<pre class="literal-block">
oarnodesetting -a -h frontal1 -p type=frontal -p cpuset=0
oarnodesetting -a -h frontal1 -p type=frontal -p cpuset=1
oarnodesetting -a -h frontal2 -p type=frontal -p cpuset=0
...
</pre>
<p>Thus you will be able to see resources identifier of these resources with
oarnodes; try to type:</p>
<pre class="literal-block">
oarnodes --sql &quot;type='frontal'&quot;
</pre>
<p>Then put this type name (here &quot;frontal&quot;) into the <em>oar.conf</em> file on the OAR
server into the tag <a class="reference internal" href="#scheduler-resources-always-assigned-type">SCHEDULER_RESOURCES_ALWAYS_ASSIGNED_TYPE</a>.</p>
<dl class="docutils">
<dt>Notes:</dt>
<dd><ul class="first last simple">
<li>if one of these resources become &quot;Suspected&quot; then the scheduling will
stop.</li>
<li>you can disable this feature with <a class="reference internal" href="#oarnodesetting">oarnodesetting</a> and put these resources
into the &quot;Absent&quot; state.</li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="a-job-remains-in-the-finishing-state-what-can-i-do">
<h2><a class="toc-backref" href="#id116">9.10&nbsp;&nbsp;&nbsp;A job remains in the &quot;Finishing&quot; state, what can I do?</a></h2>
<p>If you have waited more than a couple of minutes (10mn for example) then
something wrong occurred (frontal has crashed, out of memory, ...).</p>
<p>So you are able to turn manually a job into the &quot;Error&quot; state by typing with the root user (example with a bash shell):</p>
<pre class="literal-block">
export OARCONFFILE=/etc/oar/oar.conf
perl -e 'use OAR::IO; $db = OAR::IO::connect(); OAR::IO::set_job_state($db,42,&quot;Error&quot;)'
</pre>
<p>(Replace 42 by your job identifier)</p>
</div>
<div class="section" id="how-can-i-write-my-own-scheduler">
<h2><a class="toc-backref" href="#id117">9.11&nbsp;&nbsp;&nbsp;How can I write my own scheduler?</a></h2>
</div>
</div>
<div class="section" id="oar-s-scheduler-in-ocaml">
<h1><a class="toc-backref" href="#id118">10&nbsp;&nbsp;&nbsp;OAR's scheduler in ocaml</a></h1>
<div class="section" id="intro">
<h2><a class="toc-backref" href="#id119">10.1&nbsp;&nbsp;&nbsp;Intro</a></h2>
<p>The main goal of this scheduler is to provide a better scalabily in comparaison to the schedulers in Perl.Up to now some features are missing see below.</p>
<p>This developement of this scheduler borrows lot of ideas and source codes from perl oar_2.x schedulers and (a large part of) moldable ocaml oar_1.6 scheduler (thanks respectively to Nicolas Capit and Lionel Eyraud for theirs codes).</p>
</div>
<div class="section" id="features">
<h2><a class="toc-backref" href="#id120">10.2&nbsp;&nbsp;&nbsp;Features:</a></h2>
<blockquote>
<ul class="simple">
<li>conservative backfilling</li>
<li>resources properties matching</li>
<li>besteffort</li>
<li>hierarchies</li>
<li>multiple resource type [TO TEST]</li>
<li>multiple resource requests ( + ) [TO TEST]</li>
<li>time constant guards, [TO TEST]</li>
<li>suspend/resume,</li>
<li>job depencies [TO TEST]</li>
<li>job container</li>
<li>fairesharing [TO TEST]</li>
<li>order_by on resources [TO FINISH / EVALUATE]</li>
<li>ALL / BEST / BESTHALF for number of resources by level of hierarchy</li>
</ul>
</blockquote>
</div>
<div class="section" id="missing">
<h2><a class="toc-backref" href="#id121">10.3&nbsp;&nbsp;&nbsp;Missing:</a></h2>
<blockquote>
<ul class="simple">
<li>Timesharing (not planned for fisrt public version)</li>
<li>Placeholder (not planned)</li>
<li>Extensive test (no yet running on production cluster)</li>
<li>SCHEDULER_TOKEN_SCRIPTS support (for legacy licence management)</li>
<li>SCHEDULER_AVAILABLE_SUSPENDED_RESOURCE_TYPE (get_scheduled_jobs function is ready)</li>
</ul>
</blockquote>
</div>
<div class="section" id="next">
<h2><a class="toc-backref" href="#id122">10.4&nbsp;&nbsp;&nbsp;Next:</a></h2>
<blockquote>
<ul class="simple">
<li>Support for null</li>
<li>test hierarchy construction with different type of resource (exception raises when a field is missing)</li>
<li>performance testing</li>
<li>add always SCHEDULER_RESOURCES_ALWAYS_ASSIGNED_TYPE (is it really needed ?)</li>
<li>SCHEDULER_TOKEN_SCRIPTS support (for legacy licence management)</li>
<li>scheduler message (see perl version )</li>
<li>job_error / job_message / scheduler message</li>
<li>need to test multi-resource-type (since &gt;= cbf_mb_h)</li>
<li>need to test multi-request with non exclusive resource selection (since &gt;= cbf_mb_h)</li>
<li>errors logging (at least same error support as provide in perl scheduler)</li>
<li>dump first k ready launchable jobs (for performance /reactivity issue)</li>
<li>nb_asked_resource = 0 raise an error (&gt;= cbf_mb_h)</li>
<li>unit test</li>
<li>better compilation process (for unit tests)</li>
</ul>
</blockquote>
</div>
<div class="section" id="todo">
<h2><a class="toc-backref" href="#id123">10.5&nbsp;&nbsp;&nbsp;ToDo:</a></h2>
<blockquote>
<ul>
<li><dl class="first docutils">
<dt>ORDER_BY</dt>
<dd><ul class="first last simple">
<li>performance test</li>
<li>production test</li>
<li>ord2init_ids, init2ord_ids  more test</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">switch name to kamelot</p>
</li>
<li><p class="first">test fairsharing</p>
</li>
<li><p class="first">test_unit: better compilation process</p>
</li>
<li><p class="first">Ounit (cf archive)
* test sub_intevals</p>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="misc">
<h2><a class="toc-backref" href="#id124">10.6&nbsp;&nbsp;&nbsp;Misc:</a></h2>
<blockquote>
<ul class="simple">
<li>With 64 bits machine we can use ocaml's int with 63 bits instead of Int64.</li>
</ul>
</blockquote>
</div>
<div class="section" id="done">
<h2><a class="toc-backref" href="#id125">10.7&nbsp;&nbsp;&nbsp;Done:</a></h2>
<blockquote>
<ul class="simple">
<li>resource order_by support (usable)</li>
<li>container</li>
<li>Support of postgresql</li>
<li>Preliminary performance comparaison (perl version timesharing only scheduler from oar-server_2.3.4-1_all.deb against cbf_mh_h). Perl scheduler doesn't seem to scale with number of resources)</li>
<li>modify itv_intersect in Interval / remove itv2str, itvs2str (&gt;= cbf_mh_h)</li>
<li>multi-resource-type (since &gt;= cbf_mh_h) (</li>
<li>multi-request with non exclusive resource selection (since &gt;= cbf_mh_h)</li>
</ul>
</blockquote>
</div>
<div class="section" id="remarks-and-misc">
<h2><a class="toc-backref" href="#id126">10.8&nbsp;&nbsp;&nbsp;Remarks and misc:</a></h2>
<blockquote>
<ul class="simple">
<li><a class="reference external" href="http://martin.jambon.free.fr/ocaml.htm">http://martin.jambon.free.fr/ocaml.htm</a></li>
</ul>
</blockquote>
</div>
<div class="section" id="bugs">
<h2><a class="toc-backref" href="#id127">10.9&nbsp;&nbsp;&nbsp;Bugs:</a></h2>
</div>
<div class="section" id="debug">
<h2><a class="toc-backref" href="#id128">10.10&nbsp;&nbsp;&nbsp;Debug:</a></h2>
<blockquote>
make bc
ocamlmktop -I /usr/lib/ocaml/  -o yop str.cma unix.cma ../common/helpers.cmo ../common/interval.cmo ../common/conf.cmo types.cmo ../common/hierarchy.cmo ./simple_cbf_mb_h_ct.cmo</blockquote>
<dl class="docutils">
<dt>ocamlmktop -I /usr/lib/ocaml/  -o yop str.cma unix.cma ../common/helpers.cmo </dt>
<dd>../common/interval.cmo ../common/conf.cmo types.cmo ../common/hierarchy.cmo ./simple_cbf_mb_h_ct.cmo mysql/mysql.cma ./mysql_driver.cmo iolib.cmo ./simple_cbf_mb_h_ct_oar.cmo</dd>
<dt>ocamlmktop -I /usr/lib/ocaml/  -o yop str.cma unix.cma ../common/helpers.cmo </dt>
<dd>../common/interval.cmo ../common/conf.cmo types.cmo ../common/hierarchy.cmo ./simple_cbf_mb_h_ct.cmo mysql/mysql.cma ./mysql_driver.cmo iolib.cmo</dd>
</dl>
<p>rlwrap ./yop -I ../common -I .</p>
</div>
<div class="section" id="what-is-the-syntax-of-this-documentation">
<h2><a class="toc-backref" href="#id129">10.11&nbsp;&nbsp;&nbsp;What is the syntax of this documentation?</a></h2>
<p>We are using the RST format from the <a class="reference external" href="http://docutils.sourceforge.net/">Docutils</a> project. This syntax is easily readable
and can be converted into HTML, LaTex or XML.</p>
<p>You can find basic informations on
<a class="reference external" href="http://docutils.sourceforge.net/docs/user/rst/quickref.html">http://docutils.sourceforge.net/docs/user/rst/quickref.html</a></p>
</div>
</div>
<div class="section" id="oar-changelog">
<h1><a class="toc-backref" href="#id130">11&nbsp;&nbsp;&nbsp;OAR CHANGELOG</a></h1>
<div class="section" id="version-2-5-3">
<h2><a class="toc-backref" href="#id131">11.1&nbsp;&nbsp;&nbsp;version 2.5.3:</a></h2>
<blockquote>
<ul class="simple">
<li>Add the &quot;Name&quot; field on the main Monika page. This is easier for the users
to find there jobs.</li>
<li>Add MAX_CONCURRENT_JOB_TERMINATIONS into the oar.conf ofthe master. This
limits the number of concurrent processes launched by the Almighty when the
the jobs finish.</li>
<li>Bug fix in ssh key feature in oarsub.</li>
<li>Added --compact, -c option to oarstat (compact view or array jobs)</li>
<li>Improvements of the API: media upload from html forms, listing of files,
security fixes, add of new configuration options, listing of the scheduled
nodes into jobs, fixed bad reinitialization of the limit parameter...
See OAR-DOCUMENTATION-API-USER for more informations.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-5-2">
<h2><a class="toc-backref" href="#id132">11.2&nbsp;&nbsp;&nbsp;version 2.5.2:</a></h2>
<blockquote>
<ul>
<li><p class="first">Bugfix: /var/lib/oar/.bash_oar was empty due to an error in the common
setup script.</p>
</li>
<li><p class="first">Bugfix: the PINGCHECKER_COMMAND in oar.conf depends now on %%OARDIR%%.</p>
</li>
<li><dl class="first docutils">
<dt>Bug #13939: the job_resource_manager.pl and job_resource_manager_cgroups.pl</dt>
<dd><p class="first last">now deletes the user files in /tmp, /var/tmp and /dev/shm at
the end of the jobs.</p>
</dd>
</dl>
</li>
<li><p class="first">Bugfix: in oardodo.c, the preprocessed variables was not defined correclty.</p>
</li>
<li><p class="first">Finaud: fix race condition when there was a PINGCHECKER error jsut before
another problem. The node became Alive again when the PINGCHECKER said OK
BUT there was another error to resolve.</p>
</li>
<li><p class="first">Bugfix: The feature CHECK_NODES_WITH_RUNNING_JOB=yes never worked before.</p>
</li>
<li><p class="first">Speedup monika (X5).</p>
</li>
<li><p class="first">Monika: Add the conf max_cores_per_line to have several lines if the number
of cores are too big.</p>
</li>
<li><dl class="first docutils">
<dt>Minor changes into API:</dt>
<dd><ul class="first last simple">
<li>added cmd_output into POST /jobs.</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">API: Added GET /select_all?query=&lt;query&gt; (read only mode).</p>
</li>
<li><p class="first">Add the field &quot;array_index&quot; into the jobs table. So that resubmit a job
from an array will have the right array_index anvironment variable.</p>
</li>
<li><p class="first">oarstat: order the output by job_id.</p>
</li>
<li><p class="first">Speedup oarnodes.</p>
</li>
<li><p class="first">Fix a spelling error in the oaradmin manpage.</p>
</li>
<li><p class="first">Bugfix #14122 : the oar-node init.d script wasn't executing
start_oar_node/stop_oar_node during the 'restart' action.</p>
</li>
<li><p class="first">Allow the dash  character into the --notify &quot;exec:...&quot; oarsub option.</p>
</li>
<li><dl class="first docutils">
<dt>Remove some old stuffs from the tarball:</dt>
<dd><ul class="first last simple">
<li>visualization_interfaces/{tgoar,accounting,poar};</li>
<li>scheduler/moldable;</li>
<li>pbs-oar-lib.</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Fix some licence issues.</p>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-5-1">
<h2><a class="toc-backref" href="#id133">11.3&nbsp;&nbsp;&nbsp;version 2.5.1:</a></h2>
<blockquote>
<ul>
<li><p class="first">Sources directories reorganized</p>
</li>
<li><p class="first">New &quot;Phoenix&quot; tool to try to reboot automatically broken nodes
(to setup into /etc/oar/oar_phoenix.pl)</p>
</li>
<li><p class="first">New (experimental!) scheduler written in Ocaml</p>
</li>
<li><p class="first">Cpusets are activated by default</p>
</li>
<li><p class="first">Bugfix #11065: oar_resource_init fix (add a space)</p>
</li>
<li><p class="first">Bug 10999: memory leak into Hulot when used with postgresql. The leak has been
minimized, but it is still there (DBD::Pg bug)</p>
</li>
<li><p class="first">Almighty cleans ipcs used by oar on exit</p>
</li>
<li><p class="first">Bugfix #10641 and #10999 : Hulot is automatically and periodically restarted</p>
</li>
<li><p class="first">Feature request #10565: add the possibility to check the aliveness of the
nodes of a job at the end of this one (pingchecker)</p>
</li>
<li><p class="first">REST API heavily updated: new data structures with paginated results, desktop
computing functions, rspec tests, oaradmin resources management, admission
rules edition, relative/absolutes uris fixed</p>
</li>
<li><p class="first">New ruby desktop computing agent using REST API (experimental)</p>
</li>
<li><p class="first">Experimental testsuite</p>
</li>
<li><p class="first">Poar: web portal using the REST API (experimental)</p>
</li>
<li><p class="first">Oaradmin YAML export support for resources creation (for the REST API)</p>
</li>
<li><p class="first">Bugfix #10567: enabling to bypass window mechanism of hulot.</p>
</li>
<li><p class="first">Bugfix #10568: Wake up timeout changing with the number of nodes</p>
</li>
<li><p class="first">Add in oar.conf the tag &quot;RUNNER_SLIDING_WINDOW_SIZE&quot;: it allows the runner
to use a sliding window to launch the bipbip processes if
&quot;DETACH_JOB_FROM_SERVER=1&quot;. This feature avoids the overload of the server
if plenty of jobs have to be launched at the same time.</p>
</li>
<li><p class="first">Fix problem when deleting a job in the Suspended state (oarexec was stopped
by a SIGSTOP so it was not able to handle the delete operation)</p>
</li>
<li><p class="first">Make the USER_SIGNAL feature of oardel multi job independant and remove the
temporary file at the end of the job</p>
</li>
<li><dl class="first docutils">
<dt>Monika: display if the job is of timesharing type or not</dt>
<dd><p class="first last">add in the job listing the initial_request (is there a reason to
not display it?)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>IoLib: update scheduler_priority resources property for timesharing jobs.</dt>
<dd><p class="first last">So the scheduler will be able to avoid to launch every timesharing
jobs on the same resources (they can be dispatched)</p>
</dd>
</dl>
</li>
<li><p class="first">OAREXEC: unmask SIGHUP and SIGPIPE for user script</p>
</li>
<li><p class="first">node_change_state: do not Suspect the first node of a job which was
EXTERMINATED by Leon if the cpuset feature is configured (let do the job by
the cpuset)</p>
</li>
<li><p class="first">OAREXEC: ESRF detected that sometime oarexec think that he notified the
Almighty with it exit code but nothing was seen on the server. So try to
resend the exit code until oarexec is killed.</p>
</li>
<li><p class="first">oar_Tools: add in notify_almighty a check on the print and on the close of
the socket connected to Almighty.</p>
</li>
<li><p class="first">oaraccounting: --sql is now possible into a &quot;oarstat --accounting&quot; query</p>
</li>
<li><p class="first">Add more logs to the command &quot;oarnodes -e host&quot; when a node turns into
Suspected</p>
</li>
<li><p class="first">Execute user commands with /proc/self/oom_adj to 15. So the first processes
that will be killed when there is no more memory available is the user
ones.
Hence the system will remain up and running and the user job will finished.
Drawback: this file can be changed manually by the user so if someone knows
a method to do the same thing but only managed by root, we take???</p>
</li>
<li><p class="first">Bugfix API: quotes where badly escaped into job submission (<a class="reference external" href="mailto:Ugo.Meda@insa-rennes.fr">Ugo.Meda&#64;insa-rennes.fr</a>)</p>
</li>
<li><p class="first">Add the possibility to automatically resubmit idempotent job which ends
with an exit code of 99: oarsub -t idempotent &quot;sleep 5; exit 99&quot;</p>
</li>
<li><p class="first">Bugfix API: Some informations where missing into jobs/details, especially the
scheduled resources.</p>
</li>
<li><p class="first">API: added support of &quot;param_file&quot; value for array job submissions. This value
is a string representing the content of a parameters file. Sample submission:</p>
<pre class="literal-block">
{&quot;resource&quot;:&quot;/cpu=1&quot;, &quot;command&quot;:&quot;sleep&quot;, &quot;param_file&quot;:&quot;60\n90\n30&quot;}
</pre>
<p>This submits 3 sleep jobs with differents sleep values.</p>
</li>
<li><p class="first">Remove any reference to gridlibs and gridapi as these components are obselete</p>
</li>
<li><p class="first">Add stdout and stderr files of each job in oarstat output.</p>
</li>
<li><p class="first">API now supports fastcgi (big performance raise!)</p>
</li>
<li><p class="first">Add &quot;-f&quot; option to oarnodesetting to read hostnames from a file.</p>
</li>
<li><p class="first">API can get/upload files (GET or POST /media/&lt;file_path&gt;)</p>
</li>
<li><p class="first">Make &quot;X11 forwarding&quot; working even if the user XAUTHORITY environment
variable does not contain ~/.Xauthority (GDM issue).</p>
</li>
<li><p class="first">Add job_resource_manager_cgroups which handles cpuset + other cgroup
features like network packet tagging, IO disk shares, ...</p>
</li>
<li><p class="first">Bugfix #13351: now oar_psql_db_init is executed with root privileges</p>
</li>
<li><p class="first">Bugfix #13434: reservation were not handled correctly with the energy
saving feature</p>
</li>
<li><p class="first">Add cgroups FREEZER feature to the suspend/resume script (better than kill
SIGSTOP/SIGCONT).
This is doable thanks to the new job_resource_manager_cgroups.</p>
</li>
<li><p class="first">Implement a new script 'oar-database' to manage the oar database.
oar_mysql_init &amp; oar_psql_init are dropped.</p>
</li>
<li><p class="first">Huge code reorganisation to allow a better packaging and system integration</p>
</li>
<li><p class="first">Drop the oarsub/oarstat 2.3 version that was kept for compatiblity issues
during the 2.4.x branch.</p>
</li>
<li><p class="first">By default the oar scheduler is now
'oar_sched_gantt_with_timesharing_and_fairsharing' and the following values
has been set in oar.conf: SCHEDULER_TIMEOUT to 30, SCHEDULER_NB_PROCESSES to 4
and SCHEDULER_FAIRSHARING_MAX_JOB_PER_USER to 30</p>
</li>
<li><p class="first">Add a limitation on the number of concurrent bipbip processes on the server
(for detached jobs).</p>
</li>
<li><p class="first">Add IPC cleaning to the job_resource_manager* when there is no other job of
the same user on the nodes.</p>
</li>
<li><p class="first">make better scheduling behaviour for dependency jobs</p>
</li>
<li><p class="first">API: added missing stop_time into /jobs/details</p>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-4-4">
<h2><a class="toc-backref" href="#id134">11.4&nbsp;&nbsp;&nbsp;version 2.4.4:</a></h2>
<blockquote>
<ul class="simple">
<li>oar_resource_init: bad awk delimiter. There's a space and if the property
is the first one then there is not a ','.</li>
<li>job suspend: oardo does not exist anymore (long long time ago). Replace it
with oardodo.</li>
<li>oarsub: when an admission rule died micheline returns an integer and not an
array ref. Now oarsub ends nicely.</li>
<li>Monika: add a link on each jobid on the node display area.</li>
<li>sshd_config: with nodes with a lot of core, 10 // connections could be too
few</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-4-3">
<h2><a class="toc-backref" href="#id135">11.5&nbsp;&nbsp;&nbsp;version 2.4.3:</a></h2>
<blockquote>
<ul class="simple">
<li>Hulot module now has customizable keepalive feature</li>
<li>Added a hook to launch a healing command when nodes are suspected
(activate the SUSPECTED_HEALING_EXEC_FILE variable)</li>
<li>Bugfix #9995: oaraccouting script doesn't freeze anymore when db is unreachable.</li>
<li>Bugfix #9990: prevent from inserting jobs with invalid username (like an empty username)</li>
<li>Oarnodecheck improvements: node is not checked if a job is already running</li>
<li>New oaradmin option: --auto-offset</li>
<li>Feature request #10565: add the possibility to check the aliveness of the
nodes of a job at the end of this one (pingchecker)</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-4-2">
<h2><a class="toc-backref" href="#id136">11.6&nbsp;&nbsp;&nbsp;version 2.4.2:</a></h2>
<blockquote>
<ul class="simple">
<li>New &quot;Hulot&quot; module for intelligent and configurable energy saving</li>
<li>Bug #9906: fix bad optimization in the gantt lib (so bad scheduling</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-4-1">
<h2><a class="toc-backref" href="#id137">11.7&nbsp;&nbsp;&nbsp;version 2.4.1:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug #9038: Security flaw in oarsub --notify option</li>
<li>Bug #9601: Cosystem jobs are no more killed when a resource is set to Absent</li>
<li>Fixed some packaging bugs</li>
<li>API bug fixes in job submission parsing</li>
<li>Added standby info into <cite>oarnodes -s</cite> and available_upto info into
/resources uri of the API</li>
<li>Bug Grid'5000 #2687 Fix possible crashes of the scheduler.</li>
<li>Bug fix: with MySQL DB Finaud suspected resources which are not of the
&quot;default&quot; type.</li>
<li>Signed debian packages (install oar-keyring package)</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-4-0">
<h2><a class="toc-backref" href="#id138">11.8&nbsp;&nbsp;&nbsp;version 2.4.0:</a></h2>
<blockquote>
<ul>
<li><p class="first">Bug #8791: added CHECK_NODES_WITH_RUNNING_JOB=no to prevent from checking
occupied nodes</p>
</li>
<li><p class="first">Fix bug in oarnodesetting command generated by oar_resources_init (detect_resources)</p>
</li>
<li><p class="first">Added a --state option to oarstat to only get the status of specified jobs
(optimized query, to allow scripting)</p>
</li>
<li><p class="first">Added a REST API for OAR and OARGRID</p>
</li>
<li><p class="first">Added JSON support into oarnodes, oarstat and oarsub</p>
</li>
<li><p class="first">New Makefile adapted to build packages as non-root user</p>
</li>
<li><p class="first">add the command &quot;oar_resources_init&quot; to easily detect and initialize the
whole resources of a cluster.</p>
</li>
<li><p class="first">&quot;oaradmin version&quot; : now retrieve the most recent database schema number</p>
</li>
<li><p class="first">Fix rights on the &quot;schema&quot; table in postgresql.</p>
</li>
<li><p class="first">Bug #7509: fix bug in add_micheline_subjob for array jobs + jobtypes</p>
</li>
<li><p class="first">Ctrl-C was not working anymore in oarsub.
It seems that the signal handler does not handle the previous syntax
($SIG = 'qdel')</p>
</li>
<li><p class="first">Fix bug in oarsh with the &quot;-l&quot; option</p>
</li>
<li><p class="first">Bug #7487: bad initialisation of the gnatt for the container jobs.</p>
</li>
<li><p class="first">Scheduler: move the &quot;delete_unnecessary_subtrees&quot; directly into
&quot;find_first_hole&quot;. Thus this is possible to query a job like:</p>
<pre class="literal-block">
oarsub -I -l nodes=1/core=1+nodes=4/core=2
(no hard separation between each group)
</pre>
<dl class="docutils">
<dt>For the same behaviour as before, you can query:</dt>
<dd><p class="first last">oarsub -I -l {prop=1}/nodes=1/core=1+{prop=2}/nodes=4/core=2</p>
</dd>
</dl>
</li>
<li><p class="first">Bug #7634: test if the resource property value is effectively defined
otherwise print a ''</p>
</li>
<li><p class="first">Optional script to take into account cpu/core topology of the nodes at boot
time (to activate inside oarnodesetting_ssh)</p>
</li>
<li><p class="first">Bug #7174: Cleaned default PATH from &quot;./&quot; into oardodo</p>
</li>
<li><p class="first">Bug #7674: remove the computation of the scheduler_priority field for
besteffort jobs from the asynchronous OAR part. Now the value is set when
the jobs are turned into toLaunch state and in Error/Terminated.</p>
</li>
<li><p class="first">Bug #7691: add --array and --array-param-file options parsing into the
submitted script. Fix also some parsing errors.</p>
</li>
<li><p class="first">Bug #7962: enable resource property &quot;cm_availability&quot; to be manipulated by
the oarnodesetting command</p>
</li>
<li><dl class="first docutils">
<dt>Added the (standby) information to a node state in oarnodes when it's state</dt>
<dd><p class="first last">is Absent and cm_availability != 0</p>
</dd>
</dl>
</li>
<li><p class="first">Changed the name of cm_availability to available_upto which is more relevant</p>
</li>
<li><p class="first">add a --maintenance option to oarnodesetting that sets the state of a resource
to Absent and its available_upto to 0 if maintenance is on and resets previous
values if maintenance is off.</p>
</li>
<li><p class="first">added a --signal option to oardel that allow a user to send a signal to one of
his jobs</p>
</li>
<li><p class="first">added a name field in the schema table that will refer to the OAR version name</p>
</li>
<li><p class="first">added a table containing scheduler name, script and description</p>
</li>
<li><p class="first">Bug #8559: Almighty: Moved OAREXEC_XXXX management code out of the queue for
immediate action, to prevent potential problems in case of scheduler timeouts.</p>
</li>
<li><p class="first">oarnodes, oarstat and the REST API are no more making retry connections to the
database in case of failure, but exit with an error instead. The retry behavior
is left for daemons.</p>
</li>
<li><p class="first">improved packaging (try to install files in more standard places)</p>
</li>
<li><p class="first">improved init script for Almighty (into deb and rpm packages)</p>
</li>
<li><p class="first">fixed performance issue on oarstat (array_id index missing)</p>
</li>
<li><p class="first">fixed performance issue (job_id index missing in event_log table)</p>
</li>
<li><p class="first">fixed a performance issue at job submission (optimized a query and added an
index on challenges table)
decisions).</p>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-3-5">
<h2><a class="toc-backref" href="#id139">11.9&nbsp;&nbsp;&nbsp;version 2.3.5:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug #8139: Drawgantt nil error (Add condition to test the presence of nil
value in resources table.)</li>
<li>Bug #8416: When a the automatic halt/wakeup feature is enabled then there
was a problem to determine idle nodes.</li>
<li>Debug a mis-initialization of the Gantt with running jobs in the
metascheduler (concurrency access to PG database)</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-3-4">
<h2><a class="toc-backref" href="#id140">11.10&nbsp;&nbsp;&nbsp;version 2.3.4:</a></h2>
<blockquote>
<ul class="simple">
<li>add the command &quot;oar_resources_init&quot; to easily detect and initialize the
whole resources of a cluster.</li>
<li>&quot;oaradmin version&quot; : now retrieve the most recent database schema number</li>
<li>Fix rights on the &quot;schema&quot; table in postgresql.</li>
<li>Bug #7509: fix bug in add_micheline_subjob for array jobs + jobtypes</li>
<li>Ctrl-C was not working anymore in oarsub.
It seems that the signal handler does not handle the previous syntax
($SIG = 'qdel')</li>
<li>Bug #7487: bad initialisation of the gnatt for the container jobs.</li>
<li>Fix bug in oarsh with the &quot;-l&quot; option</li>
<li>Bug #7634: test if the resource property value is effectively defined
otherwise print a ''</li>
<li>Bug #7674: remove the computation of the scheduler_priority field for
besteffort jobs from the asynchronous OAR part. Now the value is set when
the jobs are turned into toLaunch state and in Error/Terminated.</li>
<li>Bug #7691: add --array and --array-param-file options parsing into the
submitted script. Fix also some parsing errors.</li>
<li>Bug #7962: enable resource property &quot;cm_availability&quot; to be manipulated by
the oarnodesetting command</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-3-3">
<h2><a class="toc-backref" href="#id141">11.11&nbsp;&nbsp;&nbsp;version 2.3.3:</a></h2>
<blockquote>
<ul>
<li><p class="first">Fix default admission rules: case unsensitive check for properties used in
oarsub</p>
</li>
<li><p class="first">Add new oaradmin subcommand : oaradmin conf. Useful to edit conf files and
keep changes in a Subversion repository.</p>
</li>
<li><p class="first">Kill correctly each taktuk command children in case of a timeout.</p>
</li>
<li><p class="first">New feature: array jobs (option --array)  (on oarsub, oarstat oardel,
oarhold and oarresume) and file-based parametric array jobs
(oarsub --array-param-file)
/!in this version the DB scheme has changed. If you want to upgrade your
installation from a previous 2.3 release then you have to execute in your
database one of these SQL script (stop OAR before):</p>
<pre class="literal-block">
mysql:
    DB/mysql_structure_upgrade_2.3.1-2.3.3.sql

postgres:
    DB/pg_structure_upgrade_2.3.1-2.3.3.sql
</pre>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-3-2">
<h2><a class="toc-backref" href="#id142">11.12&nbsp;&nbsp;&nbsp;version 2.3.2:</a></h2>
<blockquote>
<ul class="simple">
<li>Change scheduler timeout implementation to schedule the maximum of jobs.</li>
<li>Bug #5879: do not show initial_request in oarstat when it is not a job of
the user who launched the oarstat command (oar or root).</li>
<li>Add a --event option to oarnodes and oarstat to display events recorded for
a job or node</li>
<li>Display reserved resources for a validated waiting reservation, with a hint
in their state</li>
<li>Fix oarproperty: property names are lowercase</li>
<li>Fix OAR_JOB_PROPERTIES_FILE: do not display system properties</li>
<li>Add a new user command: oarprint which allow to pretty print resource
properties of a job</li>
<li>Debug temporary job UID feature</li>
<li>Add 'kill -9' on subprocesses that reached a timeout (avoid Perl to
wait something)</li>
<li>desktop computing feature is now available again. (ex: oarsub -t
desktop_computing date)</li>
<li>Add versioning feature for admission rules with Subversion</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-3-1">
<h2><a class="toc-backref" href="#id143">11.13&nbsp;&nbsp;&nbsp;version 2.3.1:</a></h2>
<blockquote>
<ul class="simple">
<li>Add new oarmonitor command. This will permit to monitor OAR jobs on compute
nodes.</li>
<li>Remove sudo dependency and replace it by the commands &quot;oardo&quot; and
&quot;oardodo&quot;.</li>
<li>Add possibility to create a temporary user for each jobs on compute nodes.
So you can perform very strong restrictions for each job (ex: bandwidth
restrictions with iptable, memory management, ... everything that can be
handled with a user id)</li>
<li>Debian packaging: Run OAR specific sshd with root privileges (under heavy
load, kernel may be more responsive for root processes...)</li>
<li>Remove ALLOWED_NETWORKS tag in oar.conf (added more complexeity than
resolving problems)</li>
<li>/!change database scheme for the field <em>exit_code</em> in the table <em>jobs</em>.
Now <em>oarstat</em> <em>exit_code</em> line reflects the right exit code of the user
passive job (before, even when the user script was not launched the
<em>exit_code</em> was 0 which was BAD)</li>
<li>/!add DB field <em>initial_request</em> in the table <em>jobs</em> that stores the
oarsub line of the user</li>
<li>Feature Request #4868: Add a parameter to specify what the &quot;nodes&quot; resource
is a synomym for. Network_address must be seen as an internal data and not
used.</li>
<li>Scheduler: add timeout for each job == 1/4 of the remaining scheduler
timeout.</li>
<li>Bug #4866: now the whole node is Suspected instead of just the par where
there is no job onto. So it is possible to have a job on Suspected nodes.</li>
<li>Add job walltime (in seconds) in parameter of prologue and epilogue on
compute nodes.</li>
<li>oarnodes does not show system properties anymore.</li>
<li>New feature: container job type now allows to submit inner jobs for a
scheduling within the container job</li>
<li>Monika refactoring and now in the oar packaging.</li>
<li>Added a table schema in the db with the field version, reprensenting the
version of the db schema.</li>
<li>Added a field DB_PORT in the oar config file.</li>
<li>Bug #5518: add right initialization of the job user name.</li>
<li>Add new oaradmin command. This will permit to create resources and
manage admission rules more easily.</li>
<li>Bug #5692: change source code into a right Perl 5.10 syntax.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-12">
<h2><a class="toc-backref" href="#id144">11.14&nbsp;&nbsp;&nbsp;version 2.2.12:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug #5239: fix the bug if there are spaces into job name or project</li>
<li>Fix the bug in Iolib if DEAD_SWITCH_TIME &gt;0</li>
<li>Fix a bug in bipbip when calling the cpuset_manager to clean jobs in error</li>
<li>Bug #5469: fix the bug with reservations and Dead resources</li>
<li>Bug #5535: checks for reservations made at a same time was wrong.</li>
<li>New feature: local checks on nodes can be plugged in the oarnodecheck
mechanism. Results can be asynchronously checked from the server (taktuk
ping checker)</li>
<li>Add 2 new tables to keep track of the scheduling decisions
(gantt_jobs_predictions_log and gantt_jobs_resources_log). This will help
debugging scheduling troubles (see SCHEDULER_LOG_DECISIONS in oar.conf)</li>
<li>Now reservations are scheduled only once (at submission time). Resources
allocated to a reservations are definitively set once the validated is
done and won't change in next scheduler's pass.</li>
<li>Fix DrawGantt to not display besteffort jobs in the future which is
meaningless.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-11">
<h2><a class="toc-backref" href="#id145">11.15&nbsp;&nbsp;&nbsp;version 2.2.11:</a></h2>
<blockquote>
<ul class="simple">
<li>Fix Debian package dependency on a CGI web server.</li>
<li>Fix little bug: remove notification (scheduled start time) for Interactive
reservation.</li>
<li>Fix bug in reservation: take care of the SCHEDULER_JOB_SECURITY_TIME for
reservations to check.</li>
<li>Fix bug: add a lock around the section which creates and feed the OAR
cpuset.</li>
<li>Taktuk command line API has changed (we need taktuk &gt;= 3.6).</li>
<li>Fix extra ' in the name of output files when using a job name.</li>
<li>Bug #4740: open the file in oarsub with user privileges (-S option)</li>
<li>Bug #4787: check if the remote socket is defined (problem of timing with
nmap)</li>
<li>Feature Request #4874: check system names when renaming properties</li>
<li>DrawGantt can export charts to be reused to build a global multi-OAR view
(e.g. DrawGridGantt).</li>
<li>Bug #4990: DrawGantt now uses the database localtime as its time reference.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-10">
<h2><a class="toc-backref" href="#id146">11.16&nbsp;&nbsp;&nbsp;version 2.2.10:</a></h2>
<blockquote>
<ul class="simple">
<li>Job dependencies: if the required jobs do not have an exit code == 0 and in
the state Terminated then the schedulers refuse to schedule this job.</li>
<li>Add the possibility to disable the halt command on nodes with
cm_availability value.</li>
<li>Enhance oarsub &quot;-S&quot; option (more #OAR parsed).</li>
<li>Add the possibility to use oarsh without configuring the CPUSETs (can be
useful for users that don't want to configure there ssh keys)</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-9">
<h2><a class="toc-backref" href="#id147">11.17&nbsp;&nbsp;&nbsp;version 2.2.9:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug 4225: Dump only 1 data structure when using -X or -Y or -D.</li>
<li>Bug fix in Finishing sequence (Suspect right nodes).</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-8">
<h2><a class="toc-backref" href="#id148">11.18&nbsp;&nbsp;&nbsp;version 2.2.8:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug 4159: remove unneeded Dump print from oarstat.</li>
<li>Bug 4158: replace XML::Simple module by XML::Dumper one.</li>
<li>Bug fix for reservation (recalculate the right walltime).</li>
<li>Print job dependencies in oarstat.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-7">
<h2><a class="toc-backref" href="#id149">11.19&nbsp;&nbsp;&nbsp;version 2.2.7:</a></h2>
</div>
<div class="section" id="id12">
<h2><a class="toc-backref" href="#id150">11.20&nbsp;&nbsp;&nbsp;version 2.2.11:</a></h2>
<blockquote>
<ul class="simple">
<li>Fix Debian package dependency on a CGI web server.</li>
<li>Fix little bug: remove notification (scheduled start time) for Interactive
reservation.</li>
<li>Fix bug in reservation: take care of the SCHEDULER_JOB_SECURITY_TIME for
reservations to check.</li>
<li>Fix bug: add a lock around the section which creates and feed the OAR
cpuset.</li>
<li>Taktuk command line API has changed (we need taktuk &gt;= 3.6).</li>
<li>Fix extra ' in the name of output files when using a job name.</li>
<li>Bug #4740: open the file in oarsub with user privileges (-S option)</li>
<li>Bug #4787: check if the remote socket is defined (problem of timing with
nmap)</li>
<li>Feature Request #4874: check system names when renaming properties</li>
<li>DrawGantt can export charts to be reused to build a global multi-OAR view
(e.g. DrawGridGantt).</li>
<li>Bug #4990: DrawGantt now uses the database localtime as its time reference.</li>
</ul>
</blockquote>
</div>
<div class="section" id="id13">
<h2><a class="toc-backref" href="#id151">11.21&nbsp;&nbsp;&nbsp;version 2.2.10:</a></h2>
<blockquote>
<ul class="simple">
<li>Job dependencies: if the required jobs do not have an exit code == 0 and in
the state Terminated then the schedulers refuse to schedule this job.</li>
<li>Add the possibility to disable the halt command on nodes with
cm_availability value.</li>
<li>Enhance oarsub &quot;-S&quot; option (more #OAR parsed).</li>
<li>Add the possibility to use oarsh without configuring the CPUSETs (can be
useful for users that don't want to configure there ssh keys)</li>
</ul>
</blockquote>
</div>
<div class="section" id="id14">
<h2><a class="toc-backref" href="#id152">11.22&nbsp;&nbsp;&nbsp;version 2.2.9:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug 4225: Dump only 1 data structure when using -X or -Y or -D.</li>
<li>Bug fix in Finishing sequence (Suspect right nodes).</li>
</ul>
</blockquote>
</div>
<div class="section" id="id15">
<h2><a class="toc-backref" href="#id153">11.23&nbsp;&nbsp;&nbsp;version 2.2.8:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug 4159: remove unneeded Dump print from oarstat.</li>
<li>Bug 4158: replace XML::Simple module by XML::Dumper one.</li>
<li>Bug fix for reservation (recalculate the right walltime).</li>
<li>Print job dependencies in oarstat.</li>
</ul>
</blockquote>
</div>
<div class="section" id="id16">
<h2><a class="toc-backref" href="#id154">11.24&nbsp;&nbsp;&nbsp;version 2.2.7:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug 4106: fix oarsh and oarcp issue with some options (erroneous leading
space).</li>
<li>Bug 4125: remove exit_code data when it is not relevant.</li>
<li>Fix potential bug when changing asynchronously the state of the jobs into
&quot;Terminated&quot; or &quot;Error&quot;.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-6">
<h2><a class="toc-backref" href="#id155">11.25&nbsp;&nbsp;&nbsp;version 2.2.6:</a></h2>
<blockquote>
<ul>
<li><dl class="first docutils">
<dt>Bug fix: job types was not sent to cpuset manager script anymore.</dt>
<dd><p class="first last">(border effect from bug 4069 resolution)</p>
</dd>
</dl>
</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-5">
<h2><a class="toc-backref" href="#id156">11.26&nbsp;&nbsp;&nbsp;version 2.2.5:</a></h2>
<blockquote>
<ul class="simple">
<li>Bug fix: remove user command when oar execute the epilogue script on the
nodes.</li>
<li>Clean debug and mail messages format.</li>
<li>Remove bad oarsub syntax from oarsub doc.</li>
<li>Debug xauth path.</li>
<li>bug 3995: set project correctly when resubmitting a job</li>
<li>debug 'bash -c' on Fedora</li>
<li>bug 4069: reservations with CPUSET_ERROR (remove bad hosts and continue
with a right integrity in the database)</li>
<li>bug 4044: fix free resources query for reservation (get the nearest hole
from the beginning of the reservation)</li>
<li>bug 4013: now Dead, Suspected and Absent resources have different colors in
drawgantt with a popup on them.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-4">
<h2><a class="toc-backref" href="#id157">11.27&nbsp;&nbsp;&nbsp;version 2.2.4:</a></h2>
<blockquote>
<ul class="simple">
<li>Redirect third party commands into oar.log (easier to debug).</li>
<li>Add user info into drawgantt interface.</li>
<li>Some bug fixes.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-3">
<h2><a class="toc-backref" href="#id158">11.28&nbsp;&nbsp;&nbsp;version 2.2.3:</a></h2>
<blockquote>
<ul class="simple">
<li>Debug prologue and epilogue when oarexec receives a signal.</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-2">
<h2><a class="toc-backref" href="#id159">11.29&nbsp;&nbsp;&nbsp;version 2.2.2:</a></h2>
<blockquote>
<ul class="simple">
<li>Switch nice value of the user processes into 0 in oarsh_shell (in case of
sshd was launched with a different priority).</li>
<li>debug taktuk zombies in pingchecker and oar_Tools</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2-1">
<h2><a class="toc-backref" href="#id160">11.30&nbsp;&nbsp;&nbsp;version 2.2.1:</a></h2>
<blockquote>
<ul class="simple">
<li>install the &quot;allow_clasic_ssh&quot; feature by default</li>
<li>debug DB installer</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-2">
<h2><a class="toc-backref" href="#id161">11.31&nbsp;&nbsp;&nbsp;version 2.2:</a></h2>
<blockquote>
<ul class="simple">
<li>oar_server_proepilogue.pl: can be used for server prologue and epilogue to
authorize users to access to nodes that are completely allocated by OAR. If
the whole node is assigned then it kills all jobs from the user if all cpus
are assigned.</li>
<li>the same thing can be done with cpuset_manager_PAM.pl as the script used to
configure the cpuset. More efficent if cpusets are configured.</li>
<li>debug cm_availability feature to switch on and off nodes automatically
depending on waiting jobs.</li>
<li>reservations now take care of cm_availability field</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-1-0">
<h2><a class="toc-backref" href="#id162">11.32&nbsp;&nbsp;&nbsp;version 2.1.0:</a></h2>
<blockquote>
<ul class="simple">
<li>add &quot;oarcp&quot; command to help the users to copy files using oarsh.</li>
<li>add sudo configuration to deal with bash. Now oarsub and oarsh have the
same behaviour as ssh (the bash configuration files are loaded correctly)</li>
<li>bug fix in drawgantt (loose jobs after submission of a moldable one)</li>
<li>add SCHEDULER_RESOURCES_ALWAYS_ASSIGNED_TYPE into oar.conf. Thus admin can
add some resources for each jobs (like frontale node)</li>
<li>add possibility to use taktuk to check the aliveness of the nodes</li>
<li>%jobid% is now replaced in stdout and stderr file names by the effective
job id</li>
<li>change interface to shu down or wake up nodes automatically (now the node
list is read on STDIN)</li>
<li>add OARSUB_FORCE_JOB_KEY in oar.conf. It says to create a job ssh key by
default for each job.</li>
<li>%jobid% is now replaced in the ssh job key name (oarsub -k ...).</li>
<li>add NODE_FILE_DB_FIELD_DISTINCT_VALUES in oar.conf that enables the admin
to configure the generated containt of the OAR_NODE_FILE</li>
<li>change ssh job key oarsub options behaviour</li>
<li>add options &quot;--reinitialize&quot; and &quot;--delete-before&quot; to the oaraccounting
command</li>
<li>cpuset are now stored in /dev/cpuset/oar</li>
<li>debian packaging: configure and launch a specific sshd for the user oar</li>
<li>use a file descriptor to send the node list --&gt; able to handle a very large
amount of nodes</li>
<li>every config files are now in /etc/oar/</li>
<li>oardel can add a besteffort type to jobs and vis versa</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-0-2">
<h2><a class="toc-backref" href="#id163">11.33&nbsp;&nbsp;&nbsp;version 2.0.2:</a></h2>
<blockquote>
<ul class="simple">
<li>add warnings and exit code to oarnodesetting when there is a bad node name
or resource number</li>
<li>change package version</li>
<li>change default behaviour for the cpuset_manager.pl (more portable)</li>
<li>enable a user to use the same ssh key for several jobs (at his own risk!)</li>
<li>add node hostnames in oarstat -f</li>
<li>add --accounting and -u options in oarstat</li>
<li>bug fix on index fields in the database (syncro): bug 2020</li>
<li>bug fix about server pro/epilogue: bug 2022</li>
<li>change the default output of oarstat. Now it is usable: bug 1875</li>
<li>remove keys in authorized_keys of oar (on the nodes) that do not
correspond to an active cpuset (clean after a reboot)</li>
<li>reread oar.conf after each database connection tries</li>
<li>add support for X11 forwarding in oarsub -I and -C</li>
<li>debug mysql initialization script in debian package</li>
<li>add a variable in oarsh for the default options of ssh to use
(more useful to change if the ssh version installed does not
handle one of these options)</li>
<li>read oar.conf in oarsh (so admin can more easily change options in this
script)</li>
<li>add support for X11 forwarding via oarsh</li>
<li>change variable for oarsh: OARSH_JOB_ID --&gt; OAR_JOB_ID</li>
</ul>
</blockquote>
</div>
<div class="section" id="version-2-0-0">
<h2><a class="toc-backref" href="#id164">11.34&nbsp;&nbsp;&nbsp;version 2.0.0:</a></h2>
<blockquote>
<ul>
<li><p class="first">Now, with the ability to declare any type of resources like licences,
VLAN, IP range, computing resources must have the type <em>default</em> and a
network_address not null.</p>
</li>
<li><p class="first">Possibility to declare associated resources like licences, IP ranges, ...
and to reserve them like others.</p>
</li>
<li><p class="first">Now you can connect to your jobs (not only for reservations).</p>
</li>
<li><p class="first">Add &quot;cosystem&quot; job type (execute and do nothing for these jobs).</p>
</li>
<li><p class="first">New scheduler : &quot;oar_sched_gantt_with_timesharing&quot;. You can specify jobs
with the type &quot;timesharing&quot; that indicates that this scheduler can launch
more than 1 job on a resource at a time. It is possible to restrict this
feature with words &quot;user and name&quot;. For example, '-t
timesharing=user,name' indicates that only a job from the same user with
the same name can be launched in the same time than it.</p>
</li>
<li><p class="first">Add PostGresSQL support. So there is a choice to make between MySQL and
PostgresSQL.</p>
</li>
<li><p class="first">New approach for the scheduling : administrators have to insert into the
databases descriptions about resources and not nodes. Resources have a
network address (physical node) and properties. For example, if you have
dual-processor, then you can create 2 different resources with the same
natwork address but with 2 different processor names.</p>
</li>
<li><p class="first">The scheduler can now handle resource properties in a hierarchical
manner. Thus, for example, you can do &quot;oarsub -l /switch=1/cpu=5&quot; which
submit a job on 5 processors on the same switch.</p>
</li>
<li><p class="first">Add a signal handler in oarexec and propagate this signal to the user
process.</p>
</li>
<li><p class="first">Support '#OAR -p ...' options in user script.</p>
</li>
<li><dl class="first docutils">
<dt>Add in oar.conf:</dt>
<dd><ul class="first last simple">
<li>DB_BASE_PASSWD_RO : for security issues, it is possible to execute
request with parts specified by users with a read only account (like
&quot;-p&quot; option).</li>
<li>OARSUB_DEFAULT_RESOURCES : when nothing is specified with the oarsub
command then OAR takes this default resource description.</li>
<li>OAREXEC_DEBUG_MODE : turn on or off debug mode in oarexec (create
/tmp/oar/oar.log on nodes).</li>
<li>FINAUD_FREQUENCY : indicates the frequency when OAR launchs Finaud
(search dead nodes).</li>
<li>SCHEDULER_TIMEOUT : indicates to the scheduler the amount of time
after what it must end itself.</li>
<li>SCHEDULER_JOB_SECURITY_TIME : time between each job.</li>
<li>DEAD_SWITCH_TIME : after this time Absent and Suspected resources are
turned on the Dead state.</li>
<li>PROLOGUE_EPILOGUE_TIMEOUT : the possibility to specify a different
timeout for prologue and epilogue (PROLOGUE_EPILOGUE_TIMEOUT).</li>
<li>PROLOGUE_EXEC_FILE : you can specify the path of the prologue script
executed on nodes.</li>
<li>EPILOGUE_EXEC_FILE : you can specify the path of the epilogue script
executed on nodes.</li>
<li>GENERIC_COMMAND : a specific script may be used instead of ping to
check aliveness of nodes. The script must return bad nodes on STDERR
(1 line for a bad node and it must have exactly the same name that
OAR has given in argument of the command).</li>
<li>JOBDEL_SOFTWALLTIME : time after a normal frag that the system waits
to retry to frag the job.</li>
<li>JOBDEL_WALLTIME : time after a normal frag that the system waits
before to delete the job arbitrary and suspects nodes.</li>
<li>LOG_FILE : specify the path of OAR log file (default :
/var/log/oar.log).</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Add wait() in pingchecker to avoid zombies.</p>
</li>
<li><p class="first">Better code modularization.</p>
</li>
<li><p class="first">Remove node install part to launch jobs. So it is easier to upgrade from
one version to an other (oarnodesetting must already be installed on each
nodes if we want to use it).</p>
</li>
<li><p class="first">Users can specify a method to be notified (mail or script).</p>
</li>
<li><p class="first">Add cpuset support</p>
</li>
<li><p class="first">Add prologue and epilogue script to be executed on the OAR server before
and after launching a job.</p>
</li>
<li><p class="first">Add dependancy support between jobs (&quot;-a&quot; option in oarsub).</p>
</li>
<li><p class="first">In oarsub you can specify the launching directory (&quot;-d&quot; option).</p>
</li>
<li><p class="first">In oarsub you can specify a job name (&quot;-n&quot; option).</p>
</li>
<li><p class="first">In oarsub you can specify stdout and stderr file names.</p>
</li>
<li><p class="first">User can resubmit a job (option &quot;--resubmit&quot; in oarsub).</p>
</li>
<li><p class="first">It is possible to specify a read only database account and it will be
used to evaluate SQL properties given by the user with the oarsub command
(more scecure).</p>
</li>
<li><p class="first">Add possibility to order assigned resources with their properties by the
scheduler. So you can privilege some resources than others
(SCHEDULER_RESOURCE_ORDER tag in oar.conf file)</p>
</li>
<li><p class="first">a command can be specified to switch off idle nodes
(SCHEDULER_NODE_MANAGER_SLEEP_CMD, SCHEDULER_NODE_MANAGER_IDLE_TIME,
SCHEDULER_NODE_MANAGER_SLEEP_TIME in oar.conf)</p>
</li>
<li><p class="first">a command can be specified to switch on nodes in the Absent state
according to the resource property <em>cm_availability</em> in the table
resources (SCHEDULER_NODE_MANAGER_WAKE_UP_CMD in oar.conf).</p>
</li>
<li><p class="first">if a job goes in Error state and this is not its fault then OAR will
resubmit this one.</p>
</li>
</ul>
</blockquote>
</div>
</div>
<div class="section" id="oar-archives">
<h1><a class="toc-backref" href="#id165">12&nbsp;&nbsp;&nbsp;OAR Archives</a></h1>
<p>There are several mini-projects for and around OAR that has been done since the
beginning. Some of them are not currently used or are no more relevant. To keep
a trace for memories and for the possibility to reuse them if needed, we have
created a branche 'archives' in the OAR source repository to keep them. Here
are the list of them.</p>
<div class="section" id="module-accounting">
<h2><a class="toc-backref" href="#id166">12.1&nbsp;&nbsp;&nbsp;module Accounting</a></h2>
</div>
<div class="section" id="desktop-computing">
<h2><a class="toc-backref" href="#id167">12.2&nbsp;&nbsp;&nbsp;desktop_computing</a></h2>
</div>
<div class="section" id="drmaa-c">
<h2><a class="toc-backref" href="#id168">12.3&nbsp;&nbsp;&nbsp;drmaa-c</a></h2>
</div>
<div class="section" id="moldable">
<h2><a class="toc-backref" href="#id169">12.4&nbsp;&nbsp;&nbsp;moldable</a></h2>
</div>
<div class="section" id="ocaml-schedulers">
<h2><a class="toc-backref" href="#id170">12.5&nbsp;&nbsp;&nbsp;ocaml-schedulers</a></h2>
</div>
<div class="section" id="poar">
<h2><a class="toc-backref" href="#id171">12.6&nbsp;&nbsp;&nbsp;poar</a></h2>
</div>
<div class="section" id="poar-proto">
<h2><a class="toc-backref" href="#id172">12.7&nbsp;&nbsp;&nbsp;poar-proto</a></h2>
</div>
<div class="section" id="testsuite">
<h2><a class="toc-backref" href="#id173">12.8&nbsp;&nbsp;&nbsp;testsuite</a></h2>
</div>
<div class="section" id="tgoar">
<h2><a class="toc-backref" href="#id174">12.9&nbsp;&nbsp;&nbsp;tgoar</a></h2>
</div>
</div>
</div>
<div class="footer">
<hr class="footer" />
<a class="reference external" href="OAR-DOCUMENTATION-ADMIN.rst">View document source</a>.
Generated on: 2012-11-16 09:25 UTC.
Generated by <a class="reference external" href="http://docutils.sourceforge.net/">Docutils</a> from <a class="reference external" href="http://docutils.sourceforge.net/rst.html">reStructuredText</a> source.

</div>



</div>





</div>

<div id="footer" class="pagefooter">

<div id="pageinfo">









<div class="pagedate">
Last edited <span class="date">Friday 16 November 2012</span>
<!-- Created <span class="date">Wednesday 15 June 2011</span> -->
</div>

</div>


<!-- from OAR -->
</div>

</div>

</body>
</html>
